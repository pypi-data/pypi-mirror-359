{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b13b8c2-4c83-4873-87a2-0ff2c8b02b7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook to automatically process multiple datasets\n",
    "__Written by Haixing Fang, Jon Wright and James Ball__  \n",
    "__Date: 21/02/2025__\n",
    "\n",
    "With this notebook, we can process multiple datasets and samples.  \n",
    "You choose which notebooks you would like to run, and which samples to run them on.  \n",
    "Notebooks will be ran with the same parameters you defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4859d-bf4f-4347-942e-1ea6de4203b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'  # ignore papermill debugger warnings\n",
    "\n",
    "exec(open('/data/id11/nanoscope/install_ImageD11_from_git.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90d06e-5ba9-4c22-829b-5a0cccb0ef88",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged with 'parameters'\n",
    "# to view the tag, select the cell, then find the settings gear icon (right or left sidebar) and look for Cell Tags\n",
    "\n",
    "PYTHONPATH = setup_ImageD11_from_git( ) # ( os.path.join( os.environ['HOME'],'Code'), 'ImageD11_git' )\n",
    "\n",
    "# give it a path to an existing dataset to determine the required paths\n",
    "dset_path = \"path/to/dataset.h5\"\n",
    "\n",
    "# you can specify a list of samples to process\n",
    "sample_list = None\n",
    "\n",
    "# or you can specify a skips_dict and a samples_dict\n",
    "skips_dict = {'sample':['ff1']}  # for example, we already processed layer ff1\n",
    "samples_dict = None\n",
    "\n",
    "# common prefix to all datasets\n",
    "dset_prefix = 'ff'\n",
    "\n",
    "# which notebooks should be run?\n",
    "notebooks_to_run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8af86f-330b-486e-a7da-1307c193910f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ImageD11.sinograms.dataset\n",
    "from ImageD11.nbGui import segmenter_gui\n",
    "from ImageD11.nbGui import nb_utils as utils\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65f950-5c35-4f1e-8d27-e4e87256fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageD11.sinograms.dataset.load(dset_path)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6c65d-47ca-4f15-9f40-168cc072a83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try to get list of samples automatically\n",
    "if sample_list is None:\n",
    "    sample_list = sorted([name for name in os.listdir(ds.dataroot) if os.path.isdir(os.path.join(ds.dataroot, name))])\n",
    "\n",
    "print(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970bfe86-09f3-4f2a-83a4-867f5cfe70d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if samples_dict is None:\n",
    "    samples_dict = utils.find_datasets_to_process(ds.dataroot, skips_dict, dset_prefix, sample_list)\n",
    "\n",
    "print(samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9313bae-8e46-42f0-9ddc-1f2bade7b9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# which notebooks would you like to run?\n",
    "# example is below for single-phase tomo method\n",
    "# provided as as list of tuples of:\n",
    "# (notebook_name, notebook_params_dict)\n",
    "\n",
    "if notebooks_to_run is None:\n",
    "    notebooks_to_run = [\n",
    "        ('0_segment_and_label.ipynb', {}), \n",
    "        ('tomo_1_index.ipynb', {}), \n",
    "        ('tomo_2_map.ipynb', {}),\n",
    "        ('tomo_3_refinement.ipynb', {}),\n",
    "        ('4_visualise.ipynb', {}),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b87b74-9627-4787-b3e1-5e27e39f5c38",
   "metadata": {},
   "source": [
    "The next cell will prepare the notebooks for execution by putting them in PROCESSED_DATA/sample/sample_dataset for each dataset.  \n",
    "It will skip this if any notebooks are already present in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467fa39-85c3-4be1-ab1b-a491e0f12419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebooks_to_execute = utils.prepare_notebooks_for_datasets(samples_dict,\n",
    "                                                            notebooks_to_run,\n",
    "                                                            ds.dataroot,\n",
    "                                                            ds.analysisroot,\n",
    "                                                            PYTHONPATH=PYTHONPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4bc3b-49e1-45bf-a7eb-934381bdb95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('I will execute the following notebooks:')\n",
    "pprint.pprint([nb.split(ds.analysisroot)[1] for nb in notebooks_to_execute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec07a7-50b1-480d-9fa8-c6fd1cd3c38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Executing notebooks')\n",
    "for nb_path in notebooks_to_execute:\n",
    "    utils.notebook_exec_pmill(nb_path, nb_path, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (main)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
