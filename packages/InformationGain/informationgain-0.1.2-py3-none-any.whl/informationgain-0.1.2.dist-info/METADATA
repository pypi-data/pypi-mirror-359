Metadata-Version: 2.4
Name: InformationGain
Version: 0.1.2
Summary: A Python package for calculating information gain.
Author: Abhinav Masih
Author-email: abhnv.msh@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: requires-python
Dynamic: summary

# informationGain Library

This module helps you calculate **Information Gain** for categorical data using **entropy**.

---

## Class
`infoGain.calculate(data, target, fIndex=True)`

---

## Parameters

| Parameter | Type      | Description                                                      | Default |
|-----------|-----------|------------------------------------------------------------------|---------|
| `data`    | DataFrame | Dataset in pandas dataframe format                               | Required|
| `target`  | String    | Output column (the target variable)                              | Required|
| `fIndex`  | Boolean   | Specifies if the first column of the dataset is an index column  | True    |

---

## Description
- Calculates **Information Gain** for each feature/column in the dataset with respect to the target column.
- Useful for decision tree splitting based on entropy.
- **Returns:** A dictionary where keys are feature/column names and values are their corresponding Information Gain with respect to the target column.

---

## Example Usage
```python
from informationGain import infoGain

import pandas as pd

# Load dataset
data = pd.read_csv('your_dataset.csv')

# Initialize
ig = infoGain()

# Calculate Information Gain
result = ig.calculate(data, target='Output', fIndex=True)

print(result)
# Example Output:
# {'Feature1': 0.25, 'Feature2': 0.18, 'Feature3': 0.0}
