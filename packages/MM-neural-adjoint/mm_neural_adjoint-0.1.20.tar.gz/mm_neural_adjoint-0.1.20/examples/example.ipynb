{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "This notebook demonstrates how to use the Neural Adjoint (NA) package with different model architectures for both forward and inverse modeling.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The example covers two main scenarios:\n",
    "\n",
    "### Example 1: Built-in Models\n",
    "- **Data**: Loads geometry-spectra pairs from CSV files (8D geometry → 300D spectra)\n",
    "- **Models**: Demonstrates both `ConvModel` and `LinModel` architectures\n",
    "- **Training**: Trains forward models (geometry → spectra) with automatic checkpointing\n",
    "- **Inference**: Shows both forward prediction and NA inverse prediction (spectra → geometry)\n",
    "\n",
    "### Example 2: Custom PyTorch Models\n",
    "- **Custom Architecture**: Defines a simple feedforward neural network\n",
    "- **Synthetic Data**: Generates 1000 samples with 200D input → 10D output\n",
    "- **Training**: Trains the custom model using the NA framework\n",
    "- **Evaluation**: Demonstrates geometry prediction and evaluation on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example 1**\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mm_neural_adjoint import NANetwork, ConvModel, LinModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/data_x_tiny.csv', header=None, delimiter=' ')\n",
    "y = pd.read_csv('data/data_y_tiny.csv', header=None, delimiter=' ')\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split the dataset into train, validation, and test\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Convolutional Model\n",
    "\n",
    "This cell trains a convolutional neural network using the Neural Adjoint framework which was used in the original paper.\n",
    "\n",
    "**Setup:**\n",
    "- Creates a `ConvModel` with 8 input features and 300 output features\n",
    "- Wraps it in `NANetwork` for enhanced training capabilities\n",
    "- Sets up device (GPU if available, otherwise CPU)\n",
    "\n",
    "**Training:**\n",
    "- Trains for 50 epochs using the provided train and validation data loaders\n",
    "- Uses a custom progress bar to track training progress\n",
    "- Automatically saves the best model during training based on validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 50/50 [00:04<00:00, 11.49it/s, train_loss=0.012768, val_loss=0.017610]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_conv = ConvModel(8, 300)\n",
    "\n",
    "model = NANetwork(model_conv, device=device)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "pbar = tqdm(total=epochs, desc='Training Progress')\n",
    "\n",
    "model.train(epochs, train_loader, val_loader, progress_bar=pbar, save=True)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "# model.evaluate_geometry(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FC Model\n",
    "\n",
    "This cell trains a fully connected neural network using the Neural Adjoint framework worked better for some data.\n",
    "\n",
    "**Setup:**\n",
    "- Creates a `LinModel` with 8 input features and 300 output features\n",
    "- Wraps it in `NANetwork` for enhanced training capabilities\n",
    "- Sets up device (GPU if available, otherwise CPU)\n",
    "\n",
    "**Training:**\n",
    "- Trains for 50 epochs using the provided train and validation data loaders\n",
    "- Uses a custom progress bar to track training progress\n",
    "- Automatically saves the best model during training based on validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 50/50 [00:06<00:00,  7.68it/s, train_loss=0.009149, val_loss=0.022766]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_lin = LinModel(8, 300)\n",
    "\n",
    "model = NANetwork(model_lin, device=device)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "pbar = tqdm(total=epochs, desc='Training Progress')\n",
    "\n",
    "model.train(epochs, train_loader, val_loader, progress_bar=pbar, save=True)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "# model.evaluate_geometry(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FC Model\n",
    "\n",
    "This cell trains a fully connected neural network using the Neural Adjoint framework worked better for some data.\n",
    "\n",
    "**Setup:**\n",
    "- Creates a `LinModel` with 8 input features and 300 output features\n",
    "- Wraps it in `NANetwork` for enhanced training capabilities\n",
    "- Sets up device (GPU if available, otherwise CPU)\n",
    "\n",
    "**Training:**\n",
    "- Trains for 50 epochs using the provided train and validation data loaders\n",
    "- Uses a custom progress bar to track training progress\n",
    "- Automatically saves the best model during training based on validation loss\n",
    "\n",
    "**Tracking & MLflow:**\n",
    "- Training metrics are logged to MLflow for experiment tracking\n",
    "- Records learning rate, batch size, regularization parameters, and geometry bounds\n",
    "- Tracks training loss, validation loss, and best validation loss over time\n",
    "- Saves total training time and model checkpoints\n",
    "- Results stored in local SQLite database (`mlflow.db`)\n",
    "- View results by running: `mlflow ui --backend-store-uri sqlite:///mlflow.db` in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:12<?, ?it/s]\n",
      "2025/07/03 11:32:48 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/07/03 11:32:48 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/07/03 11:32:48 INFO mlflow.tracking.fluent: Experiment with name 'NA' does not exist. Creating a new experiment.\n",
      "Training Progress: 100%|██████████| 50/50 [00:08<00:00,  6.24it/s, train_loss=0.015750, val_loss=0.021109]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_lin = LinModel(8, 300)\n",
    "\n",
    "model = NANetwork(model_lin, device=device, tracking=True)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "pbar = tqdm(total=epochs, desc='Training Progress')\n",
    "\n",
    "model.train(epochs, train_loader, val_loader, progress_bar=pbar, save=True)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "# model.evaluate_geometry(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Model\n",
    "\n",
    "This cell loads a previously trained model from a checkpoint file.\n",
    "\n",
    "**What's Loaded:**\n",
    "- Model architecture (`LinModel` with 8 input features, 300 output features)\n",
    "- Trained model weights and parameters\n",
    "- Training metadata including best validation loss\n",
    "- Geometry preprocessing parameters (mean, lower/upper bounds)\n",
    "- Optimizer state (if available)\n",
    "\n",
    "**Usage:**\n",
    "- Creates a new `NANetwork` instance with the same architecture\n",
    "- Loads the saved state from `checkpoints/best_model.pt`\n",
    "- Prints the geometry lower bounds to verify successful loading\n",
    "- Model is ready for inference without retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model from checkpoints/best_model.pt\n",
      "tensor([-1., -1., -1., -1., -1., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LinModel(8, 300)\n",
    "model = NANetwork(model, device=device)\n",
    "\n",
    "\n",
    "model.load('checkpoints/best_model.pt')\n",
    "print(model.geometry_lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Prediction (Geometry → Spectra)\n",
    "\n",
    "This cell demonstrates standard forward inference using the trained model.\n",
    "\n",
    "**Process:**\n",
    "- Takes a single geometry sample from the dataset (`X_tensor[0]`)\n",
    "- Adds batch dimension with `unsqueeze(0)` for model input\n",
    "- Predicts the corresponding spectra using the trained forward model\n",
    "- Returns predicted spectra with shape `(1, 300)` - one sample with 300 spectral features\n",
    "\n",
    "**Usage:**\n",
    "- Standard neural network inference (no Neural Adjoint method)\n",
    "- Useful for validating model performance on known geometries\n",
    "- Can be used for batch predictions by passing multiple geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "spectra = model.predict_spectra(X_tensor[0].unsqueeze(0))\n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Adjoint Prediction (Spectra → Geometry)\n",
    "\n",
    "This cell demonstrates the core Neural Adjoint method for inverse prediction.\n",
    "\n",
    "**Process:**\n",
    "- Takes a target spectra (`y_tensor[0]`) as input\n",
    "- Uses gradient-based optimization to find the best geometry that produces this spectra\n",
    "- Runs multiple optimization trials with different initializations\n",
    "- Returns the top prediction based on MSE loss\n",
    "\n",
    "**Outputs:**\n",
    "- `Xpred_top`: Predicted geometry with shape `(1, 8)` - one sample with 8 geometry features\n",
    "- `Ypred_top`: Predicted spectra from the best geometry with shape `(1, 300)`\n",
    "- `MSE_top`: Mean squared error between target and predicted spectra\n",
    "\n",
    "**Key Features:**\n",
    "- Inverse modeling using gradient descent on the input space\n",
    "- Multiple random initializations for robust optimization\n",
    "- Boundary constraints to keep predictions within valid geometry ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using first layer extraction with 8 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8) (1, 300) (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "Xpred_top, Ypred_top, MSE_top = model.predict_geometry(y_tensor[0])\n",
    "print(Xpred_top.shape, Ypred_top.shape, MSE_top.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom PyTorch Model Definition\n",
    "\n",
    "This cell defines a custom feedforward neural network architecture.\n",
    "\n",
    "**Architecture:**\n",
    "- Input layer: 200 features → 128 hidden units\n",
    "- Hidden layer 1: 128 → 64 units\n",
    "- Hidden layer 2: 64 → 32 units\n",
    "- Output layer: 32 → 10 features\n",
    "- ReLU activation functions and 20% dropout for regularization\n",
    "\n",
    "**Flexibility:**\n",
    "This demonstrates that **any PyTorch model** can be used with the Neural Adjoint framework.\n",
    "\n",
    "The only requirement is that the model inherits from `nn.Module` and implements a `forward()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size=200, output_size=10, hidden_size=128):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            # Input layer: 200 -> 128\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Hidden layer: 128 -> 64\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Hidden layer: 64 -> 32\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Output layer: 32 -> 10\n",
    "            nn.Linear(hidden_size // 4, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation\n",
    "\n",
    "This cell creates synthetic training data to demonstrate the Neural Adjoint framework.\n",
    "\n",
    "**Data Generation:**\n",
    "- **1000 samples** with **200 input features** and **10 output features**\n",
    "- Input features: Random normal distribution (mean=0, std=0.5)\n",
    "- Output features: Non-linear transformation of inputs with added noise\n",
    "\n",
    "**Data Loaders:**\n",
    "- Training: Batch size 32 with shuffling\n",
    "- Validation: Batch size 32 without shuffling\n",
    "- Test: Batch size 1 for individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1000, 200])\n",
      "y shape: torch.Size([1000, 10])\n",
      "X range: [-2.295, 2.315]\n",
      "y range: [-1.052, 0.850]\n",
      "\n",
      "Dataset splits:\n",
      "Train: 700 samples\n",
      "Validation: 290 samples\n",
      "Test: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic training data\n",
    "n_samples = 1000\n",
    "n_features = 200\n",
    "n_outputs = 10\n",
    "\n",
    "# Create input features (X) - random values between -1 and 1\n",
    "X = torch.randn(n_samples, n_features) * 0.5  # Normal distribution with std=0.5\n",
    "\n",
    "# Create a simple relationship for outputs (Y)\n",
    "# This creates a non-linear relationship between inputs and outputs\n",
    "def generate_outputs(X):\n",
    "    # Create some non-linear transformations\n",
    "    Y = torch.zeros(n_samples, n_outputs)\n",
    "    \n",
    "    for i in range(n_outputs):\n",
    "        # Each output depends on different combinations of input features\n",
    "        feature_indices = torch.randperm(n_features)[:20]  # Use 20 random features per output\n",
    "        weights = torch.randn(20) * 0.1\n",
    "        \n",
    "        # Non-linear transformation\n",
    "        Y[:, i] = torch.sum(X[:, feature_indices] * weights, dim=1) + \\\n",
    "                  torch.sin(torch.sum(X[:, feature_indices], dim=1)) * 0.1 + \\\n",
    "                  torch.randn(n_samples) * 0.05  # Add some noise\n",
    "    \n",
    "    return Y\n",
    "\n",
    "# Generate outputs\n",
    "y = generate_outputs(X)\n",
    "\n",
    "# Convert to pandas DataFrames (optional, for easy viewing)\n",
    "X_df = pd.DataFrame(X.numpy())\n",
    "y_df = pd.DataFrame(y.numpy())\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "print(f\"y range: [{y.min():.3f}, {y.max():.3f}]\")\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Split into train/validation/test\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.29 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 50/50 [00:02<00:00, 23.33it/s, train_loss=0.015782, val_loss=0.017491]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sample_X, sample_y = next(iter(train_loader))\n",
    "\n",
    "model_base = SimpleModel(sample_X.shape[1], sample_y.shape[1])\n",
    "\n",
    "model = NANetwork(model_base, device=device)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "pbar = tqdm(total=epochs, desc='Training Progress')\n",
    "\n",
    "model.train(epochs, train_loader, val_loader, progress_bar=pbar, save=True)\n",
    "\n",
    "pbar.close()\n",
    "# model.evaluate_geometry(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "This cell performs comprehensive evaluation of the trained model on the test dataset.\n",
    "\n",
    "**Process:**\n",
    "- Evaluates the model on all test samples using the Neural Adjoint method\n",
    "- For each test sample, performs inverse prediction (spectra → geometry)\n",
    "- Compares predicted geometries with true geometries\n",
    "- Saves results to CSV files for analysis\n",
    "\n",
    "**Output Files:**\n",
    "- `val_results/val_Ypred.csv`: Predicted spectra from best geometries\n",
    "- `val_results/val_Ytruth.csv`: True target spectra\n",
    "- `val_results/val_Xtruth.csv`: True input geometries\n",
    "- `val_results/val_Xpred.csv`: Predicted geometries\n",
    "\n",
    "- Batch size must be 1 for evaluation (individual sample processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_geometry(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Sample Neural Adjoint Prediction\n",
    "\n",
    "This cell demonstrates the Neural Adjoint method on a single target sample.\n",
    "\n",
    "**Process:**\n",
    "- Takes the first target spectra from the synthetic dataset (`y[0]`)\n",
    "- Uses gradient-based optimization to find the best input that produces this target\n",
    "- Runs multiple optimization trials with different random initializations\n",
    "- Returns the top prediction based on MSE loss\n",
    "\n",
    "**Outputs:**\n",
    "- `Xpred_top`: Predicted input features with shape `(1, 200)` - one sample with 200 features\n",
    "- `Ypred_top`: Predicted output from the best input with shape `(1, 10)`\n",
    "- `MSE_top`: Mean squared error between target and predicted output\n",
    "\n",
    "**Parameters:**\n",
    "- `save_top`: Controls how many top predictions to return (default=1 for best prediction only)\n",
    "\n",
    "**Note** This does not save the results to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using first layer extraction with 8 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8) (10, 300) (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "sample = next(iter(test_loader))[1]\n",
    "\n",
    "Xpred_top, Ypred_top, MSE_top = model.predict_geometry(sample, save_top=10)\n",
    "print(Xpred_top.shape, Ypred_top.shape, MSE_top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "na",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
