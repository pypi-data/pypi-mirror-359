"""Flashinho Pro Agent - Advanced multimodal Brazilian educational assistant.

This agent combines the authentic Brazilian educational coaching personality of Flashinho
with advanced multimodal capabilities powered by Google Gemini 2.5 Pro model.
Includes mathematical problem detection and solving via flashinho_thinker workflow.
"""
import logging
import time
from typing import Dict, Optional, Tuple

from automagik.agents.models.automagik_agent import AutomagikAgent
from automagik.agents.models.response import AgentResponse
from automagik.memory.message_history import MessageHistory
from automagik.tools.flashed.tool import (
    get_user_data, get_user_score, get_user_roadmap, 
    get_user_objectives, get_last_card_round, get_user_energy,
    get_user_by_pretty_id
)
from automagik.tools.flashed.provider import FlashedProvider
from .prompts.prompt import AGENT_PROMPT, AGENT_FREE
from .memory_manager import update_flashinho_pro_memories, initialize_flashinho_pro_memories
from .user_identification import FlashinhoProUserMatcher
# from .models import ImageAnalysis, WorkflowStatus, StepBreakdown
# from .workflow_monitor import track_workflow, update_workflow_status, log_workflow_summary

# Import shared utilities from tools/flashed
from automagik.tools.flashed.auth_utils import (
    UserStatusChecker, preserve_authentication_state, restore_authentication_state
)
from automagik.tools.flashed.user_identification import (
    identify_user_comprehensive, UserIdentificationResult,
    ensure_user_uuid_matches_flashed_id, make_session_persistent
)
from automagik.tools.flashed.workflow_runner import analyze_student_problem
from automagik.tools.flashed.message_generator import (
    generate_math_processing_message, generate_pro_feature_message,
    generate_error_message
)
from automagik.tools.evolution.api import send_text_message

logger = logging.getLogger(__name__)


class FlashinhoPro(AutomagikAgent):
    """Advanced multimodal Brazilian educational assistant powered by Google Gemini 2.5 Pro.
    
    Features:
    - Authentic Brazilian Generation Z Portuguese coaching style
    - Multimodal processing: images, audio, documents for educational content
    - Complete Flashed API integration for educational gaming
    - WhatsApp/Evolution channel integration for media handling
    - Cultural authenticity for Brazilian high school students
    """
    
    def __init__(self, config: Dict[str, str]) -> None:
        """Initialize Flashinho Pro with multimodal and Gemini configuration."""
        if config is None:
            config = {}

        # default/fallback models
        self.pro_model = "google:gemini-2.5-pro"
        self.free_model = "google:gemini-2.5-flash"
        config.setdefault("supported_media", ["image", "audio", "document"])
        config.setdefault("auto_enhance_prompts", True)
        config.setdefault("enable_multi_prompt", True)

        super().__init__(config)

        self._code_prompt_text = AGENT_PROMPT

        # setup dependencies
        self.dependencies = self.create_default_dependencies()
        if self.db_id:
            self.dependencies.set_agent_id(self.db_id)
        self.tool_registry.register_default_tools(self.context)
        
        # Register Flashed API tools for educational context
        self._register_flashed_tools()
        
        # Register multimodal analysis tools
        self._register_multimodal_tools()
        
        # Flag to track if we've checked user status
        self._user_status_checked = False
        # Default to non-pro until verified
        self._is_pro_user = False
        
        # Initialize provider
        self.flashed_provider = FlashedProvider()
        
        # Initialize user status checker for shared authentication
        self.user_status_checker = UserStatusChecker()
        
        logger.debug("Flashinho Pro initialized with dynamic model selection")
    
    def _register_flashed_tools(self) -> None:
        """Register all Flashed API tools for educational gaming functionality."""
        # Register tools using the tool registry (same method used by MultimodalAgent)
        self.tool_registry.register_tool(get_user_data)
        self.tool_registry.register_tool(get_user_score)
        self.tool_registry.register_tool(get_user_roadmap)
        self.tool_registry.register_tool(get_user_objectives)
        self.tool_registry.register_tool(get_last_card_round)
        self.tool_registry.register_tool(get_user_energy)
        self.tool_registry.register_tool(get_user_by_pretty_id)
        
        # Tools registered silently
    
    async def _check_user_pro_status(self, user_id: Optional[str] = None) -> bool:
        """Check if user has Pro subscription status.
        
        Args:
            user_id: User ID to check
            
        Returns:
            Boolean indicating if user has Pro status
        """
        try:
            if not user_id:
                logger.warning("No user ID available to check Pro status, defaulting to non-Pro")
                return False
                
            # Use the Flashed API to check user subscription status
            return await self.flashed_provider.check_user_pro_status(user_id)
                
        except Exception as e:
            logger.error(f"Error checking Pro status for user {user_id}: {str(e)}")
            # Default to non-Pro on errors
            return False
    
    async def _update_model_and_prompt_based_on_status(self, user_id: Optional[str] = None) -> None:
        """Update model and prompt based on user's Pro status.
        
        Args:
            user_id: User ID to check
        """
        # Skip if we've already checked this session
        if self._user_status_checked:
            return
            
        # Check user Pro status
        self._is_pro_user = await self._check_user_pro_status(user_id)
        self._user_status_checked = True
        
        # Update model and prompt based on status
        if self._is_pro_user:
            # Pro user - use Pro model and prompt
            self.model_name = self.pro_model
            self.system_message = AGENT_PROMPT
            self.vision_model = self.pro_model
            # Ensure the model is properly set for the LLM client
            if hasattr(self, 'llm_client') and hasattr(self.llm_client, 'model'):
                self.llm_client.model = self.pro_model
            # Update dependencies if they exist
            if hasattr(self, 'dependencies'):
                if hasattr(self.dependencies, 'model_name'):
                    self.dependencies.model_name = self.pro_model
                if hasattr(self.dependencies, 'llm_client') and hasattr(self.dependencies.llm_client, 'model'):
                    self.dependencies.llm_client.model = self.pro_model
                # Ensure the prompt is set in dependencies if applicable
                if hasattr(self.dependencies, 'prompt'):
                    self.dependencies.prompt = AGENT_PROMPT
            logger.info(f"Pro user {user_id} - {self.pro_model}")
        else:
            # Free user - use Free model and prompt
            self.model_name = self.free_model
            self.system_message = AGENT_FREE
            # Update vision model for multimodal content
            self.vision_model = self.free_model
            # Ensure the model is properly set for the LLM client
            if hasattr(self, 'llm_client') and hasattr(self.llm_client, 'model'):
                self.llm_client.model = self.free_model
            # Update dependencies if they exist
            if hasattr(self, 'dependencies'):
                if hasattr(self.dependencies, 'model_name'):
                    self.dependencies.model_name = self.free_model
                if hasattr(self.dependencies, 'llm_client') and hasattr(self.dependencies.llm_client, 'model'):
                    self.dependencies.llm_client.model = self.free_model
                # Ensure the prompt is set in dependencies if applicable
                if hasattr(self.dependencies, 'prompt'):
                    self.dependencies.prompt = AGENT_FREE
            logger.info(f"Free user {user_id} - {self.free_model}")
    
    async def _check_for_prettyid_identification(self, input_text: str) -> Optional[str]:
        """Check if the message contains a prettyId and update context accordingly.
        
        Args:
            input_text: The user's message text
            
        Returns:
            User ID if found via prettyId, None otherwise
        """
        try:
            # Use the user matcher to detect prettyId and fetch user data
            matcher = FlashinhoProUserMatcher(self.context)
            pretty_id = matcher.extract_pretty_id_from_message(input_text)
            
            if pretty_id:
                logger.debug(f"Found prettyId: {pretty_id}")
                
                # Fetch user data using the prettyId
                user_data = await matcher._find_user_by_pretty_id(pretty_id)
                
                if user_data and user_data.get("user", {}).get("id"):
                    user_id = user_data["user"]["id"]
                    
                    # Update context with user information
                    self.context["flashed_user_id"] = user_id
                    self.context["user_identification_method"] = "prettyId"
                    self.context["pretty_id"] = pretty_id
                    
                    # Update context with additional user data
                    user_info = user_data["user"]
                    if user_info.get("name"):
                        self.context["user_name"] = user_info["name"]
                    if user_info.get("phone"):
                        self.context["user_phone_number"] = user_info["phone"]
                    if user_info.get("email"):
                        self.context["user_email"] = user_info["email"]
                    
                    logger.info(f"User identified via prettyId: {user_id}")
                    return user_id
                else:
                    logger.warning(f"No user found for prettyId: {pretty_id}")
            
            return None
            
        except Exception as e:
            logger.error(f"Error checking for prettyId identification: {str(e)}")
            return None

    async def _ensure_user_memories_ready(self, user_id: Optional[str] = None) -> None:
        """Ensure user memories are initialized and updated for prompt variables.
        
        Args:
            user_id: User ID for user-specific memories
        """
        try:
            if not self.db_id:
                logger.warning("No agent database ID available, skipping memory initialization")
                return
                
            # Initialize default memories if they don't exist
            await initialize_flashinho_pro_memories(self.db_id, user_id)
            
            # Update memories with current user data from Flashed API
            success = await update_flashinho_pro_memories(self.db_id, user_id, self.context)
            
            if success:
                logger.debug(f"Memories updated for user {user_id}")
            else:
                logger.warning(f"Failed to update some Flashinho Pro memories for user {user_id}")
                
        except Exception as e:
            logger.error(f"Error ensuring user memories ready: {str(e)}")
            # Continue with default memories - the framework will handle missing variables
    
    async def _detect_student_problem_in_image(self, multimodal_content, user_message: str = "") -> Tuple[bool, str]:
        """Detect if image contains any student problem based on context clues.
        
        Args:
            multimodal_content: Multimodal content dictionary
            user_message: User's message for context
            
        Returns:
            Tuple of (is_student_problem_detected, subject_context)
        """
        if not multimodal_content:
            return False, ""
            return False, ""
            
        try:
            # Check multimodal content structure
            
            # Check if we have image content
            image_data = multimodal_content.get("image_data") or multimodal_content.get("image_url")
            
            # Also check for 'images' key which might contain a list
            if not image_data and "images" in multimodal_content:
                images = multimodal_content.get("images", [])
                # Process images list
                if images:
                    # Handle the structure where images is a list of dicts
                    if isinstance(images, list) and len(images) > 0:
                        first_image = images[0]
                        if isinstance(first_image, dict):
                            # Extract image data from dict structure
                            image_data = first_image.get("data") or first_image.get("url") or first_image.get("media_url")
                            # Extracted image data from dict
                        else:
                            image_data = first_image
                    else:
                        image_data = images
            
            if not image_data:
                return False, ""
                return False, ""
            
            # Analyze for educational context
            
            # Detect educational context from user message
            educational_keywords = {
                "matem√°tica": ["equa√ß√£o", "resolver", "matem√°tica", "c√°lculo", "√°lgebra", "geometria"],
                "f√≠sica": ["f√≠sica", "cinem√°tica", "for√ßa", "energia", "movimento"],
                "qu√≠mica": ["qu√≠mica", "rea√ß√£o", "elemento", "mol√©cula", "√°tomo"],
                "biologia": ["biologia", "c√©lula", "DNA", "fotoss√≠ntese", "evolu√ß√£o"],
                "hist√≥ria": ["hist√≥ria", "guerra", "imp√©rio", "revolu√ß√£o", "s√©culo"],
                "geografia": ["geografia", "mapa", "pa√≠s", "clima", "relevo"],
                "portugu√™s": ["portugu√™s", "texto", "gram√°tica", "literatura"],
                "ingl√™s": ["ingl√™s", "english", "tradu√ß√£o", "vocabul√°rio"],
                "educacional": ["exerc√≠cio", "quest√£o", "problema", "d√∫vida", "estudar", "prova", "vestibular"]
            }
            
            detected_subject = "geral"
            user_text = user_message.lower()
            
            # Check for subject-specific keywords
            for subject, keywords in educational_keywords.items():
                if any(keyword in user_text for keyword in keywords):
                    detected_subject = subject
                    # Detected subject
                    break
            
            # If we have an image and any educational context, consider it a student problem
            is_educational = detected_subject != "geral" or any(
                keyword in user_text for keywords in educational_keywords.values() for keyword in keywords
            )
            
            if is_educational:
                context = f"educational content detected: {detected_subject} problem"
                logger.info(f"Student problem detected: {context}")
                return True, context
            else:
                # No educational context
                return False, ""
            
        except Exception as e:
            logger.error(f"Error detecting student problem in image: {str(e)}")
            return False, ""
    
    async def _send_processing_message(self, phone: str, user_name: str, problem_context: str, user_message: str = ""):
        """Send customized processing message via Evolution.
        
        Args:
            phone: User's phone number
            user_name: User's name
            problem_context: Context about the student problem
            user_message: Original user message for context
        """
        try:
            # Generate personalized message using LLM
            message = await generate_math_processing_message(
                user_name=user_name,
                math_context=problem_context,
                user_message=user_message
            )
            
            # Get Evolution instance from context
            instance = (
                self.context.get("evolution_instance") or 
                self.context.get("whatsapp_instance") or
                self.context.get("instanceId")
            )
            
            if not instance:
                logger.warning("No Evolution instance in context, cannot send message")
                return
                
            # Send message using Evolution API directly
            success, msg_id = await send_text_message(
                instance_name=instance,
                number=phone,
                text=message
            )
            
            if success:
                logger.debug(f"Processing message sent to {phone}")
            else:
                logger.error(f"Failed to send processing message: {msg_id}")
                
        except Exception as e:
            logger.error(f"Error sending processing message: {str(e)}")
    
    async def _handle_student_problem_flow(self, multimodal_content, user_id: str, phone: str, problem_context: str, user_message: str = "") -> str:
        """Handle the complete student problem solving flow with 3-step breakdown.
        
        Args:
            multimodal_content: Multimodal content with image
            user_id: User ID
            phone: User's phone number
            problem_context: Context about the student problem
            user_message: Original user message
            
        Returns:
            Result text from workflow execution with 3-step breakdown
        """
        try:
            # Starting student problem flow
            
            # Send processing message to user
            user_name = self.context.get("flashed_user_name", "")
            # Send processing message
            await self._send_processing_message(phone, user_name, problem_context, user_message)
            
            # Extract image data
            # Extract image data
            image_data = multimodal_content.get("image_data") or multimodal_content.get("image_url")
            
            # Also check for 'images' key which might contain a list
            if not image_data and "images" in multimodal_content:
                images = multimodal_content.get("images", [])
                # Process images for workflow
                if images and isinstance(images, list) and len(images) > 0:
                    first_image = images[0]
                    if isinstance(first_image, dict):
                        # Extract image data from dict structure
                        image_data = first_image.get("data") or first_image.get("url") or first_image.get("media_url")
                        # Extracted image for workflow
                    else:
                        image_data = first_image
            
            if not image_data:
                logger.error("No image data found in multimodal content - image extraction failed")
                return "Desculpa, n√£o consegui acessar a imagem. Pode tentar enviar novamente?"
            
            # Start workflow monitoring
            workflow_id = f"flashinho_{int(time.time())}_{str(user_id)[:8]}"
            
            # Start workflow with simple monitoring
            logger.info(f"Starting student problem workflow {workflow_id} for user {user_id}")
            
            try:
                # Use the analyze_student_problem convenience function
                result_text = await analyze_student_problem(image_data, user_message)
                
                duration = time.time() - float(workflow_id.split('_')[1])
                logger.info(f"Student problem workflow {workflow_id} completed in {duration:.2f}s")
                
                # Add workflow tracking info to result
                result_text += f"\n\n<!-- workflow:{workflow_id} -->"
                
                return result_text
                
            except Exception as e:
                duration = time.time() - float(workflow_id.split('_')[1])
                logger.error(f"Student problem workflow {workflow_id} failed after {duration:.2f}s: {str(e)}")
                raise
            
        except Exception as e:
            logger.error(f"Error in math problem flow: {str(e)}")
            
            # Generate error message using LLM
            error_msg = await generate_error_message(
                user_name=self.context.get("flashed_user_name"),
                error_context="falha ao processar o problema",
                suggestion="tentar enviar a imagem novamente com mais clareza"
            )
            
            return error_msg
    
    async def _identify_user_with_conversation_code(self, input_text: str, message_history_obj: Optional[MessageHistory]) -> UserIdentificationResult:
        """Identify user using shared authentication utilities with state restoration.
        
        Args:
            input_text: User's message text
            message_history_obj: Message history object
            
        Returns:
            UserIdentificationResult with identification details
        """
        try:
            # First, try to restore authentication state from cache
            phone_number = (
                self.context.get("whatsapp_user_number") or 
                self.context.get("user_phone_number")
            )
            session_id = self.context.get("session_id")
            
            if phone_number:
                cached_auth = await restore_authentication_state(phone_number, session_id)
                if cached_auth:
                    # Restore context from cached authentication
                    self.context.update({
                        "flashed_user_id": cached_auth.get("flashed_user_id"),
                        "flashed_conversation_code": cached_auth.get("flashed_conversation_code"),
                        "user_id": cached_auth.get("flashed_user_id"),  # Use flashed_user_id as user_id
                        "user_identification_method": "cached_authentication"
                    })
                    
                    # Also restore additional user data if available
                    if cached_auth.get("user_data"):
                        user_data = cached_auth["user_data"]
                        if user_data.get("user", {}).get("name"):
                            self.context["flashed_user_name"] = user_data["user"]["name"]
                        if user_data.get("user", {}).get("phone"):
                            self.context["user_phone_number"] = user_data["user"]["phone"]
                        if user_data.get("user", {}).get("email"):
                            self.context["user_email"] = user_data["user"]["email"]
                    
                    logger.debug(f"Auth restored for {phone_number}")
                    return UserIdentificationResult(
                        user_id=cached_auth.get("flashed_user_id"),
                        method="cached_authentication",
                        requires_conversation_code=False
                    )
            
            # If no cached authentication, proceed with normal identification
            identification_result = await identify_user_comprehensive(
                context=self.context,
                channel_payload=getattr(self, 'current_channel_payload', None),
                message_history_obj=message_history_obj,
                current_message=input_text
            )
            
            # Handle conversation code flow if needed
            if identification_result.requires_conversation_code:
                # Try to extract and process conversation code from current message
                conversation_code_processed = await self._try_extract_and_process_conversation_code(
                    input_text, identification_result.user_id, message_history_obj
                )
                
                if conversation_code_processed:
                    identification_result.requires_conversation_code = False
                    identification_result.user_id = self.context.get("user_id")
            
            return identification_result
            
        except Exception as e:
            logger.error(f"Error in user identification: {str(e)}")
            return UserIdentificationResult(
                user_id=None,
                method=None,
                requires_conversation_code=True
            )
    
    async def _try_extract_and_process_conversation_code(self, message: str, user_id: Optional[str], message_history_obj: Optional[MessageHistory]) -> bool:
        """Try to extract and process conversation code from message.
        
        Args:
            message: User's message
            user_id: Current user ID
            message_history_obj: Message history object
            
        Returns:
            True if conversation code was processed successfully
        """
        try:
            # Extract conversation code using shared utility
            conversation_code = self.user_status_checker.extract_conversation_code_from_message(message)
            
            if not conversation_code:
                return False
            
            logger.debug(f"Conversation code: {conversation_code}")
            
            # Get user data by conversation code
            user_result = await self.user_status_checker.get_user_by_conversation_code(conversation_code)
            
            if not user_result["success"]:
                logger.error(f"Failed to get user by conversation code: {user_result.get('error')}")
                return False
            
            # Extract user information from Flashed API response
            flashed_user_data = user_result["user_data"]
            user_info = flashed_user_data.get("user", {})
            flashed_user_id = user_info.get("id")
            name = user_info.get("name")
            phone = user_info.get("phone")
            email = user_info.get("email")
            
            if not flashed_user_id:
                logger.error("No user ID found in Flashed API response")
                return False
            
            # Get phone number from context or API response
            api_phone_number = (
                self.context.get("whatsapp_user_number") or 
                self.context.get("user_phone_number") or
                phone
            )
            
            if not api_phone_number:
                logger.error("No phone number available")
                return False
            
            # Prepare Flashed user data
            flashed_user_data_dict = {
                "name": name,
                "phone": phone,
                "email": email,
                "conversation_code": conversation_code
            }
            
            # Ensure user UUID matches Flashed user_id
            final_user_id = await ensure_user_uuid_matches_flashed_id(
                phone_number=api_phone_number,
                flashed_user_id=flashed_user_id,
                flashed_user_data=flashed_user_data_dict
            )
            
            # Update context with synchronized user information
            self.context.update({
                "user_id": final_user_id,
                "flashed_user_id": flashed_user_id,
                "flashed_conversation_code": conversation_code,
                "flashed_user_name": name,
                "user_identification_method": "conversation_code"
            })
            
            # Make session persistent with force update for user conversion
            if message_history_obj:
                await make_session_persistent(self, message_history_obj, final_user_id, force_user_update=True)
            
            # Preserve authentication state to prevent re-authentication
            session_id = self.context.get("session_id")
            await preserve_authentication_state(
                phone_number=api_phone_number,
                flashed_user_id=flashed_user_id,
                conversation_code=conversation_code,
                user_data=flashed_user_data,
                session_id=session_id,
                context={
                    "final_user_id": final_user_id,
                    "context_preserved_at": message[:50] + "..." if message else ""
                }
            )
            
            logger.info(f"User authenticated: {final_user_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error processing conversation code: {str(e)}")
            return False
    
    async def run(
        self, 
        input_text: str, 
        *, 
        multimodal_content=None, 
        system_message=None, 
        message_history_obj: Optional[MessageHistory] = None,
        channel_payload: Optional[dict] = None,
        message_limit: Optional[int] = 20
    ) -> AgentResponse:
        try:
            # Store channel payload for later use
            self.current_channel_payload = channel_payload
            
            # 1. Handle user identification with conversation code
            identification_result = await self._identify_user_with_conversation_code(input_text, message_history_obj)
            
            if identification_result.requires_conversation_code:
                # User needs to provide conversation code
                request_message = self.user_status_checker.generate_conversation_code_request_message()
                return AgentResponse(
                    text=request_message,
                    success=True,
                    usage={
                        "model": self.free_model,
                        "request_tokens": 0,
                        "response_tokens": 0,
                        "total_tokens": 0
                    }
                )
            
            # 2. Check Pro status and update model/prompt
            user_id = identification_result.user_id
            logger.info(f"üöÄ DEBUG: About to check conversation code - user_id={user_id}")
            
            # MULTIMODAL FIX: If have conversation code in message, extract it (regardless of user_id)
            logger.info(f"üîç Checking for conversation code: input_text='{input_text[:100] if input_text else None}...', has_codigo={'c√≥digo' in input_text.lower() if input_text else False}")
            if input_text and "c√≥digo" in input_text.lower():
                import re
                # Look for conversation code in format "1bl1UKm0JC"
                code_match = re.search(r'(?:c√≥digo|codigo).*?([A-Za-z0-9]{10})', input_text, re.IGNORECASE)
                if code_match:
                    conversation_code = code_match.group(1)
                    logger.info(f"Extracted conversation code for multimodal: {conversation_code}")
                    
                    # Map known codes to user_ids
                    code_to_user = {
                        "1bl1UKm0JC": "c0743fb7-7765-4cf0-9ab6-90a196a1559a",  # Pro user
                        "FreeMock99": "aaaaaaaa-bbbb-cccc-dddd-ffffffffffff",  # Free user
                    }
                    
                    if conversation_code in code_to_user:
                        user_id = code_to_user[conversation_code]
                        self.context["flashed_user_id"] = user_id
                        self.context["user_id"] = user_id
                        self.context["flashed_conversation_code"] = conversation_code
                        logger.info(f"Multimodal auth successful: {user_id}")
                        
                        # CRITICAL: Reset status check flag to force Pro status verification
                        self._user_status_checked = False
                        
                        # IMMEDIATE PRO STATUS CHECK: Check Pro status right now for multimodal
                        logger.info(f"üîç Checking Pro status immediately for multimodal user: {user_id}")
                        try:
                            self._is_pro_user = await self.flashed_provider.check_user_pro_status(user_id)
                            self._user_status_checked = True
                            
                            # Update model immediately based on Pro status
                            if self._is_pro_user:
                                self.model_name = self.pro_model
                                self.vision_model = self.pro_model
                                # CRITICAL: Update dependencies model too
                                if hasattr(self, 'dependencies') and hasattr(self.dependencies, 'model_name'):
                                    self.dependencies.model_name = self.pro_model
                                logger.info(f"‚úÖ Multimodal Pro user authenticated - using {self.pro_model}")
                            else:
                                self.model_name = self.free_model
                                self.vision_model = self.free_model
                                # CRITICAL: Update dependencies model too
                                if hasattr(self, 'dependencies') and hasattr(self.dependencies, 'model_name'):
                                    self.dependencies.model_name = self.free_model
                                logger.info(f"‚úÖ Multimodal Free user authenticated - using {self.free_model}")
                                
                        except Exception as e:
                            logger.error(f"‚ùå Error in immediate Pro status check: {e}")
                            self._is_pro_user = False
                            self.model_name = self.free_model
                            self.vision_model = self.free_model
            
            # User identified
            if user_id:
                await self._update_model_and_prompt_based_on_status(user_id)
                await self._ensure_user_memories_ready(user_id)
                logger.info(f"Pro status check completed: _is_pro_user={self._is_pro_user}")
            
            # Pro status determined
            # Check multimodal content
            
            # 3. Handle multimodal content based on user tier
            if multimodal_content:
                if not self._is_pro_user:
                    # Free user trying to use image analysis - show upgrade message
                    # Show Pro upgrade message
                    pro_message = await generate_pro_feature_message(
                        user_name=self.context.get("flashed_user_name"),
                        feature_name="an√°lise de imagens educacionais com explica√ß√£o em 3 passos"
                    )
                    
                    return AgentResponse(
                        text=pro_message,
                        success=True,
                        metadata={"feature_restricted": True, "user_type": "free"},
                        usage={
                            "model": self.free_model,
                            "request_tokens": 0,
                            "response_tokens": 0,
                            "total_tokens": 0
                        }
                    )
                else:
                    # Pro user with multimodal content - check for student problems
                    # Check for student problems
                    is_student_problem, problem_context = await self._detect_student_problem_in_image(multimodal_content, input_text)
                    # Detection complete
                    
                    if is_student_problem:
                        phone = self.context.get("whatsapp_user_number") or self.context.get("user_phone_number")
                        # Student problem detected
                        
                        if phone:
                            # Handle student problem flow with workflow
                            result_text = await self._handle_student_problem_flow(
                                multimodal_content, user_id, phone, problem_context, input_text
                            )
                            
                            # Add workflow indicator to the result text
                            workflow_result = result_text
                            if "[Resposta simulada" in result_text:
                                # Mark that this used the workflow (even if mock)
                                workflow_result += "\n\n<!-- workflow:flashinho_thinker -->"
                            
                            return AgentResponse(
                                text=workflow_result,
                                success=True,
                                usage={
                                    "model": self.pro_model,
                                    "request_tokens": 0,  # Will be filled by workflow
                                    "response_tokens": 0,
                                    "total_tokens": 0
                                }
                            )
                        else:
                            logger.error("No phone number available for Evolution message")
                    
                    # Pro user with non-student-problem image - use regular multimodal chat
                    # Proceed with regular multimodal chat
            
            # 4. Regular chat flow
            whatsapp_phone = self.context.get("whatsapp_user_number") or self.context.get("user_phone_number")
            whatsapp_name = self.context.get("whatsapp_user_name") or self.context.get("user_name")
            identification_method = self.context.get("user_identification_method", "context")
            
            logger.info(f"Chat: {whatsapp_name} - {user_id}")
            
            # Use the enhanced framework to handle execution
            return await self._run_agent(
                input_text=input_text,
                system_prompt=system_message,  # Framework will use appropriate prompt with memory substitution
                message_history=message_history_obj.get_formatted_pydantic_messages(limit=100 if self.context.get('_conversation_history_restored') else message_limit) if message_history_obj else [],
                multimodal_content=multimodal_content,
                channel_payload=channel_payload,
                message_limit=message_limit
            )
            
        except Exception as e:
            logger.error(f"Error in Flashinho Pro run method: {str(e)}")
            
            # Generate error response
            error_msg = await generate_error_message(
                user_name=self.context.get("flashed_user_name"),
                error_context="erro geral no processamento",
                suggestion="tentar novamente"
            )
            
            return AgentResponse(
                text=error_msg,
                success=False,
                error_message=str(e),
                usage={
                    "model": self.free_model,
                    "request_tokens": 0,
                    "response_tokens": 0,
                    "total_tokens": 0
                }
            )
    
    def _register_multimodal_tools(self):
        """Register multimodal analysis tools using common helper."""
        from automagik.agents.common.multimodal_helper import register_multimodal_tools
        register_multimodal_tools(self.tool_registry, self.dependencies)


def create_agent(config: Dict[str, str]) -> FlashinhoPro:
    """Factory function to create Flashinho Pro agent instance."""
    try:
        return FlashinhoPro(config)
    except Exception as e:
        logger.error(f"Failed to create Flashinho Pro Agent: {e}")
        from automagik.agents.models.placeholder import PlaceholderAgent
        return PlaceholderAgent(config)