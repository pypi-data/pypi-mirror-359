{
    "altids": {
        "itemid": "f63d7fcc4b361cf8073406bf231e2b92",
        "etag": "f63d7fcc4b361cf8073406bf231e2b92_1a18aza0c0",
        "friendlykey": "598827804675",
        "referenceid": "US-MED--Doctors-Artificial Intelligence"
    },
    "version": 1,
    "type": "text",
    "urgency": 4,
    "profile": "Spot Development",
    "language": "en",
    "versioncreated": "2024-03-13T14:43:59Z",
    "firstcreated": "2024-03-12T20:31:15Z",
    "editorialrole": "FullStory",
    "pubstatus": "usable",
    "ednote": "Eds: UPDATES: Adds role and affiliation of Dr. Lauren Bruckner.",
    "editorialtypes": [
        "Lead"
    ],
    "signals": [
        "newscontent"
    ],
    "title": "US-MED--Doctors-Artificial Intelligence",
    "headline": "New AI tools can record your medical appointment or draft a message from your doctor",
    "headline_extended": "New artificial intelligence tools are helping doctors communicate with their patients",
    "slugline": "BC-US-MED-Doctors-Artificial-Intelligence, 1st Ld-Writethru",
    "description_summary": "New artificial intelligence tools are helping doctors communicate with their patients. Some tools answer messages and others take notes during exams. It\u2019s been just 15 months since OpenAI released ChatGPT. Already thousands of doctors are using products based on similar large language models. Enthusiasts say these AI tools save doctors\u2019 time and prevent burnout. They\u2019re also shaking up the doctor-patient relationship, raising questions of trust, transparency, privacy and the future of human connection. AI tools can be prompted to be friendly, empathetic and informative. They can also make mistakes, so it's important that the human doctor stay in the loop.",
    "bylines": [
        {
            "by": "By CARLA K. JOHNSON",
            "title": "AP Medical Writer"
        }
    ],
    "copyrightnotice": "Copyright 2024 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.",
    "usageterms": [
        "This content is intended for editorial use only. For other uses, additional clearances may be required."
    ],
    "keywords": [
        "chatgpt ai health doctors microsoft"
    ],
    "provider": "AP",
    "infosource": [
        {
            "name": "AP",
            "type": "AP"
        }
    ],
    "subject": [
        {
            "rels": [
                "category"
            ],
            "creator": "Editorial",
            "code": "f",
            "name": "f"
        },
        {
            "rels": [
                "category"
            ],
            "creator": "Editorial",
            "code": "a",
            "name": "a"
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "7077b3c88b6b10048b67a385cd5ce603",
            "name": "Medical technology",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 66
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "cc7a76087e4e10048482df092526b43e",
            "name": "Health",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 93
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "455ef2b87df7100483d8df092526b43e",
            "name": "Technology",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 86
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "c94763b88b6b10048dc5a385cd5ce603",
            "name": "Artificial intelligence",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 79
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "455ef2b87df7100483d8df092526b43e",
            "name": "Technology",
            "creator": "Editorial",
            "editorial_subject": "Technology",
            "rels": [
                "direct"
            ],
            "relevance": 75
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "cc7a76087e4e10048482df092526b43e",
            "name": "Health",
            "creator": "Editorial",
            "editorial_subject": "Health",
            "rels": [
                "direct"
            ],
            "relevance": 99
        }
    ],
    "place": [
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "902a5eb082af1004828adf092526b43e",
            "name": "Colorado",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "parentids": [
                "661e48387d5b10048291c076b8e3055c"
            ],
            "locationtype": {
                "code": "0ae5eb8e00e04295a4fc209c94bfe6ef",
                "name": "State"
            },
            "geometry_geojson": {
                "type": "Point",
                "coordinates": [
                    -105.50083,
                    39.00027
                ]
            },
            "relevance": 41,
            "parentnames": [
                "United States"
            ]
        }
    ],
    "audiences": [
        {
            "code": "82c6a4c46fa0446090a7acaf93159e4c",
            "name": "Print",
            "type": "AUDPLATFORM"
        },
        {
            "code": "9add4649b53b4702ba7d9de5d4fa607a",
            "name": "Online",
            "type": "AUDPLATFORM"
        },
        {
            "code": "f43adc08760d10048040e6e7a0f4673e",
            "name": "National",
            "type": "AUDSCOPE"
        },
        {
            "code": "f4ecf9b0760d10048044e6e7a0f4673e",
            "name": "International",
            "type": "AUDSCOPE"
        },
        {
            "code": "661850e07d5b100481f5c076b8e3055c",
            "name": "Latin America and Caribbean",
            "type": "AUDGEOGRAPHY"
        },
        {
            "code": "661e48387d5b10048291c076b8e3055c",
            "name": "United States",
            "type": "AUDGEOGRAPHY"
        }
    ],
    "associations": {
        "1": {
            "altids": {
                "itemid": "86a7222f9f1b4c55a1678a68673af435"
            },
            "type": "picture"
        },
        "2": {
            "altids": {
                "itemid": "8b1921eed7ab49819ed59972201ee1d6"
            },
            "type": "picture"
        }
    },
    "body_nitf": "<p>Don\u2019t be surprised if your doctors start writing you overly friendly messages. They could be getting some help from <a href=\"https://apnews.com/hub/artificial-intelligence\">artificial intelligence</a>.</p><p>New AI tools are helping doctors communicate with their patients, some by answering messages and others by taking notes during exams. It's been 15 months since OpenAI released ChatGPT. Already thousands of doctors are using similar products based on large language models. One company says its tool works in 14 languages.</p><p>AI saves doctors time and prevents burnout, enthusiasts say. It also shakes up the doctor-patient relationship, raising questions of trust, transparency, privacy and the future of human connection.</p><p>A look at how new AI tools affect patients:</p><p>IS MY DOCTOR USING AI?</p><p>In recent years, medical devices with machine learning have been doing things like reading mammograms, diagnosing eye disease and detecting heart problems. What's new is generative AI's ability to respond to complex instructions by <a href=\"https://apnews.com/article/technology-artificial-intelligence-1a652de47c2d0e502c2896748d9d1d5f\">predicting language</a>.</p><p>Your next check-up could be recorded by an AI-powered smartphone app that listens, documents and instantly organizes everything into a note you can read later. The tool also can mean more money for the doctor\u2019s employer because it won\u2019t forget details that legitimately could be billed to insurance.</p><p>Your doctor should ask for your consent before using the tool. You might also see some new wording in the forms you sign at the doctor\u2019s office.</p><p>Other AI tools could be helping your doctor draft a message, but you might never know it.</p><p>\u201cYour physician might tell you that they\u2019re using it, or they might not tell you,\u201d said Cait DesRoches, director of OpenNotes, a Boston-based group working for transparent communication between doctors and patients. Some health systems encourage disclosure, and some don\u2019t.</p><p>Doctors or nurses must approve the AI-generated messages before sending them. In one Colorado health system, such messages contain a sentence disclosing they were automatically generated. But doctors can delete that line.</p><p>\u201cIt sounded exactly like him. It was remarkable,\u201d said patient Tom Detner, 70, of Denver, who recently received an AI-generated message that began: \u201cHello, Tom, I\u2019m glad to hear that your neck pain is improving. It\u2019s important to listen to your body.\u201d The message ended with \u201cTake care\u201d and a disclosure that it had been automatically generated and edited by his doctor.</p><p>Detner said he was glad for the transparency. \u201cFull disclosure is very important,\u201d he said.</p><p>WILL AI MAKE MISTAKES?</p><p>Large language models can misinterpret input or even fabricate inaccurate responses, an effect called <a href=\"https://apnews.com/article/artificial-intelligence-hallucination-chatbots-chatgpt-falsehoods-ac4672c5b06e6f91050aa46ee731bcf4\">hallucination</a>. The new tools have internal guardrails to try to prevent inaccuracies from reaching patients \u2014 or landing in electronic health records.</p><p>\u201cYou don\u2019t want those fake things entering the clinical notes,\u201d said Dr. Alistair Erskine, who leads digital innovations for Georgia-based Emory Healthcare, where hundreds of doctors are using a product from Abridge to document patient visits.</p><p>The tool runs the doctor-patient conversation across several large language models and eliminates weird ideas, Erskine said. \u201cIt\u2019s a way of engineering out hallucinations.\u201d</p><p>Ultimately, \u201cthe doctor is the most important guardrail,\u201d said Abridge CEO Dr. Shiv Rao. As doctors review AI-generated notes, they can click on any word and listen to the specific segment of the patient\u2019s visit to check accuracy.</p><p>In Buffalo, New York, a different AI tool misheard Dr. Lauren Bruckner when she told a teenage cancer patient it was a good thing she didn't have an allergy to sulfa drugs. The AI-generated note said, \u201cAllergies: Sulfa.\u201d</p><p>The tool \u201ctotally misunderstood the conversation,\u201d said Bruckner, chief medical information officer at Roswell Park Comprehensive Cancer Center. \u201cThat doesn\u2019t happen often, but clearly that's a problem.\u201d</p><p>WHAT ABOUT THE HUMAN TOUCH?</p><p>AI tools can be prompted to be friendly, empathetic and informative.</p><p>But they can get carried away. In Colorado, a patient with a runny nose was alarmed to learn from an AI-generated message that the problem could be a brain fluid leak. (It wasn\u2019t.) A nurse hadn\u2019t proofread carefully and mistakenly sent the message.</p><p>\u201cAt times, it\u2019s an astounding help and at times it\u2019s of no help at all,\u201d said Dr. C.T. Lin, who leads technology innovations at Colorado-based UC Health, where about 250 doctors and staff use a Microsoft AI tool to write the first draft of messages to patients. The messages are delivered through Epic\u2019s patient portal.</p><p>The tool had to be taught about a new RSV vaccine because it was drafting messages saying there was no such thing. But with routine advice \u2014 like rest, ice, compression and elevation for an ankle sprain \u2014 \u201cit\u2019s beautiful for that,\u201d Linn said.</p><p>Also on the plus side, doctors using AI are no longer tied to their computers during medical appointments. They can make eye contact with their patients because the AI tool records the exam.</p><p>The tool needs audible words, so doctors are learning to explain things aloud, said Dr. Robert Bart, chief medical information officer at Pittsburgh-based UPMC. A doctor might say: \u201cI am currently examining the right elbow. It is quite swollen. It feels like there\u2019s fluid in the right elbow.\u201d</p><p>Talking through the exam for the benefit of the AI tool can also help patients understand what's going on, Bart said. \u201cI\u2019ve been in an examination where you hear the hemming and hawing while the physician is doing it. And I\u2019m always wondering, \u2018Well, what does that mean?\u2019\u201d</p><p>WHAT ABOUT PRIVACY?</p><p>U.S. law requires health care systems to get assurances from business associates that they will safeguard protected health information, and the companies could face <a href=\"https://www.hhs.gov/hipaa/for-professionals/compliance-enforcement/data/enforcement-highlights/index.html\">investigation and fines</a> from the Department of Health and Human Services if they mess up.</p><p>Doctors interviewed for this article said they feel confident in the data security of the new products and that the information will not be sold.</p><p>Information shared with the new tools is used to improve them, so that could add to the risk of a health care data breach.</p><p>Dr. Lance Owens is chief medical information officer at the University of Michigan Health-West, where 265 doctors, physician assistants and nurse practitioners are using a Microsoft tool to document patient exams. He believes patient data is being protected.</p><p>\u201cWhen they tell us that our data is safe and secure and segregated, we believe that,\u201d Owens said.</p><p>___</p><p>The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute\u2019s Science and Educational Media Group. The AP is solely responsible for all content.</p>",
    "textformat": "bx",
    "links": [
        {
            "href": "https://apnews.com/article/chatgpt-ai-health-doctors-microsoft-f63d7fcc4b361cf8073406bf231e2b92",
            "rel": "canonical"
        }
    ],
    "topics": {
        "Health": {
            "relevance_score": 5,
            "reason": "The document discusses the use of new AI tools in the medical field, specifically how they assist doctors in communicating with patients, taking notes during exams, and drafting messages. It also addresses the implications of AI on doctor-patient relationships, potential errors, and privacy concerns. These topics are directly related to health as they impact medical practices, patient care, and healthcare data security."
        }
    }
}