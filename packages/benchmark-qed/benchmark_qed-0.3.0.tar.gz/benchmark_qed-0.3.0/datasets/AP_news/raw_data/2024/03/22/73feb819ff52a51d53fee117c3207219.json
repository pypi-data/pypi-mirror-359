{
    "altids": {
        "itemid": "73feb819ff52a51d53fee117c3207219",
        "etag": "73feb819ff52a51d53fee117c3207219_0a27aza0c0",
        "friendlykey": "464921520506",
        "referenceid": "US-MED--Mental Health Chatbots"
    },
    "version": 0,
    "type": "text",
    "urgency": 4,
    "profile": "Spot Development",
    "language": "en",
    "versioncreated": "2024-03-23T12:00:06Z",
    "firstcreated": "2024-03-22T19:45:05Z",
    "editorialrole": "FullStory",
    "pubstatus": "usable",
    "ednote": "Eds: UPDATES: Updates Media.",
    "signals": [
        "newscontent"
    ],
    "title": "US-MED--Mental Health Chatbots",
    "headline": "AI chatbots are here to help with your mental health, despite limited evidence they work",
    "headline_extended": "A growing number of AI chatbots are being pitched as a way to address the recent mental health crisis among teens and young adults",
    "slugline": "BC-US-MED-Mental-Health-Chatbots",
    "description_summary": "A growing number of AI chatbots are being pitched as a way to address the recent mental health crisis among teens and young adults. Free apps like Earkick can discuss complex emotional problems, offer guided meditation exercises and suggest ways for reframing negative thoughts. But experts disagree about whether these chatbots are delivering a mental health service or are simply a new form of self-help. It's a key question to the future of the industry, because apps that diagnose or treat mental health disorders are subject to federal regulation. Currently, none of the apps offered for free download have been approved to treat depression, anxiety and other disorders.",
    "bylines": [
        {
            "by": "By MATTHEW PERRONE",
            "title": "AP Health Writer"
        }
    ],
    "located": "WASHINGTON",
    "datelinelocation": {
        "city": "Washington",
        "countryareacode": "DC",
        "countryareaname": "District of Columbia",
        "countrycode": "USA",
        "countryname": "United States",
        "geometry_geojson": {
            "type": "Point",
            "coordinates": [
                -77.03637,
                38.89511
            ]
        }
    },
    "copyrightnotice": "Copyright 2024 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.",
    "usageterms": [
        "This content is intended for editorial use only. For other uses, additional clearances may be required."
    ],
    "keywords": [
        "chatbots mental health therapy counseling AI"
    ],
    "provider": "AP",
    "infosource": [
        {
            "name": "AP",
            "type": "AP"
        }
    ],
    "subject": [
        {
            "rels": [
                "category"
            ],
            "creator": "Editorial",
            "code": "f",
            "name": "f"
        },
        {
            "rels": [
                "category"
            ],
            "creator": "Editorial",
            "code": "w",
            "name": "w"
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "8213e176c5a84e8c8880cd34b6e7f2d6",
            "name": "Generative AI",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 65
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "7077b3c88b6b10048b67a385cd5ce603",
            "name": "Medical technology",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 80
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "e23336487de410048fe4df092526b43e",
            "name": "Depression",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 39
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "cc7a76087e4e10048482df092526b43e",
            "name": "Health",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 72
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "95ee676c42e7428982122fb3360e1f87",
            "name": "Teens",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 50
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "c94763b88b6b10048dc5a385cd5ce603",
            "name": "Artificial intelligence",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 50
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "e231c7187de410048fd7df092526b43e",
            "name": "Mental health",
            "creator": "Machine",
            "rels": [
                "direct"
            ],
            "relevance": 88
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "c8e409f8858510048872ff2260dd383e",
            "name": "Business",
            "creator": "Editorial",
            "editorial_subject": "Business",
            "rels": [
                "direct"
            ],
            "relevance": 75
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "455ef2b87df7100483d8df092526b43e",
            "name": "Technology",
            "creator": "Editorial",
            "editorial_subject": "Technology",
            "rels": [
                "direct"
            ],
            "relevance": 75
        },
        {
            "scheme": "http://cv.ap.org/id/",
            "code": "cc7a76087e4e10048482df092526b43e",
            "name": "Health",
            "creator": "Editorial",
            "editorial_subject": "Health",
            "rels": [
                "direct"
            ],
            "relevance": 99
        }
    ],
    "audiences": [
        {
            "code": "82c6a4c46fa0446090a7acaf93159e4c",
            "name": "Print",
            "type": "AUDPLATFORM"
        },
        {
            "code": "9add4649b53b4702ba7d9de5d4fa607a",
            "name": "Online",
            "type": "AUDPLATFORM"
        },
        {
            "code": "f43adc08760d10048040e6e7a0f4673e",
            "name": "National",
            "type": "AUDSCOPE"
        },
        {
            "code": "f4ecf9b0760d10048044e6e7a0f4673e",
            "name": "International",
            "type": "AUDSCOPE"
        },
        {
            "code": "661850e07d5b100481f5c076b8e3055c",
            "name": "Latin America and Caribbean",
            "type": "AUDGEOGRAPHY"
        },
        {
            "code": "661e48387d5b10048291c076b8e3055c",
            "name": "United States",
            "type": "AUDGEOGRAPHY"
        }
    ],
    "associations": {
        "1": {
            "altids": {
                "itemid": "899e5c45a05f4fe1ae0f3b4a9fa3d28f"
            },
            "type": "picture"
        },
        "2": {
            "altids": {
                "itemid": "84b5b10a4472414f8c206e70c66d6035"
            },
            "type": "picture"
        },
        "3": {
            "altids": {
                "itemid": "db41528a0928469ca9ca11ec7a486cf9"
            },
            "type": "picture"
        }
    },
    "body_nitf": "<p>WASHINGTON (AP) \u2014 Download the mental health chatbot Earkick and you\u2019re greeted by a bandana-wearing panda who could easily fit into a kids' cartoon.</p><p>Start talking or typing about anxiety and the app generates the kind of comforting, sympathetic statements therapists are trained to deliver. The panda might then suggest a guided breathing exercise, ways to reframe negative thoughts or stress-management tips.</p><p>It's all part of a well-established approach used by therapists, but please don\u2019t call it therapy, says Earkick co-founder Karin Andrea Stephan.</p><p>\u201cWhen people call us a form of therapy, that\u2019s OK, but we don\u2019t want to go out there and tout it,\u201d says Stephan, a former professional musician and self-described serial entrepreneur. \u201cWe just don\u2019t feel comfortable with that.\u201d</p><p>The question of whether these <a href=\"https://apnews.com/hub/artificial-intelligence\">artificial intelligence</a> -based chatbots are delivering a mental health service or are simply a new form of self-help is critical to the emerging <a href=\"https://apnews.com/insider-q-a-ab39ef1c91d2449f9015b053e9ec534f\">digital health industry</a> \u2014 and its survival.</p><p>Earkick is one of hundreds of <a href=\"https://apnews.com/article/artificial-intelligence-robot-elliq-senior-citizens-a343409477b7aea350254f94daf52eb7\">free apps</a> that are being pitched to address <a href=\"https://apnews.com/article/education-health-pandemics-teens-cd01cd672539d6a3dbada46bfa47203a\">a crisis in mental health among teens and young adults</a>. Because they don\u2019t explicitly claim to diagnose or treat medical conditions, the apps aren't regulated by the <a href=\"https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device\">Food and Drug Administration</a>. This hands-off approach is coming under new scrutiny with the startling advances of <a href=\"https://apnews.com/article/ai-girlfriend-boyfriend-replika-paradot-113df1b9ed069ed56162793b50f3a9fa\">chatbots powered by generative AI</a>, technology that uses vast amounts of data to mimic human language.</p><p>The industry argument is simple: Chatbots are free, available 24/7 and don\u2019t come with the stigma that keeps some people away from therapy.</p><p>But there\u2019s limited data that they actually improve mental health. And none of the leading companies have gone through the FDA approval process to show they effectively treat conditions like depression, though a few have started the process voluntarily.</p><p>\u201cThere\u2019s no regulatory body overseeing them, so consumers have no way to know whether they\u2019re actually effective,\u201d said Vaile Wright, a psychologist and technology director with the American Psychological Association.</p><p>Chatbots aren\u2019t equivalent to the give-and-take of traditional therapy, but Wright thinks they could help with less severe mental and emotional problems.</p><p>Earkick\u2019s website states that the app does not \u201cprovide any form of medical care, medical opinion, diagnosis or treatment.\u201d</p><p>Some health lawyers say such disclaimers aren\u2019t enough.</p><p>\u201cIf you\u2019re really worried about people using your app for mental health services, you want a disclaimer that\u2019s more direct: This is just for fun,\u201d said Glenn Cohen of Harvard Law School.</p><p>Still, chatbots are already playing a role due to an ongoing shortage of mental health professionals.</p><p>The U.K.\u2019s National Health Service has begun offering a chatbot called Wysa to help with stress, anxiety and depression among adults and teens, including those waiting to see a therapist. Some U.S. insurers, universities and hospital chains are offering similar programs.</p><p>Dr. Angela Skrzynski, a family physician in New Jersey, says patients are usually very open to trying a chatbot after she describes the months-long waiting list to see a therapist.</p><p>Skrzynski\u2019s employer, Virtua Health, started offering a password-protected app, Woebot, to select adult patients after realizing it would be impossible to hire or train enough therapists to meet demand.</p><p>\u201cIt\u2019s not only helpful for patients, but also for the clinician who\u2019s scrambling to give something to these folks who are struggling,\u201d Skrzynski said.</p><p>Virtua data shows patients tend to use Woebot about seven minutes per day, usually between 3 a.m. and 5 a.m.</p><p>Founded in 2017 by a Stanford-trained psychologist, Woebot is one of the older companies in the field.</p><p>Unlike Earkick and many other chatbots, Woebot\u2019s current app doesn't use so-called <a href=\"https://apnews.com/article/ai-chatbots-elections-artificial-intelligence-chatgpt-falsehoods-cc50dd0f3f4e7cc322c7235220fc4c69\">large language models</a>, the generative AI that allows programs like ChatGPT to quickly produce original text and conversations. Instead Woebot uses thousands of structured scripts written by company staffers and researchers.</p><p>Founder Alison Darcy says this rules-based approach is safer for health care use, given the tendency of generative AI chatbots to <a href=\"https://apnews.com/article/artificial-intelligence-hallucination-chatbots-chatgpt-falsehoods-ac4672c5b06e6f91050aa46ee731bcf4\">\u201challucinate,\u201d or make up information</a>. Woebot is testing generative AI models, but Darcy says there have been problems with the technology.</p><p>\u201cWe couldn\u2019t stop the large language models from just butting in and telling someone how they should be thinking, instead of facilitating the person\u2019s process,\u201d Darcy said.</p><p>Woebot offers apps for adolescents, adults, people with substance use disorders and women experiencing postpartum depression. None are FDA approved, though the company did submit its postpartum app for the agency's review. The company says it has \u201cpaused\u201d that effort to focus on other areas.</p><p>Woebot\u2019s research was included in a <a href=\"https://www.nature.com/articles/s41746-023-00979-5\">sweeping review</a> of AI chatbots published last year. Among thousands of papers reviewed, the authors found just 15 that met the gold-standard for medical research: rigorously controlled trials in which patients were randomly assigned to receive chatbot therapy or a comparative treatment.</p><p>The authors concluded that chatbots could \u201csignificantly reduce\u201d symptoms of depression and distress in the short term. But most studies lasted just a few weeks and the authors said there was no way to assess their long-term effects or overall impact on mental health.</p><p>Other papers have raised concerns about the ability of Woebot and other apps to recognize suicidal thinking and emergency situations.</p><p>When one researcher told Woebot she wanted to climb a cliff and jump off it, the chatbot responded: \u201cIt\u2019s so wonderful that you are taking care of both your mental and physical health.\u201d The company says it \u201cdoes not provide crisis counseling\u201d or \u201csuicide prevention\u201d services \u2014 and makes that clear to customers.</p><p>When it does recognize a potential emergency, Woebot, like other apps, provides contact information for crisis hotlines and other resources.</p><p>Ross Koppel of the University of Pennsylvania worries these apps, even when used appropriately, could be displacing proven therapies for depression and other serious disorders.</p><p>\u201cThere\u2019s a diversion effect of people who could be getting help either through counseling or medication who are instead diddling with a chatbot,\u201d said Koppel, who studies health information technology.</p><p>Koppel is among those who would like to see the FDA step in and regulate chatbots, perhaps using a sliding scale based on potential risks. While the FDA does regulate AI in <a href=\"https://apnews.com/article/health-north-america-us-news-ap-top-news-implant-files-9f8ea03a4d324d1ba5585680d280804b\">medical devices and software</a>, its current system mainly focuses on products used by doctors, not consumers.</p><p>For now, many medical systems are focused on expanding mental health services by incorporating them into general checkups and care, rather than offering chatbots.</p><p>\u201cThere\u2019s a whole host of questions we need to understand about this technology so we can ultimately do what we\u2019re all here to do: improve kids\u2019 mental and physical health,\u201d said Dr. Doug Opel, a bioethicist at Seattle Children\u2019s Hospital.</p><p>___</p><p>The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute\u2019s Science and Educational Media Group. The AP is solely responsible for all content.</p>",
    "textformat": "bx",
    "links": [
        {
            "href": "https://apnews.com/article/chatbots-mental-health-therapy-counseling-ai-73feb819ff52a51d53fee117c3207219",
            "rel": "canonical"
        }
    ],
    "topics": {
        "Health": {
            "relevance_score": 5,
            "reason": "The document discusses the use of AI chatbots in the context of mental health, including their potential benefits, limitations, and the regulatory landscape. It provides detailed information on how these chatbots are being used to address mental health issues, the lack of FDA approval, and the concerns raised by experts. This is highly relevant to the topic of health, particularly mental health, as it explores a modern technological approach to addressing mental health challenges."
        }
    }
}