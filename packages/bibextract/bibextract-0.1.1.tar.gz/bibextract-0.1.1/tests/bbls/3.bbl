% Generated by IEEEtranN.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranN.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, ichter, Xia, Chi, Le, and Zhou]{wei2022chain}
J.~Wei, X.~Wang, D.~Schuurmans, M.~Bosma, b.~ichter, F.~Xia \emph{et~al.}, ``Chain-of-thought prompting elicits reasoning in large language models,'' in \emph{Advances in Neural Information Processing Systems}, vol.~35, 2022, pp. 24\,824--24\,837.

\bibitem[Kojima et~al.(2022)Kojima, Gu, Reid, Matsuo, and Iwasawa]{kojima2022large}
T.~Kojima, S.~S. Gu, M.~Reid, Y.~Matsuo, and Y.~Iwasawa, ``Large language models are zero-shot reasoners,'' in \emph{Advances in Neural Information Processing Systems}, vol.~35, 2022, pp. 22\,199--22\,213.

\bibitem[Yao et~al.(2023)Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{shunyu2024tree}
S.~Yao, D.~Yu, J.~Zhao, I.~Shafran, T.~Griffiths, Y.~Cao, and K.~Narasimhan, ``Tree of thoughts: Deliberate problem solving with large language models,'' in \emph{Advances in Neural Information Processing Systems}, vol.~36, 2023, pp. 11\,809--11\,822.

\bibitem[Besta et~al.(2024)Besta, Blach, Kubicek, Gerstenberger, Podstawski, Gianinazzi, Gajda, Lehmann, Niewiadomski, Nyczyk, and Hoefler]{besta2024graph}
M.~Besta, N.~Blach, A.~Kubicek, R.~Gerstenberger, M.~Podstawski, L.~Gianinazzi \emph{et~al.}, ``Graph of thoughts: Solving elaborate problems with large language models,'' \emph{Proc. of the AAAI Conf. on Artificial Intelligence}, vol.~38, no.~16, pp. 17\,682--17\,690, Mar. 2024.

\bibitem[Huang et~al.(2022)Huang, Abbeel, Pathak, and Mordatch]{huang22a}
W.~Huang, P.~Abbeel, D.~Pathak, and I.~Mordatch, ``Language models as zero-shot planners: Extracting actionable knowledge for embodied agents,'' in \emph{Proc. of the 39th Int. Conf. on Machine Learning}, vol. 162, 17--23 Jul 2022, pp. 9118--9147.

\bibitem[Ichter et~al.(2023)Ichter, Brohan, Chebotar, Finn, Hausman, Herzog, Ho, Ibarz, Irpan, Jang, Julian, Kalashnikov, Levine, Lu, Parada, Rao, Sermanet, Toshev, Vanhoucke, Xia, Xiao, Xu, Yan, Brown, Ahn, Cortes, Sievers, Tan, Xu, Reyes, Rettinghouse, Quiambao, Pastor, Luu, Lee, Kuang, Jesmonth, Joshi, Jeffrey, Ruano, Hsu, Gopalakrishnan, David, Zeng, and Fu]{ichter23a}
B.~Ichter, A.~Brohan, Y.~Chebotar, C.~Finn, K.~Hausman, A.~Herzog \emph{et~al.}, ``Do as i can, not as i say: Grounding language in robotic affordances,'' in \emph{Proc. of The 6th Conf. on Robot Learning}, vol. 205, 14--18 Dec 2023, pp. 287--318.

\bibitem[Huang et~al.(2023)Huang, Xia, Xiao, Chan, Liang, Florence, Zeng, Tompson, Mordatch, Chebotar, Sermanet, Jackson, Brown, Luu, Levine, Hausman, and ichter]{huang23c}
W.~Huang, F.~Xia, T.~Xiao, H.~Chan, J.~Liang, P.~Florence \emph{et~al.}, ``Inner monologue: Embodied reasoning through planning with language models,'' in \emph{Proc. of The 6th Conf. on Robot Learning}, vol. 205, 14--18 Dec 2023, pp. 1769--1782.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Gopinath, Narasimhan, and Yao]{shinn23}
N.~Shinn, F.~Cassano, A.~Gopinath, K.~Narasimhan, and S.~Yao, ``Reflexion: language agents with verbal reinforcement learning,'' in \emph{Advances in Neural Information Processing Systems}, vol.~36, 2023, pp. 8634--8652.

\bibitem[Gou et~al.(2023)Gou, Shao, Gong, Shen, Yang, Duan, and Chen]{2024critic}
Z.~Gou, Z.~Shao, Y.~Gong, Y.~Shen, Y.~Yang, N.~Duan, and W.~Chen, ``Critic: Large language models can self-correct with tool-interactive critiquing,'' \emph{arXiv preprint arXiv:2305.11738}, 2023.

\bibitem[Yao et~al.(2022)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{2023react}
S.~Yao, J.~Zhao, D.~Yu, N.~Du, I.~Shafran, K.~Narasimhan, and Y.~Cao, ``React: Synergizing reasoning and acting in language models,'' \emph{arXiv preprint arXiv:2210.03629}, 2022.

\bibitem[Rana et~al.(2023)Rana, Haviland, Garg, Abou-Chakra, Reid, and Suenderhauf]{rana23a}
K.~Rana, J.~Haviland, S.~Garg, J.~Abou-Chakra, I.~Reid, and N.~Suenderhauf, ``Sayplan: Grounding large language models using 3d scene graphs for scalable robot task planning,'' in \emph{Proc. of The 7th Conf. on Robot Learning}, vol. 229, 06--09 Nov 2023, pp. 23--72.

\bibitem[Hao et~al.(2023)Hao, Gu, Ma, Hong, Wang, Wang, and Hu]{hao2023rap}
S.~Hao, Y.~Gu, H.~Ma, J.~Hong, Z.~Wang, D.~Wang, and Z.~Hu, ``Reasoning with language model is planning with world model,'' in \emph{Proc. of the Conf. on Empirical Methods in Natural Language Processing}, 2023, pp. 8154--8173.

\bibitem[Silver et~al.(2024)Silver, Dan, Srinivas, Tenenbaum, Kaelbling, and Katz]{silver2024}
T.~Silver, S.~Dan, K.~Srinivas, J.~B. Tenenbaum, L.~Kaelbling, and M.~Katz, ``Generalized planning in pddl domains with pretrained large language models,'' \emph{Proc. of the AAAI Conf. on Artificial Intelligence}, vol.~38, no.~18, pp. 20\,256--20\,264, Mar. 2024.

\bibitem[Valmeekam et~al.(2023)Valmeekam, Marquez, Olmo, Sreedharan, and Kambhampati]{valmeekam2023planbench}
K.~Valmeekam, M.~Marquez, A.~Olmo, S.~Sreedharan, and S.~Kambhampati, ``Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, pp. 38\,975--38\,987, 2023.

\bibitem[Kambhampati et~al.(2024)Kambhampati, Valmeekam, Guan, Verma, Stechly, Bhambri, Saldyt, and Murthy]{kambhampati2024}
S.~Kambhampati, K.~Valmeekam, L.~Guan, M.~Verma, K.~Stechly, S.~Bhambri \emph{et~al.}, ``Llms can’t plan, but can help planning in llm-modulo frameworks,'' in \emph{Forty-first Int. Conf. on Machine Learning}, 2024.

\bibitem[Liu et~al.(2023)Liu, Jiang, Zhang, Liu, Zhang, Biswas, and Stone]{liu2023llm+}
B.~Liu, Y.~Jiang, X.~Zhang, Q.~Liu, S.~Zhang, J.~Biswas, and P.~Stone, ``Llm+ p: Empowering large language models with optimal planning proficiency,'' \emph{arXiv preprint arXiv:2304.11477}, 2023.

\bibitem[Dagan et~al.(2023)Dagan, Keller, and Lascarides]{dagan2023}
G.~Dagan, F.~Keller, and A.~Lascarides, ``Dynamic planning with a llm,'' \emph{arXiv preprint arXiv:2308.06391}, 2023.

\bibitem[Guan et~al.(2023)Guan, Valmeekam, Sreedharan, and Kambhampati]{worldmodels2023}
L.~Guan, K.~Valmeekam, S.~Sreedharan, and S.~Kambhampati, ``Leveraging pre-trained large language models to construct and utilize world models for model-based task planning,'' in \emph{Advances in Neural Information Processing Systems}, vol.~36, 2023, pp. 79\,081--79\,094.

\bibitem[Gestrin et~al.(2024)Gestrin, Kuhlmann, and Seipp]{nl2plan}
E.~Gestrin, M.~Kuhlmann, and J.~Seipp, ``Nl2plan: Robust llm-driven planning from minimal text descriptions,'' \emph{CoRR}, 2024.

\bibitem[Zhang et~al.(2024)Zhang, Qin, Wang, Dong, and Li]{lamma-p}
X.~Zhang, H.~Qin, F.~Wang, Y.~Dong, and J.~Li, ``Lamma-p: Generalizable multi-agent long-horizon task allocation and planning with lm-driven pddl planner,'' \emph{arXiv preprint arXiv:2409.20560}, 2024.

\bibitem[Lin et~al.(2024)Lin, Wu, Yang, Zhang, Zhang, and Ji]{clmasp}
X.~Lin, Y.~Wu, H.~Yang, Y.~Zhang, Y.~Zhang, and J.~Ji, ``Clmasp: Coupling large language models with answer set programming for robotic task planning,'' \emph{arXiv preprint arXiv:2406.03367}, 2024.

\bibitem[Yang et~al.(2023)Yang, Ishay, and Lee]{yang2023}
Z.~Yang, A.~Ishay, and J.~Lee, ``Coupling large language models with logic programming for robust and general reasoning from text,'' in \emph{Findings of the Association for Computational Linguistics: ACL}, 2023, pp. 5186--5219.

\bibitem[Chen et~al.(2024)Chen, Arkin, Dawson, Zhang, Roy, and Fan]{autotamp}
Y.~Chen, J.~Arkin, C.~Dawson, Y.~Zhang, N.~Roy, and C.~Fan, ``Autotamp: Autoregressive task and motion planning with llms as translators and checkers,'' in \emph{IEEE Int. Conf. on Robotics and Automation}, 2024, pp. 6695--6702.

\bibitem[Birr et~al.(2024)Birr, Pohl, Younes, and Asfour]{birr24}
T.~Birr, C.~Pohl, A.~Younes, and T.~Asfour, ``{AutoGPT+P: Affordance-based Task Planning using Large Language Models},'' in \emph{Proc. of Robotics: Science and Systems}, Delft, Netherlands, July 2024.

\bibitem[Liu et~al.(2024)Liu, Palmieri, Koch, Georgievski, and Aiello]{liu2024delta}
Y.~Liu, L.~Palmieri, S.~Koch, I.~Georgievski, and M.~Aiello, ``Delta: Decomposed efficient long-term robot task planning using large language models,'' \emph{arXiv preprint arXiv:2404.03275}, 2024.

\bibitem[Pohl et~al.(2024)Pohl, Reister, Peller-Konrad, and Asfour]{pohl2024}
C.~Pohl, F.~Reister, F.~Peller-Konrad, and T.~Asfour, ``Makeable: Memory-centered and affordance-based task execution framework for transferable mobile manipulation skills,'' in \emph{IEEE/RSJ Int. Conf. on Intelligent Robots and Systems}, 2024, pp. 3674--3681.

\bibitem[Ali et~al.(2024)Ali, Allgeuer, Mazzola, Belgiovine, Kaplan, Gajdošech, and Wermter]{alimem}
H.~Ali, P.~Allgeuer, C.~Mazzola, G.~Belgiovine, B.~C. Kaplan, L.~Gajdošech, and S.~Wermter, ``Robots can multitask too: Integrating a memory architecture and llms for enhanced cross-task robot action generation,'' in \emph{IEEE-RAS 23rd Int. Conf. on Humanoid Robots}, 2024, pp. 811--818.

\bibitem[Kim et~al.(2024)Kim, Pertsch, Karamcheti, Xiao, Balakrishna, Nair, Rafailov, Foster, Lam, Sanketi, et~al.]{openvla}
M.~J. Kim, K.~Pertsch, S.~Karamcheti, T.~Xiao, A.~Balakrishna, S.~Nair \emph{et~al.}, ``Openvla: An open-source vision-language-action model,'' \emph{arXiv preprint arXiv:2406.09246}, 2024.

\bibitem[O’Neill et~al.(2024)O’Neill, Rehman, Maddukuri, Gupta, Padalkar, Lee, Pooley, Gupta, Mandlekar, Jain, Tung, Bewley, Herzog, Irpan, Khazatsky, Rai, Gupta, Wang, Singh, Garg, Kembhavi, Xie, Brohan, Raffin, Sharma, Yavary, Jain, Balakrishna, Wahid, Burgess-Limerick, Kim, Schölkopf, Wulfe, Ichter, Lu, Xu, Le, Finn, Wang, Xu, Chi, Huang, Chan, Agia, Pan, Fu, Devin, Xu, Morton, Driess, Chen, Pathak, Shah, Büchler, Jayaraman, Kalashnikov, Sadigh, Johns, Foster, Liu, Ceola, Xia, Zhao, Stulp, Zhou, Sukhatme, Salhotra, Yan, Feng, Schiavi, Berseth, Kahn, Wang, Su, Fang, Shi, Bao, Ben~Amor, Christensen, Furuta, Walke, Fang, Ha, Mordatch, Radosavovic, Leal, Liang, Abou-Chakra, Kim, Drake, Peters, Schneider, Hsu, Bohg, Bingham, Wu, Gao, Hu, Wu, Wu, Sun, Luo, Gu, Tan, Oh, Wu, Lu, Yang, Malik, Silvério, Hejna, Booher, Tompson, Yang, Salvador, Lim, Han, Wang, Rao, Pertsch, Hausman, Go, Gopalakrishnan, Goldberg, Byrne, Oslund, Kawaharazuka, Black, Lin, Zhang, Ehsani, Lekkala, Ellis, Rana, Srinivasan, Fang,
  Singh, Zeng, Hatch, Hsu, Itti, Chen, Pinto, Fei-Fei, Tan, Fan, Ott, Lee, Weihs, Chen, Lepert, Memmel, Tomizuka, Itkina, Castro, Spero, Du, Ahn, Yip, Zhang, Ding, Heo, Srirama, Sharma, Kim, Kanazawa, Hansen, Heess, Joshi, Suenderhauf, Liu, Di~Palo, Shafiullah, Mees, Kroemer, Bastani, Sanketi, Miller, Yin, Wohlhart, Xu, Fagan, Mitrano, Sermanet, Abbeel, Sundaresan, Chen, Vuong, Rafailov, Tian, Doshi, Martín-Martín, Baijal, Scalise, Hendrix, Lin, Qian, Zhang, Mendonca, Shah, Hoque, Julian, Bustamante, Kirmani, Levine, Lin, Moore, Bahl, Dass, Sonawani, Song, Xu, Haldar, Karamcheti, Adebola, Guist, Nasiriany, Schaal, Welker, Tian, Ramamoorthy, Dasari, Belkhale, Park, Nair, Mirchandani, Osa, Gupta, Harada, Matsushima, Xiao, Kollar, Yu, Ding, Davchev, Zhao, Armstrong, Darrell, Chung, Jain, Vanhoucke, Zhan, Zhou, Burgard, Chen, Wang, Zhu, Geng, Liu, Liangwei, Li, Lu, Ma, Kim, Chebotar, Zhou, Zhu, Wu, Xu, Wang, Bisk, Cho, Lee, Cui, Cao, Wu, Tang, Zhu, Zhang, Jiang, Li, Li, Iwasawa, Matsuo, Ma, Xu, Cui, Zhang, and
  Lin]{openxemb}
A.~O’Neill, A.~Rehman, A.~Maddukuri, A.~Gupta, A.~Padalkar, A.~Lee \emph{et~al.}, ``Open x-embodiment: Robotic learning datasets and rt-x models,'' in \emph{IEEE Int. Conf. on Robotics and Automation}, 2024, pp. 6892--6903.

\bibitem[Puig et~al.(2018)Puig, Ra, Boben, Li, Wang, Fidler, and Torralba]{puig2018virtualhome}
X.~Puig, K.~Ra, M.~Boben, J.~Li, T.~Wang, S.~Fidler, and A.~Torralba, ``Virtualhome: Simulating household activities via programs,'' in \emph{Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition}, 2018, pp. 8494--8502.

\bibitem[Renze(2024)]{renze-2024-effect}
M.~Renze, ``The effect of sampling temperature on problem solving in large language models,'' in \emph{Findings of the Association for Computational Linguistics: EMNLP}, Miami, Florida, USA, Nov. 2024, pp. 7346--7356.

\end{thebibliography}
