Metadata-Version: 2.3
Name: cloudsecgpt
Version: 0.1.1
Summary: CloudSecGPT super-charges raw cloud-security findings with AI. Analyzes OCSF/Parquet exports and live data from AWS Security Hub, GCP Security Command Center, and Azure Defender to provide risk scores, summaries, remediation steps, alert clustering, and interactive chat capabilities.
License: Apache-2.0
Keywords: cloud security,ai,llm,gpt,openai,amazon bedrock,google gemini,ollama,mcp,aws security hub,gcp scc,azure defender,ocsf,asff,parquet,triage,risk score,remediation,devsecops,cli
Author: Sergio Garcia @MrCloudSec
Author-email: hello@mistercloudsec.com
Requires-Python: >=3.9
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: azure-identity (==1.23.0)
Requires-Dist: azure-mgmt-resource (==24.0.0)
Requires-Dist: azure-mgmt-security (==7.0.0)
Requires-Dist: boto3 (==1.39.0)
Requires-Dist: google-cloud-resource-manager (==1.14.2)
Requires-Dist: google-cloud-securitycenter (==1.38.1)
Requires-Dist: google-generativeai (==0.8.3)
Requires-Dist: jinja2 (==3.1.6)
Requires-Dist: openai (==1.93.0)
Requires-Dist: pandas (==2.3.0)
Requires-Dist: requests (==2.32.4)
Requires-Dist: rich (==14.0.0)
Project-URL: homepage, https://github.com/MrCloudSec/CloudSecGPT
Project-URL: issues, https://github.com/MrCloudSec/CloudSecGPT/issues
Description-Content-Type: text/markdown

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/MrCloudSec/CloudSecGPT/blob/main/docs/images/logo-horizontal-dark.png" />
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/MrCloudSec/CloudSecGPT/blob/main/docs/images/logo-horizontal-light.png" />
    <img src="https://github.com/MrCloudSec/CloudSecGPT/blob/main/docs/images/social-preview.png" alt="CloudSecGPT logo" width="70%">
  </picture>
</p>

**CloudSecGPT** superâ€‘charges raw cloudâ€‘security findings withâ€¯AI.
Give it an OCSF/ASFF/Parquet export â€“â€¯or pull live from **AWSÂ SecurityÂ Hub**, **GCPâ€¯SecurityÂ CommandÂ Center**, or **Azureâ€¯Defender** â€“ and it spits out:

* **Risk scoreÂ (1â€‘10)** for every finding
* Oneâ€‘line **summary**, business **impact** & concise **remediation**
* Copyâ€‘â€‘pasteable **CLI fix command**
* **Groups** to slash alert fatigue
* A gorgeous selfâ€‘contained **HTML report**
* An interactive **chat** so you can ask â€œ_why?_â€ & â€œ_how do I fix this?_â€ on the fly

---

## âœ¨Â Feature Matrix

| Pillar | Highlights |
|--------|------------|
| **Sources** | â€¢ JSON-OCSF/JSON-ASFF/Parquet<br>â€¢ `--security-hub` live pull<br>â€¢ `--gcp-scc` org / folder / project<br>â€¢ `--azure-defender` subscription |
| **Analyze** | Enriches every finding â†’ `risk_score`, `summary`, `why`, `cli_fix`, `remediation` |
| **Groups** | Groups by *resource_typeÂ +Â summary* â†’ noise â†“, signal â†‘ |
| **Outputs** | 3 artefacts in `--out` dir:<br>`analyzed.csv` Â· `grouped.csv` Â· `report.html` |
| **Chat** | `cloudsecgpt chat` â†’ conversational Q&A with full context |
| **LLM backâ€‘ends** | `openai` Â· `bedrock` Â· `ollama` (local) Â· `gemini` Â· **MCP** client |
| **Smart cache** | FileÂ + prompt hashed (BLAKE2b) â†’ no double billing |
| **Progress UI** | Tidy Rich bar with live findings counter |

---

## ğŸ“¦Â Install

```bash
pip install cloudsecgpt
```

(Requires Python â‰¥ 3.9)

Developers:

```bash
git clone https://github.com/MrCloudSec/CloudSecGPT.git
cd CloudSecGPT && poetry install
```

## âš™ï¸Â QuickÂ start

```bash
export OPENAI_API_KEY=...
cloudsecgpt analyze --file path/to/JSON-OCSF/JSON-ASFF/Parquet \
  [--provider openai] [--model gpt-4o-mini] \
  [--batch 20] [--workers 8] \
  [--out ./out]
```

* `./out/analyzed_<timestamp>.csv` â€“ full table sorted by highest risk
* `./out/grouped_<timestamp>.csv` â€“ deâ€‘duplicated view
* `./out/report_<timestamp>.html`  â€“ shareâ€‘ready report (logo, chart, sticky headers)

![analyze.gif](docs/images/analyze.gif)

### Live pulls

```bash
# AWS SecurityÂ Hub via AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optional AWS_SESSION_TOKEN env vars
cloudsecgpt analyze --security-hub [-o out/]

# GCPÂ SCC (autoâ€‘detect single org) via GOOGLE_APPLICATION_CREDENTIALS env var or gcloud auth application-default login
cloudsecgpt analyze --gcp-scc [org/folder/projectID] [-o out/]

# AzureÂ Defender (single subscription auto) via AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_TENANT_ID env vars or az login
cloudsecgpt analyze --azure-defender [subscriptionID] [-o out/]
```

![security-hub.gif](docs/images/securityhub.gif)

### Chat mode

```bash
# Chat with the context of a file
cloudsecgpt chat findings.json

#Â Chat with the context of Security Hub via AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and optional AWS_SESSION_TOKEN env vars
cloudsecgpt chat --security-hub

#Â Chat with the context of GCP SCC via GOOGLE_APPLICATION_CREDENTIALS env var or gcloud auth application-default login
cloudsecgpt chat --gcp-scc

#Â Chat with the context of Azure Defender via AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_TENANT_ID env vars or az login
cloudsecgpt chat --azure-defender
```

Ask anything â€“ context is streamed from the analyzed findings.

![chat.png](docs/images/chat.png)

---

## ğŸ³ Docker

```bash
# Pull and run
docker run --rm -v $(pwd):/data -e OPENAI_API_KEY=your_key \
  mrcloudsec/cloudsecgpt:latest analyze /data/findings.parquet -o /data/out
```

```bash
# Build locally
git clone https://github.com/MrCloudSec/CloudSecGPT.git
cd CloudSecGPT && docker build -t cloudsecgpt .
docker run --rm -v $(pwd):/data cloudsecgpt analyze /data/findings.parquet -o /data/out
```

---

## ğŸ”ŒÂ Providers

| Flag | Notes |
|------|-------|
| **openai**  | `OPENAI_API_KEY` env var |
| **bedrock** | standard AWS creds via `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and optional `AWS_SESSION_TOKEN` env vars |
| **ollama**  | `ollama serve` on `localhost:11434` |
| **gemini**  | `GEMINI_API_KEY` env var |
| **mcp**     | Any Modelâ€‘Contextâ€‘Protocol host (`--host` + optional `--api-key`) |

---

## ğŸ§‘â€ğŸ’»Â Extend

```python
class MyModel:
    def call(self, messages: list[dict[str, str]]) -> str:
        ...
```

Register it in `core.get_model()` â€“ done.

---

## ğŸ›¡ï¸Â Why CloudSecGPT?

* ğŸ‘€Â Singleâ€‘pane view across **AWS / Azure / GCP / K8s**
* âš¡Â Cut triage time with instant clustering
* ğŸ§ Â Explain *why it matters* â€“ not just â€œwhatâ€
* ğŸ—£ï¸Â Talk to your findings like ChatGPT
* ğŸ‘Â Openâ€‘source, pluggable, works offline with local LLMs

---

## ğŸ¤Â Contributing

PRs & issues welcome! Preâ€‘commit hooks run **Black**, **Flake8** & **Bandit**.

---

## ğŸ“œÂ License

Apacheâ€‘2.0 Â©â€¯2025Â [**@MrCloudSec**](https://www.linkedin.com/in/mistercloudsec/)

