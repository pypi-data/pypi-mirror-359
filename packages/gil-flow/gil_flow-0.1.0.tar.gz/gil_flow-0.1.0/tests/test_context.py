#!/usr/bin/env python3
"""
Gil ì›Œí¬í”Œë¡œìš° ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°

ì»¨í…ìŠ¤íŠ¸ ì‹œìŠ¤í…œì„ ì™„ì „íˆ ì§€ì›í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°

ì‚¬ìš©ë²•:
    py test_context.py context-test.yaml
    py test_context.py smart-content-generator.yaml
"""

import os
import sys
import asyncio
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

# gil-py ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent / "gil-py"))

def load_env():
    """í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        try:
            from dotenv import load_dotenv
            load_dotenv(env_path)
        except ImportError:
            # dotenvê°€ ì—†ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ ë¡œë“œ
            with open(env_path, 'r') as f:
                for line in f:
                    if '=' in line and not line.strip().startswith('#'):
                        key, value = line.strip().split('=', 1)
                        os.environ[key] = value

def load_yaml_with_context(filepath: Path) -> Dict[str, Any]:
    """ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ ì¹˜í™˜ì„ ì§€ì›í•˜ëŠ” YAML ë¡œë”"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ê°„ë‹¨í•œ í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜
    import re
    
    # ${secrets.KEY} íŒ¨í„´ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì¹˜í™˜
    def replace_secrets(match):
        key = match.group(1)
        return os.getenv(key, f"${{secrets.{key}}}")
    
    content = re.sub(r'\$\{secrets\.([^}]+)\}', replace_secrets, content)
    
    return yaml.safe_load(content)

async def run_workflow_with_context(yaml_file: Path) -> bool:
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    try:
        from gil_py.core.context import FlowContext, NodeContext
        from gil_py.connectors.openai_connector import GilConnectorOpenAI
        
        print(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘: {yaml_file.name}")
        print(f"ğŸ“‚ íŒŒì¼ ê²½ë¡œ: {yaml_file}")
        print("=" * 60)
        
        # YAML ë¡œë“œ
        workflow_data = load_yaml_with_context(yaml_file)
        
        # Flow Context ì´ˆê¸°í™”
        flow_context = FlowContext(workflow_id=workflow_data.get("name", "test_workflow"))
        
        # YAMLì—ì„œ ì •ì˜ëœ ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        if "context" in workflow_data:
            context_config = workflow_data["context"]
            
            # ì´ˆê¸° ë³€ìˆ˜ ì„¤ì •
            if "variables" in context_config:
                for key, value in context_config["variables"].items():
                    flow_context.set_variable(key, value)
                print(f"ğŸ“ Flow ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ: {list(context_config['variables'].keys())}")
            
            # ì´ˆê¸° ë©”íƒ€ë°ì´í„° ì„¤ì •
            if "metadata" in context_config:
                for key, value in context_config["metadata"].items():
                    flow_context.update_metadata(key, value)
                print(f"ğŸ“Š Flow ë©”íƒ€ë°ì´í„° ì„¤ì • ì™„ë£Œ: {list(context_config['metadata'].keys())}")
        
        # ë…¸ë“œ ì‹¤í–‰ (ë‹¨ìˆœí™”ëœ ë²„ì „)
        nodes = workflow_data.get("nodes", {})
        flow_order = workflow_data.get("flow", [])
        
        node_results = {}
        
        print(f"\nğŸ”„ ë…¸ë“œ ì‹¤í–‰ ì‹œì‘ (ì´ {len(flow_order)}ê°œ ë…¸ë“œ)")
        print("-" * 40)
        
        for node_name in flow_order:
            if node_name not in nodes:
                error_msg = f"ë…¸ë“œ '{node_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                flow_context.add_error(node_name, error_msg, "node_not_found")
                print(f"âŒ {error_msg}")
                continue
            
            node_config = nodes[node_name]
            node_type = node_config.get("type")
            
            print(f"âš™ï¸ ì‹¤í–‰ ì¤‘: {node_name} ({node_type})")
            
            # Node Context ìƒì„±
            node_context = NodeContext(node_name, flow_context)
            
            try:
                # ë…¸ë“œë³„ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
                if node_type == "GilConnectorOpenAI":
                    # OpenAI ì»¤ë„¥í„° ì‹¤í–‰
                    connector = GilConnectorOpenAI(
                        api_key=os.getenv("OPENAI_API_KEY", ""),
                        name=node_name
                    )
                    connector.set_contexts(node_context, flow_context)
                    
                    # ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰
                    result = await connector.execute({})
                    node_results[node_name] = result
                    print("   âœ… OpenAI ì»¤ë„¥í„° ì—°ê²° í™•ì¸ ì™„ë£Œ")
                
                elif node_type in ["GilGenImage", "AITextGeneration"]:
                    # AI ìƒì„± ë…¸ë“œ ì‹œë®¬ë ˆì´ì…˜
                    node_context.set_variable("api_calls", 1)
                    node_context.set_variable("tokens_used", 150)  # ì‹œë®¬ë ˆì´ì…˜
                    
                    # Flow ì»¨í…ìŠ¤íŠ¸ì— í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
                    total_tokens = flow_context.get_shared_data("total_tokens_used", 0)
                    flow_context.set_shared_data("total_tokens_used", total_tokens + 150)
                    
                    result = {
                        "success": True,
                        "generated_text": f"[ì‹œë®¬ë ˆì´ì…˜] {node_name}ì—ì„œ ìƒì„±ëœ ì½˜í…ì¸ ",
                        "metadata": {
                            "tokens_used": 150,
                            "execution_time": 2.5
                        }
                    }
                    node_results[node_name] = result
                    print("   âœ… AI ìƒì„± ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)")
                
                elif node_type == "TransformData":
                    # ë°ì´í„° ë³€í™˜ ë…¸ë“œ ì‹œë®¬ë ˆì´ì…˜
                    operations = node_config.get("inputs", {}).get("operations", [])
                    
                    result = {
                        "success": True,
                        "transformed_data": {
                            "processed": True,
                            "operations_count": len(operations),
                            "result": "ë³€í™˜ ì™„ë£Œ"
                        }
                    }
                    node_results[node_name] = result
                    print(f"   âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ ({len(operations)}ê°œ ì—°ì‚°)")
                
                else:
                    # ê¸°íƒ€ ë…¸ë“œ ì‹œë®¬ë ˆì´ì…˜
                    result = {
                        "success": True,
                        "message": f"{node_type} ë…¸ë“œ ì‹¤í–‰ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)"
                    }
                    node_results[node_name] = result
                    print(f"   âœ… {node_type} ì‹¤í–‰ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)")
                
                # ì™„ë£Œëœ ë…¸ë“œ ìˆ˜ ì¦ê°€
                flow_context.increment_completed_nodes()
                
            except Exception as e:
                error_msg = f"ë…¸ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
                flow_context.add_error(node_name, error_msg, "execution_error")
                node_context.add_error(error_msg, "execution_error")
                print(f"   âŒ ì˜¤ë¥˜: {error_msg}")
                
                node_results[node_name] = {
                    "success": False,
                    "error": error_msg
                }
        
        # ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
        print("-" * 40)
        
        # Flow Context ì •ë³´ ì¶œë ¥
        flow_dict = flow_context.to_dict()
        print(f"âœ… ì™„ë£Œëœ ë…¸ë“œ: {flow_dict['metadata']['completed_nodes']}")
        print(f"âŒ ë°œìƒí•œ ì—ëŸ¬: {len(flow_dict['errors'])}")
        print(f"ğŸ¯ ì´ í† í° ì‚¬ìš©ëŸ‰: {flow_dict['shared_data'].get('total_tokens_used', 0)}")
        
        # Flow ë³€ìˆ˜ ì¶œë ¥
        if flow_dict['variables']:
            print("ğŸ“ Flow ë³€ìˆ˜:")
            for key, value in flow_dict['variables'].items():
                print(f"   - {key}: {value}")
        
        # ê³µìœ  ë°ì´í„° ì¶œë ¥
        if flow_dict['shared_data']:
            print("ğŸ“Š ê³µìœ  ë°ì´í„°:")
            for key, value in flow_dict['shared_data'].items():
                print(f"   - {key}: {value}")
        
        # ì—ëŸ¬ ì •ë³´ ì¶œë ¥
        if flow_dict['errors']:
            print("âš ï¸ ë°œìƒí•œ ì—ëŸ¬ë“¤:")
            for error in flow_dict['errors']:
                print(f"   - [{error['node']}] {error['message']}")
        
        # ê²°ê³¼ ì €ì¥
        output_dir = Path(__file__).parent / "context_results"
        output_dir.mkdir(exist_ok=True)
        
        result_file = output_dir / f"{yaml_file.stem}_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump({
                "workflow_name": workflow_data.get("name"),
                "execution_time": datetime.now().isoformat(),
                "flow_context": flow_dict,
                "node_results": node_results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
        
        # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
        return len(flow_dict['errors']) == 0
        
    except ImportError as e:
        print(f"âŒ Gil-Py ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return False
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: py test_context.py <workflow.yaml>")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°:")
        print("  - context-test.yaml")
        print("  - smart-content-generator.yaml")
        return
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_env()
    
    # YAML íŒŒì¼ ê²½ë¡œ
    yaml_file = Path(__file__).parent / sys.argv[1]
    
    if not yaml_file.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {yaml_file}")
        return
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    success = await run_workflow_with_context(yaml_file)
    
    if success:
        print("\nğŸ‰ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì„±ê³µ!")
    else:
        print("\nğŸ’¥ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨!")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
