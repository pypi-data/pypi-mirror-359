"""
è´¨é‡ç›‘æ§å’Œè¯„åˆ†ç³»ç»Ÿ - ç›‘æ§è¾©è®ºè´¨é‡å¹¶æä¾›è¯„åˆ†
"""

import re
from datetime import datetime

from .models import DebateQualityMetrics, PKSession


class DebateQualityAnalyzer:
    """è¾©è®ºè´¨é‡åˆ†æå™¨"""

    def __init__(self) -> None:
        # è´¨é‡æŒ‡æ ‡æƒé‡
        self.weights = {
            "novelty": 0.25,  # è§‚ç‚¹æ–°é¢–åº¦
            "depth": 0.30,  # è®ºè¯æ·±åº¦
            "interaction": 0.25,  # äº’åŠ¨è´¨é‡
            "practicality": 0.20,  # å®ç”¨ä»·å€¼
        }

        # æ–°é¢–åº¦å…³é”®è¯
        self.novelty_indicators = [
            "åˆ›æ–°",
            "çªç ´",
            "é¢ è¦†",
            "æ–°é¢–",
            "ç‹¬ç‰¹",
            "åŸåˆ›",
            "å‰æ‰€æœªæœ‰",
            "é©å‘½æ€§",
            "å¼€åˆ›æ€§",
            "ä¸ä¼—ä¸åŒ",
            "åˆ«å‡ºå¿ƒè£",
            "å¦è¾Ÿè¹Šå¾„",
        ]

        # æ·±åº¦æŒ‡æ ‡
        self.depth_indicators = [
            "æ·±å±‚",
            "æœ¬è´¨",
            "æ ¹æœ¬",
            "æ ¸å¿ƒ",
            "å†…åœ¨",
            "æ·±å…¥",
            "é€å½»",
            "ç³»ç»Ÿæ€§",
            "å…¨é¢",
            "è¯¦ç»†",
            "å…·ä½“",
            "æ·±åº¦",
            "æ·±åˆ»",
        ]

        # äº’åŠ¨æŒ‡æ ‡
        self.interaction_indicators = [
            "å›åº”",
            "æ‰¹è¯„",
            "è´¨ç–‘",
            "è¡¥å……",
            "å®Œå–„",
            "å€Ÿé‰´",
            "å¸æ”¶",
            "åé©³",
            "èµåŒ",
            "ç»“åˆ",
            "èåˆ",
            "å¯¹è¯",
            "äº¤æµ",
        ]

        # å®ç”¨æ€§æŒ‡æ ‡
        self.practicality_indicators = [
            "å®ç”¨",
            "å¯è¡Œ",
            "å…·ä½“",
            "æ“ä½œ",
            "å®æ–½",
            "æ‰§è¡Œ",
            "åº”ç”¨",
            "æ–¹æ¡ˆ",
            "æ­¥éª¤",
            "æªæ–½",
            "å»ºè®®",
            "æŒ‡å¯¼",
            "å®é™…",
        ]

    def analyze_session_quality(self, session: PKSession) -> DebateQualityMetrics:
        """åˆ†ææ•´ä¸ªä¼šè¯çš„è´¨é‡"""
        if not session.responses:
            return DebateQualityMetrics.create_initial()

        # åˆ†æå„é¡¹æŒ‡æ ‡
        novelty_score = self._analyze_novelty(session)
        depth_score = self._analyze_depth(session)
        interaction_score = self._analyze_interaction(session)
        practicality_score = self._analyze_practicality(session)

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_score = (
            novelty_score * self.weights["novelty"]
            + depth_score * self.weights["depth"]
            + interaction_score * self.weights["interaction"]
            + practicality_score * self.weights["practicality"]
        )

        # ç”Ÿæˆåé¦ˆ
        feedback = self._generate_quality_feedback(
            novelty_score, depth_score, interaction_score, practicality_score
        )

        return DebateQualityMetrics(
            novelty_score=novelty_score,
            depth_score=depth_score,
            interaction_score=interaction_score,
            practicality_score=practicality_score,
            overall_score=overall_score,
            feedback=feedback,
            timestamp=datetime.now().isoformat(),
        )

    def _analyze_novelty(self, session: PKSession) -> float:
        """åˆ†æè§‚ç‚¹æ–°é¢–åº¦"""
        novelty_score = 0.0
        total_responses = 0

        for round_responses in session.responses.values():
            for response in round_responses.values():
                response_novelty = self._calculate_text_novelty(response)
                novelty_score += response_novelty
                total_responses += 1

        if total_responses == 0:
            return 5.0

        return min(novelty_score / total_responses, 10.0)

    def _calculate_text_novelty(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬çš„æ–°é¢–åº¦è¯„åˆ†"""
        text_lower = text.lower()

        # åŸºç¡€è¯„åˆ†
        score = 5.0

        # æ£€æŸ¥æ–°é¢–åº¦å…³é”®è¯
        novelty_keywords_found = sum(
            1 for keyword in self.novelty_indicators if keyword in text_lower
        )
        score += min(novelty_keywords_found * 0.5, 2.0)

        # æ£€æŸ¥ç‹¬ç‰¹è¡¨è¾¾
        unique_expressions = self._count_unique_expressions(text)
        score += min(unique_expressions * 0.3, 1.5)

        # æ£€æŸ¥åˆ›æ–°æ€§æ€ç»´æ¨¡å¼
        if any(
            pattern in text_lower
            for pattern in ["ç¬¬ä¸€æ€§åŸç†", "åå‘æ€è€ƒ", "è·¨ç•Œæ€ç»´", "ç³»ç»Ÿé‡æ„"]
        ):
            score += 1.0

        # æ£€æŸ¥å…·ä½“æ¡ˆä¾‹å’Œç±»æ¯”
        if re.search(r"æ¯”å¦‚|ä¾‹å¦‚|ç±»ä¼¼|å¥½æ¯”|å°±åƒ", text):
            score += 0.5

        return min(score, 10.0)

    def _count_unique_expressions(self, text: str) -> int:
        """ç»Ÿè®¡ç‹¬ç‰¹è¡¨è¾¾çš„æ•°é‡"""
        unique_patterns = [
            r"æ¢å¥è¯è¯´",
            r"ä»å¦ä¸€ä¸ªè§’åº¦",
            r"ä¸å¦¨[æƒ³æƒ³|è€ƒè™‘|è¯•è¯•]",
            r"æˆ–è®¸|ä¹Ÿè®¸|å¯èƒ½",
            r"çªç„¶æƒ³åˆ°",
            r"æœ‰è¶£çš„æ˜¯",
            r"ä»¤äººæƒŠè®¶çš„æ˜¯",
        ]

        count = 0
        for pattern in unique_patterns:
            if re.search(pattern, text):
                count += 1

        return count

    def _analyze_depth(self, session: PKSession) -> float:
        """åˆ†æè®ºè¯æ·±åº¦"""
        depth_score = 0.0
        total_responses = 0

        for round_responses in session.responses.values():
            for response in round_responses.values():
                response_depth = self._calculate_text_depth(response)
                depth_score += response_depth
                total_responses += 1

        if total_responses == 0:
            return 5.0

        return min(depth_score / total_responses, 10.0)

    def _calculate_text_depth(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬çš„æ·±åº¦è¯„åˆ†"""
        text_lower = text.lower()

        # åŸºç¡€è¯„åˆ†
        score = 5.0

        # æ£€æŸ¥æ·±åº¦å…³é”®è¯
        depth_keywords_found = sum(
            1 for keyword in self.depth_indicators if keyword in text_lower
        )
        score += min(depth_keywords_found * 0.4, 2.0)

        # æ£€æŸ¥é€»è¾‘ç»“æ„
        logical_structures = self._count_logical_structures(text)
        score += min(logical_structures * 0.5, 1.5)

        # æ£€æŸ¥è®ºè¯æ·±åº¦
        if self._has_multi_layer_reasoning(text):
            score += 1.0

        # æ£€æŸ¥å…·ä½“è®ºæ®
        evidence_count = self._count_evidence(text)
        score += min(evidence_count * 0.3, 1.0)

        # æ–‡æœ¬é•¿åº¦å¥–åŠ±ï¼ˆè¾ƒé•¿çš„å›ç­”é€šå¸¸æ›´æ·±å…¥ï¼‰
        length_bonus = min(len(text) / 500, 0.5)
        score += length_bonus

        return min(score, 10.0)

    def _count_logical_structures(self, text: str) -> int:
        """ç»Ÿè®¡é€»è¾‘ç»“æ„æ•°é‡"""
        structures = [
            r"é¦–å…ˆ|ç¬¬ä¸€",
            r"å…¶æ¬¡|ç¬¬äºŒ|ç„¶å",
            r"æœ€å|æœ€ç»ˆ|æ€»ä¹‹",
            r"å› ä¸º|ç”±äº|å› æ­¤|æ‰€ä»¥",
            r"ä½†æ˜¯|ç„¶è€Œ|ä¸è¿‡|å¯æ˜¯",
            r"å¦ä¸€æ–¹é¢|ä¸æ­¤åŒæ—¶",
            r"ç»¼åˆæ¥çœ‹|æ•´ä½“è€Œè¨€",
        ]

        count = 0
        for pattern in structures:
            if re.search(pattern, text):
                count += 1

        return count

    def _has_multi_layer_reasoning(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¤šå±‚æ¬¡æ¨ç†"""
        multi_layer_patterns = [
            r"è¿›ä¸€æ­¥[è¯´|è®²|åˆ†æ|æ€è€ƒ]",
            r"æ·±å…¥[åˆ†æ|æ¢è®¨|æ€è€ƒ]",
            r"æ›´æ·±å±‚[æ¬¡|é¢]çš„",
            r"èƒŒåçš„[åŸå› |é€»è¾‘|æœºåˆ¶]",
            r"æ ¹æœ¬[åŸå› |é—®é¢˜|æ‰€åœ¨]",
        ]

        return any(re.search(pattern, text) for pattern in multi_layer_patterns)

    def _count_evidence(self, text: str) -> int:
        """ç»Ÿè®¡è®ºæ®æ•°é‡"""
        evidence_patterns = [
            r"ç ”ç©¶[è¡¨æ˜|æ˜¾ç¤º|å‘ç°]",
            r"æ•°æ®[æ˜¾ç¤º|è¡¨æ˜]",
            r"ä¾‹å­|æ¡ˆä¾‹|å®ä¾‹",
            r"å†å²[ä¸Š|ç»éªŒ|æ•™è®­]",
            r"äº‹å®[æ˜¯|ä¸Š|è¯æ˜]",
            r"è°ƒæŸ¥[æ˜¾ç¤º|è¡¨æ˜]",
        ]

        count = 0
        for pattern in evidence_patterns:
            count += len(re.findall(pattern, text))

        return count

    def _analyze_interaction(self, session: PKSession) -> float:
        """åˆ†æäº’åŠ¨è´¨é‡"""
        if len(session.responses) <= 1:
            return 5.0  # åªæœ‰ä¸€è½®ï¼Œæ— æ³•è¯„ä¼°äº’åŠ¨

        interaction_score = 0.0
        interaction_count = 0

        # åˆ†æç¬¬2è½®å¼€å§‹çš„äº’åŠ¨è´¨é‡
        for round_num in range(2, len(session.responses) + 1):
            if round_num in session.responses:
                round_score = self._analyze_round_interaction(session, round_num)
                interaction_score += round_score
                interaction_count += 1

        if interaction_count == 0:
            return 5.0

        return min(interaction_score / interaction_count, 10.0)

    def _analyze_round_interaction(self, session: PKSession, round_num: int) -> float:
        """åˆ†æç‰¹å®šè½®æ¬¡çš„äº’åŠ¨è´¨é‡"""
        current_round = session.responses.get(round_num, {})
        previous_round = session.responses.get(round_num - 1, {})

        if not current_round or not previous_round:
            return 5.0

        interaction_score = 0.0
        response_count = 0

        for persona, response in current_round.items():
            # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†å…¶ä»–ä¸“å®¶çš„è§‚ç‚¹
            reference_score = self._calculate_reference_score(
                response, previous_round, persona
            )
            interaction_score += reference_score
            response_count += 1

        return interaction_score / response_count if response_count > 0 else 5.0

    def _calculate_reference_score(
        self, response: str, previous_round: dict[str, str], current_persona: str
    ) -> float:
        """è®¡ç®—å›åº”çš„äº’åŠ¨è¯„åˆ†"""
        response_lower = response.lower()

        # åŸºç¡€è¯„åˆ†
        score = 5.0

        # æ£€æŸ¥äº’åŠ¨å…³é”®è¯
        interaction_keywords_found = sum(
            1 for keyword in self.interaction_indicators if keyword in response_lower
        )
        score += min(interaction_keywords_found * 0.5, 2.0)

        # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†å…¶ä»–ä¸“å®¶
        other_personas = [
            name for name in previous_round.keys() if name != current_persona
        ]
        references = sum(1 for name in other_personas if name in response)
        score += min(references * 1.0, 2.0)

        # æ£€æŸ¥æ‰¹åˆ¤æ€§å›åº”
        critical_patterns = [
            r"æˆ‘è®¤ä¸º.*ä¸å¤Ÿ",
            r"å­˜åœ¨.*é—®é¢˜",
            r"éœ€è¦.*è¡¥å……",
            r"å¿½ç•¥äº†",
            r"è¿‡äº.*åŒ–",
        ]
        critical_responses = sum(
            1 for pattern in critical_patterns if re.search(pattern, response)
        )
        score += min(critical_responses * 0.5, 1.0)

        return min(score, 10.0)

    def _analyze_practicality(self, session: PKSession) -> float:
        """åˆ†æå®ç”¨ä»·å€¼"""
        practicality_score = 0.0
        total_responses = 0

        for round_responses in session.responses.values():
            for response in round_responses.values():
                response_practicality = self._calculate_text_practicality(response)
                practicality_score += response_practicality
                total_responses += 1

        if total_responses == 0:
            return 5.0

        return min(practicality_score / total_responses, 10.0)

    def _calculate_text_practicality(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬çš„å®ç”¨æ€§è¯„åˆ†"""
        text_lower = text.lower()

        # åŸºç¡€è¯„åˆ†
        score = 5.0

        # æ£€æŸ¥å®ç”¨æ€§å…³é”®è¯
        practicality_keywords_found = sum(
            1 for keyword in self.practicality_indicators if keyword in text_lower
        )
        score += min(practicality_keywords_found * 0.4, 2.0)

        # æ£€æŸ¥å…·ä½“æ­¥éª¤
        steps = self._count_actionable_steps(text)
        score += min(steps * 0.5, 1.5)

        # æ£€æŸ¥å¯æ“ä½œæ€§
        if self._has_actionable_advice(text):
            score += 1.0

        # æ£€æŸ¥å…·ä½“å·¥å…·æˆ–æ–¹æ³•
        tools_mentioned = self._count_tools_and_methods(text)
        score += min(tools_mentioned * 0.3, 1.0)

        return min(score, 10.0)

    def _count_actionable_steps(self, text: str) -> int:
        """ç»Ÿè®¡å¯æ‰§è¡Œæ­¥éª¤æ•°é‡"""
        step_patterns = [
            r"ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+æ­¥",
            r"æ­¥éª¤[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+",
            r"é¦–å…ˆ.*[ï¼Œã€‚]",
            r"ç„¶å.*[ï¼Œã€‚]",
            r"æ¥ä¸‹æ¥.*[ï¼Œã€‚]",
            r"æœ€å.*[ï¼Œã€‚]",
        ]

        count = 0
        for pattern in step_patterns:
            count += len(re.findall(pattern, text))

        return count

    def _has_actionable_advice(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å¯æ‰§è¡Œçš„å»ºè®®"""
        actionable_patterns = [
            r"å»ºè®®.*[è¿›è¡Œ|é‡‡ç”¨|ä½¿ç”¨|å®æ–½]",
            r"å¯ä»¥[å°è¯•|è¯•è¯•|è€ƒè™‘|é‡‡ç”¨]",
            r"åº”è¯¥[ç«‹å³|é©¬ä¸Š|å°½å¿«]",
            r"å…·ä½“[åšæ³•|æ–¹æ³•|æ“ä½œ]",
            r"å®é™…[åº”ç”¨|æ“ä½œ|æ‰§è¡Œ]",
        ]

        return any(re.search(pattern, text) for pattern in actionable_patterns)

    def _count_tools_and_methods(self, text: str) -> int:
        """ç»Ÿè®¡æåˆ°çš„å·¥å…·å’Œæ–¹æ³•æ•°é‡"""
        tool_patterns = [
            r"[å·¥å…·|æ–¹æ³•|æŠ€æœ¯|ç³»ç»Ÿ|å¹³å°|è½¯ä»¶]",
            r"ä½¿ç”¨.*[æ¥|è¿›è¡Œ|å®ç°]",
            r"é€šè¿‡.*[æ–¹å¼|æ‰‹æ®µ|é€”å¾„]",
            r"å€ŸåŠ©.*[å®ç°|å®Œæˆ|è§£å†³]",
        ]

        count = 0
        for pattern in tool_patterns:
            count += len(re.findall(pattern, text))

        return min(count, 5)  # é™åˆ¶æœ€å¤§æ•°é‡

    def _generate_quality_feedback(
        self, novelty: float, depth: float, interaction: float, practicality: float
    ) -> str:
        """ç”Ÿæˆè´¨é‡åé¦ˆ"""
        feedback_parts = []

        # æ€»ä½“è¯„ä»·
        overall = (novelty + depth + interaction + practicality) / 4
        if overall >= 8.0:
            feedback_parts.append("ğŸŒŸ è¾©è®ºè´¨é‡ä¼˜ç§€")
        elif overall >= 6.5:
            feedback_parts.append("âœ… è¾©è®ºè´¨é‡è‰¯å¥½")
        elif overall >= 5.0:
            feedback_parts.append("âš ï¸ è¾©è®ºè´¨é‡ä¸€èˆ¬")
        else:
            feedback_parts.append("âŒ è¾©è®ºè´¨é‡éœ€è¦æ”¹è¿›")

        # å„é¡¹å…·ä½“è¯„ä»·
        if novelty >= 7.5:
            feedback_parts.append("è§‚ç‚¹æ–°é¢–ç‹¬ç‰¹")
        elif novelty < 5.0:
            feedback_parts.append("ç¼ºä¹åˆ›æ–°æ€ç»´")

        if depth >= 7.5:
            feedback_parts.append("è®ºè¯æ·±å…¥é€å½»")
        elif depth < 5.0:
            feedback_parts.append("åˆ†ææ·±åº¦ä¸å¤Ÿ")

        if interaction >= 7.5:
            feedback_parts.append("ä¸“å®¶äº’åŠ¨å……åˆ†")
        elif interaction < 5.0:
            feedback_parts.append("ç¼ºä¹æœ‰æ•ˆäº’åŠ¨")

        if practicality >= 7.5:
            feedback_parts.append("å»ºè®®å®ç”¨å¯è¡Œ")
        elif practicality < 5.0:
            feedback_parts.append("å®ç”¨æ€§æœ‰å¾…æå‡")

        return "ï¼Œ".join(feedback_parts)


class DebateQualityMonitor:
    """è¾©è®ºè´¨é‡ç›‘æ§å™¨"""

    def __init__(self) -> None:
        self.analyzer = DebateQualityAnalyzer()
        self.quality_thresholds = {
            "excellent": 8.0,
            "good": 6.5,
            "average": 5.0,
            "poor": 3.5,
        }

    def monitor_session(self, session: PKSession) -> str | None:
        """ç›‘æ§ä¼šè¯è´¨é‡ï¼Œè¿”å›å»ºè®®"""
        if not session.responses or len(session.responses) < 2:
            return None

        # åˆ†æå½“å‰è´¨é‡
        current_metrics = self.analyzer.analyze_session_quality(session)

        # æ›´æ–°ä¼šè¯è´¨é‡æŒ‡æ ‡
        session.update_quality_metrics(current_metrics)

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        suggestions = self._generate_improvement_suggestions(current_metrics, session)

        return suggestions

    def _generate_improvement_suggestions(
        self, metrics: DebateQualityMetrics, session: PKSession
    ) -> str | None:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # åŸºäºå½“å‰è´¨é‡æŒ‡æ ‡ç”Ÿæˆå»ºè®®
        if metrics.novelty_score < 6.0:
            suggestions.append("å»ºè®®ä¸“å®¶ä»¬æä¾›æ›´å¤šåˆ›æ–°æ€§è§‚ç‚¹å’Œç‹¬ç‰¹è§è§£")

        if metrics.depth_score < 6.0:
            suggestions.append("å»ºè®®æ·±å…¥åˆ†æé—®é¢˜çš„æ ¹æœ¬åŸå› å’Œå†…åœ¨æœºåˆ¶")

        if metrics.interaction_score < 6.0:
            suggestions.append("å»ºè®®ä¸“å®¶ä»¬æ›´å¤šåœ°å›åº”å’Œæ‰¹è¯„å…¶ä»–äººçš„è§‚ç‚¹")

        if metrics.practicality_score < 6.0:
            suggestions.append("å»ºè®®æä¾›æ›´å¤šå…·ä½“å¯è¡Œçš„è§£å†³æ–¹æ¡ˆå’Œæ“ä½œæ­¥éª¤")

        # åŸºäºè½®æ¬¡è¿›åº¦ç»™å‡ºå»ºè®®
        if session.current_round == 2 and metrics.interaction_score < 5.0:
            suggestions.append("å½“å‰æ˜¯äº¤å‰è¾©è®ºé˜¶æ®µï¼Œå»ºè®®ä¸“å®¶ä»¬ç§¯æå›åº”å…¶ä»–äººçš„è§‚ç‚¹")

        if (
            session.current_round == session.max_rounds - 1
            and metrics.practicality_score < 6.0
        ):
            suggestions.append("å³å°†è¿›å…¥æœ€ç»ˆé˜¶æ®µï¼Œå»ºè®®ä¸“å®¶ä»¬æä¾›æ›´å¤šå®ç”¨æ€§å»ºè®®")

        # åŠ¨æ€è½®æ¬¡è°ƒæ•´å»ºè®®ï¼ˆè‡ªç”±è¾©è®ºæ¨¡å¼ï¼‰
        if session.debate_mode.value == "free":
            if metrics.overall_score < 5.0 and session.current_round >= 3:
                suggestions.append("å»ºè®®å¢åŠ è½®æ¬¡ï¼Œä»¥æå‡è®¨è®ºè´¨é‡")
            elif metrics.overall_score >= 8.0 and session.current_round >= 2:
                suggestions.append("è®¨è®ºè´¨é‡å·²è¾¾åˆ°ä¼˜ç§€æ°´å¹³ï¼Œå¯è€ƒè™‘æå‰ç»“æŸ")

        return "ï¼›".join(suggestions) if suggestions else None

    def should_extend_debate(self, session: PKSession) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å»¶é•¿è¾©è®º"""
        if session.debate_mode.value != "free":
            return False

        if not session.quality_metrics:
            return False

        # è´¨é‡ä¸è¶³ä¸”æœªè¾¾åˆ°æœ€å¤§è½®æ•°æ—¶ï¼Œå»ºè®®å»¶é•¿
        return session.quality_metrics.overall_score < 6.0 and session.current_round < 6

    def should_end_debate_early(self, session: PKSession) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æå‰ç»“æŸè¾©è®º"""
        if session.debate_mode.value != "free":
            return False

        if not session.quality_metrics:
            return False

        # è´¨é‡ä¼˜ç§€ä¸”è‡³å°‘å®Œæˆ2è½®æ—¶ï¼Œå¯ä»¥æå‰ç»“æŸ
        return (
            session.quality_metrics.overall_score >= 8.5 and session.current_round >= 2
        )
