{
    "config": {
        "abort": {
            "already_configured": "Slu\u017eba je ji\u017e nastavena",
            "download_failed": "Sta\u017een\u00ed modelu se nezda\u0159ilo"
        },
        "error": {
            "cannot_connect": "Nepoda\u0159ilo se p\u0159ipojit",
            "unknown": "Neo\u010dek\u00e1van\u00e1 chyba"
        },
        "progress": {
            "download": "Po\u010dkejte, ne\u017e se model st\u00e1hne, co\u017e m\u016f\u017ee trvat velmi dlouho. Dal\u0161\u00ed podrobnosti naleznete v protokolech serveru Ollama."
        },
        "step": {
            "download": {
                "title": "Stahov\u00e1n\u00ed modelu"
            },
            "user": {
                "data": {
                    "model": "Model",
                    "url": "URL"
                }
            }
        }
    },
    "config_subentries": {
        "conversation": {
            "abort": {
                "entry_not_loaded": "Nelze p\u0159id\u00e1vat polo\u017eky, pokud je nastaven\u00ed zak\u00e1z\u00e1no.",
                "reconfigure_successful": "P\u0159enastaven\u00ed bylo \u00fasp\u011b\u0161n\u00e9"
            },
            "entry_type": "Agent pro konverzaci",
            "initiate_flow": {
                "reconfigure": "P\u0159enastavit agenta pro konverzaci",
                "user": "P\u0159idat agenta pro konverzaci"
            },
            "step": {
                "set_options": {
                    "data": {
                        "keep_alive": "Udr\u017eet na\u017eivu",
                        "llm_hass_api": "Ovl\u00e1d\u00e1n\u00ed Home Assistanta",
                        "max_history": "Maxim\u00e1ln\u00ed po\u010det zpr\u00e1v historie",
                        "name": "N\u00e1zev",
                        "num_ctx": "Velikost kontextov\u00e9ho okna",
                        "prompt": "Instrukce",
                        "think": "P\u0159em\u00fd\u0161let p\u0159ed odpov\u011bd\u00ed"
                    },
                    "data_description": {
                        "keep_alive": "Doba v sekund\u00e1ch, po kterou Ollama uchov\u00e1 model v pam\u011bti. -1 = neur\u010dit\u00e9, 0 = nikdy.",
                        "num_ctx": "Maxim\u00e1ln\u00ed po\u010det textov\u00fdch token\u016f, kter\u00e9 m\u016f\u017ee model zpracovat. Ni\u017e\u0161\u00ed pro sn\u00ed\u017een\u00ed RAM Ollamy nebo vy\u0161\u0161\u00ed pro velk\u00fd po\u010det vystaven\u00fdch entit.",
                        "prompt": "Pokyn, jak by m\u011bl LLM reagovat. M\u016f\u017ee se jednat o \u0161ablonu.",
                        "think": "Pokud je tato volba povolena, LLM si promysl\u00ed odpov\u011b\u010f. To m\u016f\u017ee zlep\u0161it kvalitu odpov\u011bdi, ale m\u016f\u017ee to zv\u00fd\u0161it zpo\u017ed\u011bn\u00ed."
                    }
                }
            }
        }
    }
}