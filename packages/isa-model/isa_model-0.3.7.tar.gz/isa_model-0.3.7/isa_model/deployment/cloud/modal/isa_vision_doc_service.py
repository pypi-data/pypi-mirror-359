"""
ISA Vision Document Service

Specialized service for document analysis including:
- Table detection (Table Transformer Detection)
- Table structure recognition (Table Transformer Structure v1.1) 
- OCR text extraction (PaddleOCR 3.0)
"""

import modal
import torch
import base64
import io
import numpy as np
from PIL import Image
from typing import Dict, List, Optional, Any
import time
import json
import os
import logging

# Define Modal application
app = modal.App("isa-vision-doc")

# Download document analysis models
def download_doc_models():
    """Download document analysis models"""
    from huggingface_hub import snapshot_download
    import subprocess
    
    print("üì¶ Downloading document analysis models...")
    os.makedirs("/models", exist_ok=True)
    
    # Download Table Transformer Detection
    try:
        snapshot_download(
            repo_id="microsoft/table-transformer-detection",
            local_dir="/models/table-transformer-detection",
            allow_patterns=["**/*.pt", "**/*.pth", "**/*.bin", "**/*.json", "**/*.safetensors"]
        )
        print("‚úÖ Table Transformer Detection downloaded")
    except Exception as e:
        print(f"‚ö†Ô∏è Table Transformer Detection download failed: {e}")
    
    # Download Table Transformer Structure Recognition v1.1
    try:
        snapshot_download(
            repo_id="microsoft/table-transformer-structure-recognition-v1.1-all",
            local_dir="/models/table-transformer-structure",
            allow_patterns=["**/*.pt", "**/*.pth", "**/*.bin", "**/*.json", "**/*.safetensors"]
        )
        print("‚úÖ Table Transformer Structure Recognition v1.1 downloaded")
    except Exception as e:
        print(f"‚ö†Ô∏è Table Transformer Structure Recognition download failed: {e}")
    
    # Install PaddleOCR
    try:
        subprocess.run(["pip", "install", "paddleocr>=2.7.0", "--no-deps"], check=True)
        print("‚úÖ PaddleOCR installed")
    except Exception as e:
        print(f"‚ö†Ô∏è PaddleOCR install failed: {e}")
    
    print("üì¶ Document analysis models download completed")

# Define Modal container image
image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install([
        # OpenGL and graphics libraries for PaddleOCR
        "libgl1-mesa-glx",
        "libglib2.0-0",
        "libsm6",
        "libxext6",
        "libxrender-dev",
        "libgomp1",
        # Font support
        "fontconfig",
        "libfontconfig1",
        "libfreetype6",
    ])
    .pip_install([
        # Core AI libraries
        "torch>=2.0.0",
        "torchvision",
        "transformers>=4.35.0",
        "huggingface_hub",
        "accelerate",
        
        # Image processing
        "pillow>=10.0.1",
        "opencv-python-headless",
        "numpy>=1.24.3",
        
        # OCR libraries - Latest stable versions
        "paddleocr>=3.0.0",
        "paddlepaddle>=3.0.0",
        
        # HTTP libraries
        "httpx>=0.26.0",
        "requests",
        
        # Utilities
        "pydantic>=2.0.0",
        "python-dotenv",
    ])
    .run_function(download_doc_models)
    .env({
        "TRANSFORMERS_CACHE": "/models",
        "FONTCONFIG_PATH": "/etc/fonts",
        "KMP_DUPLICATE_LIB_OK": "TRUE",
        "OMP_NUM_THREADS": "1",
        "CUDA_VISIBLE_DEVICES": "0"
    })
)

# Document Analysis Service
@app.cls(
    gpu="T4",
    image=image,
    memory=16384,  # 16GB RAM
    timeout=1800,  # 30 minutes
    scaledown_window=60,   # 1 minute idle timeout
    min_containers=0,  # Scale to zero when not in use
)
class DocumentAnalysisService:
    """
    Document Analysis Service
    
    Provides document analysis capabilities including:
    - Table detection and structure recognition
    - OCR text extraction
    - Combined document parsing
    """
    
    def __init__(self):
        self.models = {}
        self.logger = logging.getLogger(__name__)
        
    @modal.enter()
    def load_models(self):
        """Load document analysis models on container startup"""
        print("üöÄ Loading document analysis models...")
        start_time = time.time()
        
        try:
            import sys
            # Check system environment
            print(f"üîß System info:")
            print(f"   - Python version: {sys.version}")
            print(f"   - PyTorch version: {torch.__version__}")
            print(f"   - CUDA available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"   - CUDA version: {torch.version.cuda}")
                print(f"   - GPU count: {torch.cuda.device_count()}")
            
            # Load table detection models
            self._load_table_models()
            
            # Load OCR models
            self._load_ocr_models()
            
            load_time = time.time() - start_time
            print(f"‚úÖ Document analysis models loaded in {load_time:.2f}s")
            
            # Verify models are loaded
            if not self.models.get('ocr'):
                print("‚ö†Ô∏è OCR model failed to load - service will use fallback")
            
        except Exception as e:
            print(f"‚ùå Critical error during model loading: {e}")
            import traceback
            traceback.print_exc()
            # Don't raise - let service start with degraded functionality
        
    def _load_table_models(self):
        """Load table detection and structure recognition models"""
        print("üìä Loading table analysis models...")
        
        # TODO: Implement actual Table Transformer loading
        # For now, we don't load these models to avoid mock data
        print("‚ö†Ô∏è Table Transformer models not implemented yet")
        print("   - Table detection will return empty results")
        print("   - Table structure analysis will return empty results")
        
    def _load_ocr_models(self):
        """Load OCR models"""
        print("üî§ Loading OCR models...")
        
        try:
            import os
            # Set environment variables to prevent conflicts and optimize performance
            os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
            os.environ['OMP_NUM_THREADS'] = '1'
            os.environ['MKLDNN_DISABLED'] = '1'  # Disable MKLDNN to force GPU usage
            
            from paddleocr import PaddleOCR
            
            # Initialize PaddleOCR 3.0 with minimal configuration
            # PaddleOCR 3.0 uses PP-OCRv5_server model by default which supports multiple languages
            self.models['ocr'] = PaddleOCR(
                use_angle_cls=True,  # Enable text direction classification
                lang='ch'            # Chinese language (also supports English in the same model)
            )
            print("‚úÖ PaddleOCR loaded successfully with official defaults")
            print(f"   - GPU available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"   - CUDA device: {torch.cuda.get_device_name(0)}")
                print(f"   - CUDA version: {torch.version.cuda}")
            
            # Test OCR initialization
            print("üîç Testing OCR initialization...")
            
        except Exception as e:
            print(f"‚ö†Ô∏è PaddleOCR loading failed: {e}")
            import traceback
            traceback.print_exc()
            self.models['ocr'] = None
    
    @modal.method()
    def detect_tables(self, image_b64: str) -> Dict[str, Any]:
        """
        Detect tables in document image
        
        Args:
            image_b64: Base64 encoded image
            
        Returns:
            Table detection results
        """
        start_time = time.time()
        
        try:
            # Decode image
            image = self._decode_image(image_b64)
            image_np = np.array(image)
            
            # Perform table detection
            tables = self._detect_tables_impl(image_np)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'service': 'isa-vision-doc',
                'function': 'table_detection',
                'tables': tables,
                'table_count': len(tables),
                'processing_time': processing_time,
                'model_info': {
                    'detector': 'Table Transformer Detection',
                    'gpu': 'T4'
                }
            }
            
        except Exception as e:
            self.logger.error(f"Table detection failed: {e}")
            return {
                'success': False,
                'service': 'isa-vision-doc',
                'function': 'table_detection',
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    @modal.method()
    def analyze_table_structure(self, image_b64: str, table_bbox: List[int] = None) -> Dict[str, Any]:
        """
        Analyze table structure in image
        
        Args:
            image_b64: Base64 encoded image
            table_bbox: Optional bounding box of table [x1, y1, x2, y2]
            
        Returns:
            Table structure analysis results
        """
        start_time = time.time()
        
        try:
            # Decode image
            image = self._decode_image(image_b64)
            image_np = np.array(image)
            
            # Crop to table region if bbox provided
            if table_bbox:
                x1, y1, x2, y2 = table_bbox
                image_np = image_np[y1:y2, x1:x2]
            
            # Analyze table structure
            structure = self._analyze_table_structure_impl(image_np)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'service': 'isa-vision-doc',
                'function': 'table_structure',
                'structure': structure,
                'processing_time': processing_time,
                'model_info': {
                    'analyzer': 'Table Transformer Structure Recognition v1.1',
                    'gpu': 'T4'
                }
            }
            
        except Exception as e:
            self.logger.error(f"Table structure analysis failed: {e}")
            return {
                'success': False,
                'service': 'isa-vision-doc',
                'function': 'table_structure',
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    @modal.method()
    def extract_text(self, image_b64: str, regions: List[Dict] = None) -> Dict[str, Any]:
        """
        Extract text from document image using OCR
        
        Args:
            image_b64: Base64 encoded image
            regions: Optional list of regions to focus OCR on
            
        Returns:
            OCR text extraction results
        """
        start_time = time.time()
        
        try:
            # Decode image
            image = self._decode_image(image_b64)
            image_np = np.array(image)
            
            # Perform OCR
            text_results = self._extract_text_impl(image_np, regions)
            
            processing_time = time.time() - start_time
            
            return {
                'success': True,
                'service': 'isa-vision-doc',
                'function': 'ocr',
                'text_results': text_results,
                'text_count': len(text_results),
                'processing_time': processing_time,
                'model_info': {
                    'ocr_engine': 'PaddleOCR 3.0',
                    'gpu': 'T4'
                }
            }
            
        except Exception as e:
            self.logger.error(f"OCR extraction failed: {e}")
            return {
                'success': False,
                'service': 'isa-vision-doc',
                'function': 'ocr',
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    @modal.method()
    def analyze_document_complete(self, image_b64: str) -> Dict[str, Any]:
        """
        Complete document analysis: tables + structure + OCR
        
        Args:
            image_b64: Base64 encoded image
            
        Returns:
            Complete document analysis results
        """
        start_time = time.time()
        
        try:
            # Decode image once for all operations
            image = self._decode_image(image_b64)
            image_np = np.array(image)
            
            # Step 1: Detect tables
            tables = self._detect_tables_impl(image_np)
            table_detection_start = time.time()
            table_result = {
                'success': True,
                'tables': tables,
                'processing_time': time.time() - table_detection_start
            }
            
            # Step 2: Extract text
            ocr_start = time.time()
            text_results = self._extract_text_impl(image_np)
            ocr_result = {
                'success': True,
                'text_results': text_results,
                'processing_time': time.time() - ocr_start
            }
            
            # Step 3: Analyze table structures if tables found
            structure_results = []
            if table_result.get('success') and table_result.get('tables'):
                for table in table_result['tables']:
                    if 'bbox' in table:
                        x1, y1, x2, y2 = table['bbox']
                        table_image = image_np[y1:y2, x1:x2]
                        structure = self._analyze_table_structure_impl(table_image)
                        structure_results.append(structure)
            
            total_time = time.time() - start_time
            
            return {
                'success': True,
                'service': 'isa-vision-doc',
                'function': 'complete_analysis',
                'total_execution_time': total_time,
                'results': {
                    'tables': table_result.get('tables', []),
                    'table_structures': structure_results,
                    'text_extraction': ocr_result.get('text_results', [])
                },
                'summary': {
                    'tables_found': len(table_result.get('tables', [])),
                    'text_regions_found': len(ocr_result.get('text_results', [])),
                    'structures_analyzed': len(structure_results)
                },
                'performance_metrics': {
                    'table_detection_time': table_result.get('processing_time', 0),
                    'ocr_time': ocr_result.get('processing_time', 0),
                    'total_time': total_time,
                    'platform': 'modal'
                }
            }
            
        except Exception as e:
            self.logger.error(f"Complete document analysis failed: {e}")
            return {
                'success': False,
                'service': 'isa-vision-doc',
                'function': 'complete_analysis',
                'error': str(e),
                'total_execution_time': time.time() - start_time
            }
    
    def _detect_tables_impl(self, image_np: np.ndarray) -> List[Dict[str, Any]]:
        """Implementation of table detection"""
        print("üîç Table detection requested but not implemented")
        print("‚ö†Ô∏è Table Transformer models need to be properly loaded")
        
        # Return empty list since we don't have real table detection yet
        # TODO: Implement actual Table Transformer Detection
        return []
    
    def _analyze_table_structure_impl(self, image_np: np.ndarray) -> Dict[str, Any]:
        """Implementation of table structure analysis"""
        print("üìä Table structure analysis requested but not implemented")
        print("‚ö†Ô∏è Table Transformer Structure Recognition models need to be properly loaded")
        
        # Return empty structure since we don't have real table structure analysis yet
        # TODO: Implement actual Table Transformer Structure Recognition
        return {
            'rows': 0,
            'columns': 0,
            'cells': [],
            'confidence': 0.0
        }
    
    def _extract_text_impl(self, image_np: np.ndarray, regions: List[Dict] = None) -> List[Dict[str, Any]]:
        """Implementation of OCR text extraction"""
        print(f"üîç Debug: OCR model in models: {'ocr' in self.models}")
        print(f"üîç Debug: OCR model value: {self.models.get('ocr')}")
        print(f"üîç Debug: OCR model is not None: {self.models.get('ocr') is not None}")
        
        if self.models.get('ocr') is not None:
            try:
                print("üî§ Using real PaddleOCR for text extraction...")
                ocr = self.models['ocr']
                print(f"üîç Debug: OCR object type: {type(ocr)}")
                
                # Ensure image is in correct format for PaddleOCR
                if len(image_np.shape) == 3 and image_np.shape[2] == 3:
                    # Convert RGB to BGR for OpenCV/PaddleOCR
                    image_bgr = image_np[:, :, ::-1]
                else:
                    image_bgr = image_np
                
                print(f"üîç Image shape for OCR: {image_bgr.shape}")
                print(f"üîç Image dtype: {image_bgr.dtype}")
                print(f"üîç Image min/max values: {image_bgr.min()}/{image_bgr.max()}")
                
                # Save debug image to check what we're actually sending to OCR
                try:
                    import cv2
                    cv2.imwrite('/tmp/debug_ocr_input.jpg', image_bgr)
                    print("üîç Debug image saved to /tmp/debug_ocr_input.jpg")
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to save debug image: {e}")
                
                # Run PaddleOCR (angle classification is now built-in for v3.0)
                print("üîç Calling PaddleOCR...")
                result = ocr.ocr(image_bgr)
                print(f"üîç PaddleOCR completed, raw result type: {type(result)}")
                
                text_results = []
                print(f"üîç Checking result: result={bool(result)}, result length={len(result) if result else 0}")
                if result:
                    print(f"üîç First result element exists: {result[0] is not None}")
                    print(f"üîç First result type: {type(result[0])}")
                    print(f"üîç First result bool: {bool(result[0])}")
                    
                    # Try to get length safely
                    try:
                        print(f"üîç First result length: {len(result[0])}")
                    except Exception as e:
                        print(f"üîç Cannot get length: {e}")
                
                print(f"üîç About to check if result[0] is truthy...")
                if result and result[0]:
                    first_result = result[0]
                    
                    # Debug: check what attributes the object actually has
                    print(f"üîç Object attributes: {dir(first_result)}")
                    print(f"üîç Has rec_texts: {hasattr(first_result, 'rec_texts')}")
                    
                    # Check if it's PaddleOCR 3.0+ OCRResult object
                    if hasattr(first_result, 'rec_texts'):
                        print(f"üîç Processing PaddleOCR 3.0+ OCRResult with {len(first_result.rec_texts)} text regions...")
                        
                        rec_texts = first_result.rec_texts
                        rec_scores = first_result.rec_scores
                        rec_boxes = first_result.rec_boxes
                        
                        for idx in range(len(rec_texts)):
                            text = rec_texts[idx]
                            confidence = rec_scores[idx]
                            bbox = rec_boxes[idx]  # Should be [x1, y1, x2, y2]
                            
                            text_results.append({
                                'id': f'text_{idx}',
                                'text': text,
                                'confidence': float(confidence),
                                'bbox': [int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])],
                                'center': [
                                    (int(bbox[0]) + int(bbox[2])) // 2,
                                    (int(bbox[1]) + int(bbox[3])) // 2
                                ]
                            })
                    
                    else:
                        print(f"üîç Processing legacy format with {len(first_result)} text regions...")
                        for idx, line in enumerate(first_result):
                            bbox = line[0]  # Bounding box points
                            text_info = line[1]  # (text, confidence)
                            
                            if text_info and len(text_info) >= 2:
                                # Convert bbox points to [x1, y1, x2, y2]
                                x_coords = [point[0] for point in bbox]
                                y_coords = [point[1] for point in bbox]
                                bbox_rect = [
                                    int(min(x_coords)),
                                    int(min(y_coords)), 
                                    int(max(x_coords)),
                                    int(max(y_coords))
                                ]
                                
                                text_results.append({
                                    'id': f'text_{idx}',
                                    'text': text_info[0],
                                    'confidence': text_info[1],
                                    'bbox': bbox_rect,
                                    'center': [
                                        (bbox_rect[0] + bbox_rect[2]) // 2,
                                        (bbox_rect[1] + bbox_rect[3]) // 2
                                    ]
                                })
                
                print(f"‚úÖ Real PaddleOCR extraction: {len(text_results)} text regions found")
                return text_results
                
            except Exception as e:
                print(f"‚ùå PaddleOCR failed: {e}")
                import traceback
                traceback.print_exc()
        
        # No fallback - return empty if PaddleOCR is not available
        print("‚ùå PaddleOCR not available, returning empty results")
        return []
    
    @modal.method()
    def health_check(self) -> Dict[str, Any]:
        """Health check endpoint"""
        return {
            'status': 'healthy',
            'service': 'isa-vision-doc',
            'models_loaded': list(self.models.keys()),
            'capabilities': ['table_detection', 'table_structure', 'ocr'],
            'timestamp': time.time(),
            'gpu': 'T4'
        }
    
    def _decode_image(self, image_b64: str) -> Image.Image:
        """Decode base64 image"""
        if image_b64.startswith('data:image'):
            image_b64 = image_b64.split(',')[1]
        
        image_data = base64.b64decode(image_b64)
        return Image.open(io.BytesIO(image_data)).convert('RGB')

# Auto-registration function
@app.function() 
async def register_service():
    """Auto-register this service in the model registry"""
    try:
        import sys
        from pathlib import Path
        
        # Add project root to path for imports
        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))
        
        try:
            from isa_model.core.model_manager import ModelManager
            from isa_model.core.model_repo import ModelType, ModelCapability
            from isa_model.core.service_registry import ServiceRegistry
            from isa_model.core.types import ServiceType, DeploymentPlatform, ServiceStatus, ResourceRequirements
            from isa_model.core.model_service import ModelService
        except ImportError:
            # Fallback if import fails in Modal environment
            print("‚ö†Ô∏è Could not import required modules - registration skipped")
            return {"success": False, "error": "Required modules not available"}
        
        # Use ModelManager to register this service
        model_manager = ModelManager()
        
        # 1. First register the underlying model (backward compatibility)
        model_success = model_manager.registry.register_model(
            model_id="isa-vision-doc-service",
            model_type=ModelType.VISION,
            capabilities=[
                ModelCapability.TABLE_DETECTION,
                ModelCapability.TABLE_STRUCTURE_RECOGNITION,
                ModelCapability.OCR,
                ModelCapability.IMAGE_ANALYSIS
            ],
            metadata={
                "description": "ISA Vision Document Analysis Service with table detection, structure recognition, and OCR",
                "service_name": "isa-vision-doc",
                "service_type": "modal",
                "deployment_type": "modal",
                "endpoint": "https://isa-vision-doc.modal.run",
                "underlying_models": [
                    "microsoft/table-transformer-detection",
                    "microsoft/table-transformer-structure-recognition-v1.1-all",
                    "PaddleOCR 3.0"
                ],
                "gpu_requirement": "T4",
                "memory_mb": 16384,
                "auto_registered": True,
                "registered_by": "isa_vision_doc_service.py",
                "is_service": True,  # Mark this as a service, not a raw model
                "capabilities_details": {
                    "table_detection": "Microsoft Table Transformer Detection",
                    "table_structure": "Microsoft Table Transformer Structure Recognition v1.1",
                    "ocr": "PaddleOCR 3.0 with Chinese/English support"
                }
            }
        )
        
        # 2. Register as a deployed service in the ServiceRegistry (MaaS platform)
        service_success = False
        try:
            service_registry = ServiceRegistry(model_manager.registry)
            
            # Create ModelService instance
            service = ModelService(
                service_id="isa-vision-doc-modal-001",
                service_name="isa_vision_doc",
                model_id="isa-vision-doc-service",
                deployment_platform=DeploymentPlatform.MODAL,
                service_type=ServiceType.VISION,
                status=ServiceStatus.HEALTHY,
                inference_endpoint="https://isa-vision-doc.modal.run/analyze_document_complete",
                health_endpoint="https://isa-vision-doc.modal.run/health_check",
                capabilities=["table_detection", "table_structure_recognition", "ocr", "image_analysis"],
                resource_requirements=ResourceRequirements(
                    gpu_type="T4",
                    memory_mb=16384,
                    cpu_cores=4,
                    min_replicas=0,
                    max_replicas=5
                ),
                metadata={
                    "description": "ISA Vision Document Analysis Service with table detection, structure recognition, and OCR",
                    "underlying_models": [
                        "microsoft/table-transformer-detection",
                        "microsoft/table-transformer-structure-recognition-v1.1-all",
                        "PaddleOCR 3.0"
                    ],
                    "auto_scaling": True,
                    "scale_to_zero": True,
                    "platform": "modal",
                    "registered_by": "isa_vision_doc_service.py"
                }
            )
            
            # Register in ServiceRegistry
            service_success = await service_registry.register_service(service)
            
            if service_success:
                print("‚úÖ Service registered in MaaS platform ServiceRegistry")
            else:
                print("‚ö†Ô∏è ServiceRegistry registration failed")
                
        except Exception as e:
            print(f"‚ö†Ô∏è ServiceRegistry registration error: {e}")
        
        if model_success:
            print("‚úÖ Model registry registration successful")
        else:
            print("‚ö†Ô∏è Model registry registration failed")
            
        overall_success = model_success and service_success
        return {
            "success": overall_success, 
            "model_registry": model_success,
            "service_registry": service_success
        }
        
    except Exception as e:
        print(f"‚ùå Auto-registration error: {e}")
        return {"success": False, "error": str(e)}

# Quick deployment function
@app.function()
def deploy_service():
    """Deploy this service instantly"""
    import subprocess
    import os
    
    print("üöÄ Deploying ISA Vision Document Service...")
    try:
        # Get the current file path
        current_file = __file__
        
        # Run modal deploy command
        result = subprocess.run(
            ["modal", "deploy", current_file],
            capture_output=True,
            text=True,
            check=True
        )
        
        print("‚úÖ Deployment completed successfully!")
        print(f"üìù Output: {result.stdout}")
        return {"success": True, "output": result.stdout}
        
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Deployment failed: {e}")
        print(f"üìù Error: {e.stderr}")
        return {"success": False, "error": str(e), "stderr": e.stderr}

if __name__ == "__main__":
    print("üöÄ ISA Vision Document Service - Modal Deployment")
    print("Deploy with: modal deploy isa_vision_doc_service.py")
    print("Or call: modal run isa_vision_doc_service.py::deploy_service")
    print("Note: Requires T4 GPU and 16GB+ RAM for optimal performance")
    print("\nüìù Service will auto-register in model registry upon deployment")