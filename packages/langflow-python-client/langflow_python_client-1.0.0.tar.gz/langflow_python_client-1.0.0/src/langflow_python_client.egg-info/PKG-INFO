Metadata-Version: 2.4
Name: langflow-python-client
Version: 1.0.0
Summary: Async Python client library for interacting with Langflow API servers
Author-email: Adri√°n Noya Carro <anoya@ikerlan.es>
License: MIT
Project-URL: Repository, https://github.com/MattinAI/langflow-client
Project-URL: Homepage, https://github.com/MattinAI/langflow-client
Project-URL: Issues, https://github.com/MattinAI/langflow-client/issues
Keywords: langflow,client,api,ai,llm,async,python
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Internet :: WWW/HTTP :: HTTP Servers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Typing :: Typed
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: httpx>=0.24.0
Requires-Dist: pydantic>=2.11.0
Requires-Dist: aiofiles>=24.1.0
Provides-Extra: dev
Requires-Dist: pytest>=8.3.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.24.0; extra == "dev"
Requires-Dist: pytest-httpx>=0.32.0; extra == "dev"
Requires-Dist: pytest-cov>=6.2.0; extra == "dev"
Requires-Dist: black>=24.0.0; extra == "dev"
Requires-Dist: isort>=5.13.0; extra == "dev"
Requires-Dist: ruff>=0.6.0; extra == "dev"
Requires-Dist: mypy>=1.11.0; extra == "dev"
Requires-Dist: coverage[toml]>=7.6.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=8.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=3.0.0; extra == "docs"
Requires-Dist: myst-parser>=4.0.0; extra == "docs"
Dynamic: license-file

# Langflow Python Client

An async Python client library for interacting with Langflow API servers.

[![PyPI version](https://badge.fury.io/py/langflow-python-client.svg)](https://badge.fury.io/py/langflow-python-client)
[![Python Support](https://img.shields.io/pypi/pyversions/langflow-python-client.svg)](https://pypi.org/project/langflow-python-client/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Features

Features

- üöÄ Async/await support - Built with modern Python async patterns for high performance
- üîê Authentication - Secure API key authentication for protected Langflow instances
- üéõÔ∏è Dynamic Tweaks - Modify flow behavior at runtime without changing flow definitions
- üìÅ File Upload - Upload files directly to flows for document processing and analysis
- üìù Type Safety - Full type annotation support with IDE autocomplete
- üîß Flexible Configuration - Support for different input/output types (text, chat)
- üêç Python 3.10+ - Compatible with modern Python versions

## Installation

```bash
pip install langflow-python-client
```

## Quick Start
### Basic Usage

```python
import asyncio
from langflow_client import LangflowClient, FlowRequestOptions
from langflow_client.constants import InputTypes, OutputTypes

async def main():
    # Initialize the client
    client = LangflowClient(
        base_url="http://localhost:7860"
    )
    
    # Get a flow instance
    flow = client.flow("your-flow-id")
    
    # Create request options
    options = FlowRequestOptions(
        input_type=InputTypes.TEXT,
        output_type=OutputTypes.TEXT,
        session_id="my-session"
    )
    
    # Run the flow
    result = await flow.run(
        "Hello, Langflow!",
        options=options
    )
    
    print(result)

# Run the async function
asyncio.run(main())
```

### Using Tweaks for Dynamic Configuration

Tweaks allow you to modify flow components at runtime without changing the flow definition:

```python
async def run_with_tweaks():
    client = LangflowClient(base_url="http://localhost:7860")
    
    # Create flow with component tweaks
    flow = client.flow("flow-id").tweak(**{
        "TextInput-ABC123": {
            "input_value": "Candidate CV content here..."
        },
        "OpenAI-DEF456": {
            "temperature": 0.7,
            "max_tokens": 500
        },
        "ChatOutput-GHI789": {
            "should_store_message": False
        }
    })
    
    # Run with options
    options = FlowRequestOptions(
        input_type=InputTypes.CHAT,
        output_type=OutputTypes.CHAT
    )
    
    result = await flow.run(options=options)
    return result
```

## Input and Output Types
The client supports different input and output types depending on your Langflow components:

| Type           | Description        | Use Case                              |
|----------------|--------------------|----------------------------------------|
| InputTypes.TEXT | Plain text input   | Simple text processing, document analysis |
| InputTypes.CHAT | Chat message format | Interactive chatbots, conversational AI  |
| OutputTypes.TEXT | Plain text output  | Clean text responses                     |
| OutputTypes.CHAT | Chat message format |  Interactive chatbots, conversational    |


### License
This project is licensed under the MIT License - see the LICENSE file for details.
