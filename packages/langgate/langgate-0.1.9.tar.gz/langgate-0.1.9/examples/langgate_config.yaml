# Sample configuration for LangGate
# Copy this file to langgate_config.yaml in your working directory
# or set the LANGGATE_CONFIG environment variable to point to this file.
# e.g. export LANGGATE_CONFIG=path/to/langgate_config.yaml

# Global default parameters (applied to all models)
default_params:
  temperature: 0.7

# Service provider configurations
services:
  openai:
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    model_patterns:
      # match any o-series model
      openai/o:
        remove_params:
          - temperature

  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com"
    model_patterns:
      # match any model with reasoning in the id
      reasoning:
        override_params:
          thinking:
            type: enabled
        remove_params:
          - temperature

# Model-specific configurations
models:
  - id: openai/gpt-4.1
    service:
      provider: openai
      model_id: gpt-4.1

  - id: openai/o3
    service:
      provider: openai
      model_id: o3

  - id: openai/o3-high
    service:
      provider: openai
      model_id: o3
    name: o3-high
    description: o3-high applies high-effort reasoning for the o3 model
    override_params:
      reasoning_effort: high

  - id: anthropic/claude-sonnet-4
    service:
      provider: anthropic
      model_id: claude-sonnet-4-0

  - id: anthropic/claude-sonnet-4-reasoning
    service:
      provider: anthropic
      model_id: claude-sonnet-4-0
    name: Claude-4 Sonnet R
    description: "Claude-4 Sonnet with reasoning capabilities."
    override_params:
      thinking:
        budget_tokens: 1024
