# ğŸš€ Locopilot

[![PyPI version](https://badge.fury.io/py/locopilot.svg)](https://badge.fury.io/py/locopilot)
[![Python](https://img.shields.io/pypi/pyversions/locopilot.svg)](https://pypi.org/project/locopilot/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/Ripan-Roy/locopilot-ai.svg?style=social&label=Star)](https://github.com/Ripan-Roy/locopilot-ai)

<div align="center">
  <img src="assets/locopilot-demo.png" alt="Locopilot Demo" width="800"/>
</div>

Locopilot is an open-source, local-first, agentic coding assistant built for developers. It leverages local LLMs (via Ollama), and advanced memory management using LangGraph, to automate, plan, and edit codebasesâ€”all inside an interactive shell.

- **Private**: All code and prompts stay on your machine.
- **Agentic**: Locopilot plans, edits, iterates, and manages your coding tasks.
- **Interactive**: Drop into a shell, enter tasks or slash commands, and steer the agent in real time.
- **Memory-Efficient**: Advanced memory compression via LangGraph for "infinite" context.
- **Extensible**: Change models, modes, and add custom tools or plugins on the fly.

## Table of Contents

- [Features](#features)
- [How It Works](#how-it-works)
- [Architecture](#architecture)
- [Getting Started](#getting-started)
- [Usage: Interactive Shell & Commands](#usage-interactive-shell--commands)
- [Project Structure](#project-structure)
- [Extensibility & Roadmap](#extensibility--roadmap)
- [Contributing](#contributing)
- [License](#license)

## âœ¨ Features

- **Local LLM Backend**: Bring your own Ollama server and code with any open-source LLM.
- **LangGraph Agent Workflow**: Plans, executes, edits, and compresses memory as a stateful, extensible graph.
- **Interactive Shell/REPL**: After init, drop into a chat-like agent terminalâ€”just type coding tasks or slash commands.
- **Slash Command Support**: `/model`, `/change-mode`, `/concise`, `/clear`, `/new`, `/end`, `/help`, and more.
- **Smart Memory Compression**: Automatically summarizes previous context using the LLM itself, supporting ultra-long sessions.
- **Configurable**: Models, modes, and summarization thresholds are all runtime-editable.
- **Pluggable Nodes**: Add file tools, planning modules, git ops, and vector-based retrieval easily.
- **(Planned) Git Integration**: Auto-commit, rollback, and view code diffs per agent step.

## âš¡ï¸ How It Works

### 1. Initialization
Run `locopilot init` in your project root.
- Locopilot checks Ollama, prompts for model, sets up `.locopilot/config.yaml`.
- You're dropped into an interactive agent shell (REPL).

### 2. Agentic Workflow (via LangGraph)
Each user input is parsed:
- **Slash command** (`/model`, etc.) â†’ runs as a graph branch.
- **Normal prompt** (task) â†’ plans, edits, summarizes via a workflow graph:
  ```
  User Task â†’ [Planning Node] â†’ [File Edit Node] â†’ [Memory Summarizer Node] â†’ (Repeat)
  ```
- Memory is managed with a LangGraph memory nodeâ€”summarizing, chunking, and compressing context as needed.

### 3. Session Management
- Change models, modes, or reset memory on the fly with slash commands.
- All state (memory, model, mode) persists during the session.

## ğŸ—ï¸ Architecture

Key components:

- **CLI Layer**: Typer-based CLI, launches shell (REPL), parses slash commands.
- **LangGraph Workflow**:
  - **Nodes**: Planning, file edit, summarization, slash command handler, etc.
  - **Edges**: Control session flow, branching between commands and prompts.
- **LLM Backend**:
  - **Ollama**: For running CodeLlama, DeepSeek, etc.
- **Memory Layer**:
  - LangChain/LangGraph memory objects (buffer, summary, vector, hybrid).
  - Summarizes old context using the LLM to avoid hitting token/window limits.
- **Config/Project Layer**:
  - `.locopilot/config.yaml` stores model/backend/session preferences.

### Stateful Graph Example:
```
               [User Input]
                      |
      +---------------+---------------+
      |                               |
 [Slash Command]              [Prompt/Task]
      |                               |
[Command Handler]   [Plan]->[Edit]->[Summarize]->[Memory]
      |                               |
     END                             Loop
```

## ğŸ›  Getting Started

### Requirements
- Python 3.8+
- Ollama running locally
- pip

### Install Locopilot

**Option 1: Install from PyPI (Recommended)**
```bash
pip install locopilot
```

**Option 2: Install from Source**
```bash
git clone https://github.com/Ripan-Roy/locopilot-ai.git
cd locopilot-backend
pip install -e .
```

### Start Your Local LLM

**Ollama:**
```bash
ollama serve
ollama pull codellama:latest
```

### Initialize and Enter the Agent Shell
```bash
locopilot init
```

This checks LLM backend, prompts for config, scans for project context, and launches the interactive shell.

## ğŸ–¥ï¸ Usage: Interactive Shell & Commands

After init, Locopilot enters a shell where you can type prompts and commands:

### Example Session
```
$ locopilot init
[âœ“] Ollama running. Model: codellama:latest
[âœ“] Project context initialized.

Locopilot Shell (mode: do):
> Add OAuth login to my Django app
[PLANNING] ...
[EDITING] ...
[MEMORY] ...

> /model
Current model: codellama:latest
Enter new model: deepseek-coder:latest
[âœ“] Model switched to deepseek-coder:latest

> /change-mode
Current mode: do
Available modes: do, refactor, explain, chat
Enter new mode: refactor
[âœ“] Mode set to refactor.

> Refactor the payment logic for clarity
...

> /concise
[âœ“] Context summarized and compressed.

> /clear
[âœ“] Session memory cleared.

> /new
[âœ“] New session started.

> /end
[âœ“] Session ended. Bye!
```

### Supported Slash Commands

| Command | Purpose |
|---------|---------|
| `/model` | Change LLM model/backend for current session |
| `/change-mode` | Switch between do, refactor, explain, chat modes |
| `/clear` | Clear all current context/memory |
| `/new` | Start a new session/project |
| `/end` | End the agent shell and exit |
| `/concise` | Force summarization/compression of current context |
| `/help` | Show help and command list |

Anything not starting with `/` is treated as a task in the current mode!

## ğŸ—‚ï¸ Project Structure

```
locopilot-backend/
â”œâ”€â”€ locopilot/                  # Main package directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                   # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py           # LangGraph workflow and nodes
â”‚   â”‚   â”œâ”€â”€ memory.py          # Session/context memory management
â”‚   â”‚   â””â”€â”€ executor.py        # Plan execution engine
â”‚   â”œâ”€â”€ llm/                    # LLM backend handling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ connection.py      # Ollama connection helpers
â”‚   â”‚   â””â”€â”€ backends/          # Backend-specific implementations
â”‚   â”œâ”€â”€ cli/                    # CLI components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py             # CLI entrypoint, shell/REPL logic
â”‚   â”‚   â””â”€â”€ commands/          # CLI command implementations
â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ file_ops.py        # File operations, config helpers
â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_basic.py
â”‚   â”œâ”€â”€ test_connection.py
â”‚   â””â”€â”€ test_plan_executor.py
â”œâ”€â”€ scripts/                    # Setup and utility scripts
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ assets/                     # Static assets
â”‚   â””â”€â”€ locopilot-demo.png
â”œâ”€â”€ pyproject.toml             # Package configuration
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## ğŸ§  Memory Management (with LangGraph)

- `ConversationBufferMemory` or `ConversationSummaryBufferMemory` is attached to the agent graph.
- As session context grows, old steps are summarized using the LLM and replaced in memory.
- This ensures Locopilot "remembers" key tasks, design decisions, and context for long sessions.
- Slash command `/concise` lets you summarize on demand.

## âš¡ï¸ Extensibility & Roadmap

- **Editor Plugins**: VSCode, Vim, JetBrains, etc.
- **Project-Aware RAG**: Integrate vector DBs (Chroma, Qdrant) for smart codebase retrieval.
- **(Planned) Git Integration**: Auto-commit, diff, and rollback per step.
- **Save/Load Sessions**: `/save`, `/load`, `/history` commands.
- **Custom Plugins/Nodes**: Add your own LangGraph nodes for tools or workflows.
- **Web/GUI Frontends**: Same agent core, different interface.

## ğŸ¤ Contributing

- Fork and PRs are welcome!
- Open issues for bugs or feature requests.
- For major features (graph nodes, memory backends), see CONTRIBUTING.md (coming soon).

## ğŸ“ License

MIT License. Use, fork, and extend as you wish!

## ğŸ’¡ Inspiration

Locopilot is inspired by Copilot, Claude Code, Dev-GPT, OpenDevin, and the emerging open-source agentic ecosystemâ€”aiming to empower developers with private, supercharged, customizable AI tools.

## ğŸš¦ Quickstart

```bash
# Install from PyPI
pip install locopilot

# Initialize in your project
locopilot init

# ... then just type your coding tasks and manage the session with slash commands!
```

**Links:**
- [PyPI Package](https://pypi.org/project/locopilot/)
- [GitHub Repository](https://github.com/Ripan-Roy/locopilot-ai)