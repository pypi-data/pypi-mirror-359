Metadata-Version: 2.1
Name: mlforget
Version: 0.1.0
Summary: Machine unlearning methods for energy consumption prediction
Home-page: https://github.com/Kaiboy55/MLForget
Author: Kai Pinas
Author-email: kai.pinas@student.uva.nl
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: scikit-learn

# Machine Unlearning Library

This library provides modular implementations of machine unlearning techniques for time-series data. It is designed for use in research, evaluation, and deployment scenarios where data privacy and the right to be forgotten are important.

##  Features

- Support for **Exact Retraining**, **SISA**, and **Knowledge Distillation** as unlearning strategies
- LSTM-based model architecture for building energy consumption prediction
- Modular preprocessing, training, evaluation, and unlearning components
- Support for measuring carbon emissions via CodeCarbon
- Designed as a reusable, extendable Python package

---

##  Project Structure

```
â”œâ”€â”€ data_utils.py         # Data loading, preprocessing, and forget set selection
â”œâ”€â”€ model_utils.py        # LSTM model definition
â”œâ”€â”€ training.py           # Training loops and model evaluation
â”œâ”€â”€ evaluation.py         # Metrics: RMSE, MAE, RÂ²
â”œâ”€â”€ unlearning.py         # Implementations of unlearning methods
â”œâ”€â”€ workflow.py           # High-level run_* functions for each unlearning method
â”œâ”€â”€ __init__.py           # Public API
```

---

##  Getting Started

### Installation

Clone the repository and make sure dependencies are installed:

```bash
pip install torch pandas scikit-learn
```

---

### Example Usage

```python
from Machine_Unlearning_Tool import (
    load_dataset, preprocess_data, run_sisa_unlearning
)

# Load and preprocess data
df = load_dataset("data/train.csv")
config = { ... }  # preprocessing configuration
df = preprocess_data(df, config)

# Convert to tensors and run SISA
X = ...
y = ...
results = run_sisa_unlearning(X, y, df, input_cols, target_col, id_col, forget_ids, device)
```

---

##  Public API Overview

### `load_dataset(filepath: str) -> pd.DataFrame`
Loads a dataset from CSV.

### `preprocess_data(df: pd.DataFrame, config: dict) -> pd.DataFrame`
Preprocesses the dataset using normalization and categorical encoding.

### `train_model(model, ...)`
Trains a PyTorch model on provided data.

### `run_sisa_unlearning(...)`
Performs SISA unlearning: slices and shards the dataset, retrains on retained data.

### `run_exact_retraining(...)`
Performs full retraining on retained data.

### `run_knowledge_distillation(...)`
Trains a student model using teacher model outputs while excluding forget set.

### `evaluate_on_loader(model, loader, loss_fn, device)`
Computes RMSE, MAE, and RÂ² metrics on a test or validation loader.

---

##  Output

Each `run_*` method returns:
- Trained model or model dictionary
- Pre- and post-unlearning performance metrics
- (Optional) CodeCarbon energy emission data

---

##  Notes

- Forget set is defined using user-specified `id_column` and list of IDs
- Can be extended with new models or additional unlearning methods
- Suitable for research on GDPR-compliant model behavior

---

##  License

No License specified.
