# Script that fetches the active (for now) players and writes to src/nfl_api/lib/data.py
# [PLAYER_ID: int, FIRST_NAME: str, LAST_NAME: str, FULL_NAME: str, IS_ACTIVE: BOOLEAN]. For active players, is_active will always be true. 


# Full endpoint => https://sports.core.api.espn.com/v3/sports/football/nfl/athletes

# This endpoint only returns 19495 results. However, sources say >25,000 people have been in the NFL. I assume that ESPN didn't bother storing data for players from the first few years of the NFL
# Fetch the raw response from endpoint, and process active players potentially in parallel using httpx and asyncio. Since we are only concerned with active_players, if for a given object the "active" field is false, skip over adding it to the results array. 
# Store in a variable "players" in target file using repr. 

'''
    Raw response from endpoint => 
    {
    "count": 19495,
    "pageIndex": 1,
    "pageSize": 25,
    "pageCount": 780,
    "items": [
        {
            "id": "14856",
            "uid": "s:20~l:28~a:14856",
            "guid": "625857a9-05f5-590d-8cf6-69748e71ea17",
            "firstName": "Isaako",
            "lastName": "Aaitui",
            "fullName": "Isaako Aaitui",
            "displayName": "Isaako Aaitui",
            "shortName": "I. Aaitui",
            "weight": 307.0,
            "displayWeight": "307 lbs",
            "height": 76.0,
            "displayHeight": "6' 4\"",
            "age": 38,
            "dateOfBirth": "1987-01-25T08:00Z",
            "experience": {
                "years": 2
            },
            "jersey": "71",
            "active": false
        },
'''

import httpx
import asyncio
from pathlib import Path
from datetime import datetime

BASE_URL = "https://sports.core.api.espn.com/v3/sports/football/nfl/athletes"
TARGET_FILE = Path("src/nfl_api_client/lib/data.py")

async def fetch_page(client, page_index):
    url = f"{BASE_URL}?page={page_index}"
    resp = await client.get(url, timeout=20.0)
    resp.raise_for_status()
    return resp.json()

async def fetch_all_players():
    async with httpx.AsyncClient(timeout=20.0) as client:

        first_page = await fetch_page(client, 1)
        page_count = first_page.get("pageCount", 1)
        all_items = first_page.get("items", [])

        print(f"Fetching {page_count} pages...")

        tasks = [fetch_page(client, i) for i in range(2, page_count + 1)]
        results = await asyncio.gather(*tasks)

        for result in results:
            all_items.extend(result.get("items", []))

        return all_items

def extract_players(items):
    players = []
    for item in items:
        full_name = item.get("fullName", "")
        
        # Skip invalid entries like "[Touchback]"
        if "[" in full_name or "]" in full_name:
            continue  
        
        players.append([
                int(item.get('id')),
                item.get("firstName"),
                item.get("lastName"),
                full_name,
                item.get("active"),
            ])
    return players

def write_to_file(players):
    curr_date = datetime.now().strftime("%B %-d, %Y")

    with open(TARGET_FILE, "w") as f:
        f.write("# DO NOT MODIFY: This file has been auto-generated by nfl_api/_scripts/generate_players.py.\n")
        f.write(f"# Last updated: {curr_date}\n\n")
        f.write("player_id_idx = 0\n")
        f.write("player_first_name_idx = 1\n")
        f.write("player_last_name_idx = 2\n")
        f.write("player_full_name_idx = 3\n")
        f.write("player_active_idx = 4\n\n")
        f.write(f"players = {repr(players)}")

async def main():
    items = await fetch_all_players()
    players = extract_players(items)
    write_to_file(players)
    print(f"Wrote {len(players)} active players to {TARGET_FILE}")

if __name__ == "__main__":
    asyncio.run(main())
