{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0916d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "import datetime  # noqa\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "import datasets\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "649e9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = torchtext.datasets.WikiText2()\n",
    "NUM_TEXTS = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a9196be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dsets[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode()):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nessvec/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/routeddecoder.py:50\u001b[0m, in \u001b[0;36mRoutedDecoderIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe:\n\u001b[1;32m     49\u001b[0m     pathname \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 50\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (pathname, result[pathname])\n",
      "File \u001b[0;32m~/anaconda3/envs/nessvec/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/decoder.py:310\u001b[0m, in \u001b[0;36mDecoder.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nessvec/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/decoder.py:299\u001b[0m, in \u001b[0;36mDecoder.decode\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    296\u001b[0m     data \u001b[38;5;241m=\u001b[39m [data]\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# TODO: xinyu, figure out why Nvidia do this?\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "ddsets[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49ad995",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> for dset, name in zip(dsets, 'train val test'.split()):\n",
    ">>>     dset = list(dset)[:NUM_TEXTS]\n",
    ">>>     filepath = DATA_DIR / f'WikiText2-{name}-{len(dset)}.txt'\n",
    ">>>     with open(filepath, 'wt') as fout:\n",
    "...         fout.writelines(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a353589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hobs/nessvec-data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "DATA_DIR = Path('~').expanduser().absolute() / 'nessvec-data'\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347bfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_row(row):\n",
    "    row['all_tokens'] = [\n",
    "        tok for tok in re.findall(r\"\\w+\", row['text'].lower()) if tok]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faab185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**12  # 4096\n",
    "CPU_CORES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c19dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_WIDTH = 3\n",
    "EMBED_DIM = 100  # <1> Quite small, just for the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697072e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90688662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "\n",
    "dsets = torchtext.datasets.WikiText2()\n",
    "num_texts = 10000\n",
    "filepaths = []\n",
    "\n",
    "for name, dset in zip('train validation test'.split(), dsets):\n",
    "    df = pd.DataFrame(dsets[0], columns=['text'])\n",
    "    df['label'] = 1\n",
    "    filepaths.append(str(DATA_DIR / f'WikiText2-{name}'))\n",
    "    with open(filepaths[-1] + f'.{num_texts}.txt', 'wt') as fout:\n",
    "        fout.writelines(df['text'][:num_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0582e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-e60dda664d838043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /home/hobs/.cache/huggingface/datasets/text/default-e60dda664d838043/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd03599640c04974a501a3b1c8c6b62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5470e5737c0e4cdaba3f0c6fe41f5395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/hobs/.cache/huggingface/datasets/text/default-e60dda664d838043/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829cabae261744048b14751c58abf5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = datasets.load_dataset('text', data_files=filepaths[0] + f'.{num_texts}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0ba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09adfab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dset \u001b[38;5;241m=\u001b[39m dset\u001b[38;5;241m.\u001b[39mmap(\u001b[43mtokenize\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "dset = dset.map(tokenize_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ae44777",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter([i for s in dset['train']['all_tokens'] for i in s])\n",
    "counts = {k: v for k, v in counts.items() if v > 10}  # Filtering\n",
    "vocab = list(counts.keys())\n",
    "n_v = len(vocab)\n",
    "id2tok = dict(enumerate(vocab))\n",
    "tok2id = {token: id for id, token in id2tok.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0790ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_tokens(row):\n",
    "    row['tokens'] = [t for t in row['all_tokens'] if t in vocab]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "943e4324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552482dc7c4b40c6b967508c97475496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = dset.map(remove_rare_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09b13286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowizer(row, wsize=WINDOW_WIDTH):\n",
    "    \"\"\" Compute sentence (str) to sliding-window of skip-gram pairs. \"\"\"\n",
    "    doc = row['tokens']\n",
    "    out = []\n",
    "    for i, wd in enumerate(doc):\n",
    "        target = tok2id[wd]\n",
    "        window = [\n",
    "            i + j for j in range(-wsize, wsize + 1, 1)\n",
    "            if (i + j >= 0) & (i + j < len(doc)) & (j != 0)\n",
    "        ]\n",
    "\n",
    "        out += [(target, tok2id[doc[w]]) for w in window]\n",
    "    row['moving_window'] = out\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15f3dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04cfb126958463ab18bb5f918e18809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = dset.map(windowizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e5e7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def neighbor_pairs(tokens, window_width=WINDOW_WIDTH):\n",
    "#     \"\"\" skip-grams: pairs of words that are within window_width of each other\n",
    "\n",
    "#     >>> neighbor_pairs('We are all one .'.split(), 3)\n",
    "#     [\n",
    "#      (We, are),\n",
    "#      (We, all),\n",
    "#      (We, one),\n",
    "#      (are, all),\n",
    "#     ...\n",
    "#     \"\"\"\n",
    "#     pairs = []\n",
    "#     for i, wd in enumerate(tokens):\n",
    "#         target = tok2id[wd]\n",
    "#         window = [\n",
    "#             i + j for j in\n",
    "#             range(-window_width, window_width + 1, 1)\n",
    "#             if (i + j >= 0)\n",
    "#             & (i + j < len(tokens))\n",
    "#             & (j != 0)\n",
    "#         ]\n",
    "\n",
    "#         pairs.extend([(target, tok2id[tokens[w]]) for w in window])\n",
    "#     # huggingface datasets are dictionaries for every text element\n",
    "#     return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1afa5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Takes a HuggingFace dataset as an input, to be used for a Word2Vec dataloader.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, vocab_size, wsize=3):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = [i for s in dataset['moving_window'] for i in s]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77ee40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {}\n",
    "for k in dset.keys():\n",
    "    dataloader = {\n",
    "        k: DataLoader(\n",
    "            Word2VecDataset(\n",
    "                dset[k],\n",
    "                vocab_size=n_v),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=CPU_CORES - 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57898d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(input_id, size):\n",
    "    vec = torch.zeros(size).float()\n",
    "    vec[input_id] = 1.0\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb242e80",
   "metadata": {},
   "source": [
    "### OHE Example\n",
    "Example one-hot encoder showing the shapes of the neural network weight matrices and input dataset for a 10-word vocabulary and 3-word sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8128e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]], requires_grad=True)\n",
      "tensor([3.], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "ohe = one_hot_encode(input_id=3, size=10)\n",
    "linear_layer = nn.Linear(10, 1, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    linear_layer.weight = torch.nn.Parameter(\n",
    "        torch.arange(10, dtype=torch.float).reshape(linear_layer.weight.shape))\n",
    "\n",
    "print(linear_layer.weight)\n",
    "print(linear_layer(ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116394e",
   "metadata": {},
   "source": [
    "### Instantiate Word2Vec model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dc88542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.expand = nn.Linear(embedding_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Encode input to lower-dimensional representation\n",
    "        hidden = self.embed(input)\n",
    "        # Expand hidden layer to predictions\n",
    "        logits = self.expand(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ee6822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(n_v, EMBED_SIZE)\n",
    "\n",
    "# Relevant if you have a GPU:\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define training parameters\n",
    "LR = 5e-4\n",
    "EPOCHS = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4577f",
   "metadata": {},
   "source": [
    "### Train Word2Vec language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63491b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 8.67662239074707:   0%|              | 4/5970 [00:00<14:12,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2123,   94,   13,  ...,  140,  364, 1206]) tensor([ 229, 1914, 1012,  ...,   14,  120,  253])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 7.107980251312256:  10%|█          | 600/5970 [01:10<14:31,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2087,   13,    5,  ..., 1593,   56, 3870]) tensor([  32,    8, 2687,  ..., 4708,  428,  132])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.509765625:  20%|███▏            | 1197/5970 [02:17<13:42,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 517, 1643,  387,  ...,   94,   23,   13]) tensor([ 276, 3764,  261,  ...,    8,    9,  272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.41121768951416:  30%|███▎       | 1794/5970 [03:25<12:54,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1862,  326, 2572,  ...,  245,   14,  386]) tensor([ 26,   5,  18,  ...,   8,  18, 387])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.308187961578369:  40%|████      | 2391/5970 [04:34<10:11,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4084,  226, 1760,  ..., 1755, 1761,   14]) tensor([   8,    9, 1778,  ...,    8, 1392,    9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.311797142028809:  50%|█████     | 2988/5970 [05:45<09:08,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   9,  253,   17,  ..., 1351,    9, 2916]) tensor([  25,   32,   32,  ...,  495, 2365,   26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.2237114906311035:  60%|█████▍   | 3585/5970 [06:54<06:52,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  41, 3101, 4526,  ...,    8, 2542,  244]) tensor([1761,    9,    8,  ..., 1716,   13,  389])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.250300884246826:  70%|███████   | 4182/5970 [08:04<05:11,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1512,   26,  372,  ...,    9, 2118,   35]) tensor([ 253,  102,  229,  ..., 4745,  116, 1879])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.29862117767334:  80%|████████▊  | 4779/5970 [09:13<03:25,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  91, 4574,    9,  ...,  418,  269,  223]) tensor([2561,  223,    8,  ..., 1084,   25,    9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.220264911651611:  90%|█████████ | 5376/5970 [10:24<01:48,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  26,  120, 3233,  ...,   32, 1635,  112]) tensor([1078, 2409,    9,  ...,  983,   18, 4087])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss[0] = 6.220264911651611: 100%|█████████▉| 5969/5970 [11:33<00:00,  8.25it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     epoch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     running_loss\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[0;32m---> 26\u001b[0m \u001b[43msave_model\u001b[49m(model, loss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_model' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # noqa\n",
    "running_loss = []\n",
    "\n",
    "pbar = tqdm(range(EPOCHS * len(dataloader['train'])))\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for sample_num, (center, context) in enumerate(dataloader['train']):\n",
    "        if sample_num % len(dataloader['train']) == 2:\n",
    "            print(center, context)\n",
    "            # center: tensor([ 229,    0, 2379,  ...,  402,  553,  521])\n",
    "            # context: tensor([ 112, 1734,  802,  ...,   28,  852,  363])\n",
    "        center, context = center.to(device), context.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input=context)\n",
    "        loss = loss_fn(logits, center)\n",
    "        if not sample_num % 10000:\n",
    "            # print(center, context)\n",
    "            pbar.set_description(f'loss[{sample_num}] = {loss.item()}')\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.update(1)\n",
    "    epoch_loss /= len(dataloader['train'])\n",
    "    running_loss.append(epoch_loss)\n",
    "\n",
    "save_model(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "123fb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, loss=torch.tensor(float(\"NaN\")), name='Word2Vec', model_dir=Path(DATA_DIR) / 'models'):\n",
    "    \"\"\" Save the model with a unique timestamped filename including shape and loss \"\"\"\n",
    "    try:\n",
    "        loss = loss.item()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    num_embeddings, embedding_dim = model.state_dict()[\"embed.weight\"].shape\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # filename = f'Word2Vec-state_dict-{now.isoformat()[:13]}.pt'\n",
    "    # filename = f'Word2Vec-state_dict-{num_embeddings}x{embedding_dim}+{embedding_dim}x{num_embeddings}.pt'\n",
    "    filename = f'{name}-state_dict-{num_embeddings}x{embedding_dim}-{now.isoformat()[:13]}-loss_{loss}.pt'\n",
    "\n",
    "    torch.save(model.state_dict(), model_dir / filename)\n",
    "    return model_dir / filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1393bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4943x100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hobs/nessvec-data/models/Word2Vec-state_dict-4943x100-2022-02-22T22-loss_6.232699871063232.pt')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc910a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4943, 100])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()[\"expand.weight\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb858cd",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3fd0268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns  # noqa\n",
    "import matplotlib.pyplot as plt  # noqa\n",
    "sns.set_theme()\n",
    "plt.plot(running_loss)\n",
    "plt.show(block=False)\n",
    "\n",
    "sns.set_theme()\n",
    "# sns.set_style('whitegrid')\n",
    "# learning curve\n",
    "plt.grid('on')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18d84309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father ['mother', 'own', 'name', 'book', 'him', 'career', 'family', 'john', 'life', 'role'] \n",
      "\n",
      "mother ['brother', 'father', 'parents', 'wife', 'personal', 'jack', 'brothers', 'children', 'name', 'friend'] \n",
      "\n",
      "writer ['james', 'self', 'executive', 'wheeler', 'making', 'album', 'studio', 'entertainment', 'nesbitt', 'cover'] \n",
      "\n",
      "woman ['me', 'care', 'looking', 'love', 'serious', 'got', 'tell', 'makes', 'want', 'know'] \n",
      "\n",
      "man ['who', 'bass', 'as', 'an', 'is', 'he', 'however', 'was', 'long', 'she'] \n",
      "\n",
      "black ['is', 'be', 'not', 'white', 'that', 'are', 'often', 'also', 'it', 'this'] \n",
      "\n",
      "japanese ['contest', 'spear', 'portion', 'mayor', 'chutzpah', 'table', 'crescent', 'frederick', 'orozco', 'complicated'] \n",
      "\n",
      "men ['were', 'other', 'are', 'their', 'two', 'some', 'more', 'people', 'of', 'and'] \n",
      "\n",
      "women ['show', 'league', 'team', 'football', 'underground', 'national', 'men', 'teams', 'best', 'television'] \n",
      "\n",
      "people ['about', 'more', 'some', 'are', 'have', 'or', 'all', 'were', 'they', 'to'] \n",
      "\n",
      "person ['process', 'believe', 'particular', 'true', 'changes', 'write', 'specific', 'might', 'moral', 'unique'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "# Evaluation (word semantic similarity)\n",
    "\n",
    "###################################################\n",
    "# Vectors = embedding layer model weights\n",
    "\n",
    "wordvecs = model.expand.weight.cpu().detach().numpy()\n",
    "tokens = ['father', 'mother', 'writer', 'woman', 'man', 'black', 'japanese', 'men', 'women', 'people', 'person']\n",
    "\n",
    "# Vectors = embedding layer model weights\n",
    "###################################################\n",
    "\n",
    "\n",
    "\n",
    "from scipy.spatial import distance  # noqa\n",
    "import numpy as np  # noqa\n",
    "\n",
    "\n",
    "def get_distance_matrix(wordvecs, metric):\n",
    "    dist_matrix = distance.squareform(distance.pdist(wordvecs, metric))\n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "def get_k_similar_words(word, dist_matrix, k=10):\n",
    "    idx = tok2id[word]\n",
    "    dists = dist_matrix[idx]\n",
    "    ind = np.argpartition(dists, k)[:k + 1]\n",
    "    ind = ind[np.argsort(dists[ind])][1:]\n",
    "    out = [(i, id2tok[i], dists[i]) for i in ind]\n",
    "    return out\n",
    "\n",
    "\n",
    "dmat = get_distance_matrix(wordvecs, 'cosine')\n",
    "for word in tokens:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, dmat)], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041640ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok2id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtok2id\u001b[49m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tok2id' is not defined"
     ]
    }
   ],
   "source": [
    "tok2id.items(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a82b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
