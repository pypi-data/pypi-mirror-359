{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024ddc97-7183-467b-b321-92378975bf39",
   "metadata": {},
   "source": [
    "# Load Models and Generate Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b977fe50-eee9-4a44-84e6-1ecd717f7659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:43.261978Z",
     "iopub.status.busy": "2023-03-30T22:53:43.261617Z",
     "iopub.status.idle": "2023-03-30T22:53:43.268062Z",
     "shell.execute_reply": "2023-03-30T22:53:43.266991Z",
     "shell.execute_reply.started": "2023-03-30T22:53:43.261952Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, set_seed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b040e6-0785-4008-a8c6-de0833db60e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:43.270836Z",
     "iopub.status.busy": "2023-03-30T22:53:43.270494Z",
     "iopub.status.idle": "2023-03-30T22:53:43.275767Z",
     "shell.execute_reply": "2023-03-30T22:53:43.274748Z",
     "shell.execute_reply.started": "2023-03-30T22:53:43.270809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "set_seed(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c323c7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:43.277292Z",
     "iopub.status.busy": "2023-03-30T22:53:43.276924Z",
     "iopub.status.idle": "2023-03-30T22:53:49.851631Z",
     "shell.execute_reply": "2023-03-30T22:53:49.850433Z",
     "shell.execute_reply.started": "2023-03-30T22:53:43.277254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of '/notebooks/models/model01_tutorial_pytorch_loop'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/notebooks/models/model01_tutorial_pytorch_loop' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/configuration_utils.py:628\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:166\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/notebooks/models/model01_tutorial_pytorch_loop'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/models/model01_tutorial_pytorch_loop\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m finetuned_tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m, bos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|startoftext|>\u001b[39m\u001b[38;5;124m'\u001b[39m, eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m'\u001b[39m, pad_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|pad|>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m finetuned_gpt2 \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2LMHeadModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m finetuned_gpt2\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m vanilla_tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2175\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2174\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2175\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_auto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_auto_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2187\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2191\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/configuration_utils.py:546\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    548\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    549\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m         )\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/code/tangibleai/nlpia2/.venv/lib/python3.9/site-packages/transformers/configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the configuration of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of '/notebooks/models/model01_tutorial_pytorch_loop'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/notebooks/models/model01_tutorial_pytorch_loop' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '/notebooks/models/model01_tutorial_pytorch_loop'\n",
    "\n",
    "finetuned_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "finetuned_gpt2 = GPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
    "finetuned_gpt2.cuda()\n",
    "\n",
    "vanilla_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "vanilla_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# vanilla_gpt2.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a872083c-a1cb-4cd8-866e-e47e4d035998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:49.853195Z",
     "iopub.status.busy": "2023-03-30T22:53:49.852887Z",
     "iopub.status.idle": "2023-03-30T22:53:49.858739Z",
     "shell.execute_reply": "2023-03-30T22:53:49.857639Z",
     "shell.execute_reply.started": "2023-03-30T22:53:49.853168Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, generation_args):\n",
    "    encoded_prompt = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    encoded_prompt = encoded_prompt.to(device)\n",
    "    encoded_output = model.generate (encoded_prompt, **generation_args)\n",
    "    decoded_output = tokenizer.decode(encoded_output.squeeze(),clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "    return decoded_output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd8b79e-440f-497d-b4ae-83afaf1e6e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:49.862687Z",
     "iopub.status.busy": "2023-03-30T22:53:49.861640Z",
     "iopub.status.idle": "2023-03-30T22:53:49.868137Z",
     "shell.execute_reply": "2023-03-30T22:53:49.867109Z",
     "shell.execute_reply.started": "2023-03-30T22:53:49.862655Z"
    }
   },
   "outputs": [],
   "source": [
    "default_generation_args = {\n",
    "    'max_length': 100\n",
    "}   \n",
    "\n",
    "sampling_args = {\n",
    "    'max_length': 100,\n",
    "    'do_sample': True, \n",
    "    'max_length':50, \n",
    "    'top_k':50\n",
    "}  \n",
    "\n",
    "nucleus_sampling_args = {\n",
    "    'max_length': 100,\n",
    "    'do_sample': True, \n",
    "    'max_length':50, \n",
    "    'top_p':0.92\n",
    "}\n",
    "\n",
    "nucleus_sampling_args_with_temperature = {\n",
    "    'max_length': 100,\n",
    "    'do_sample': True, \n",
    "    'max_length':50, \n",
    "    'top_p':0.92, \n",
    "    'temperature': 3.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2688b54-83dc-4082-940b-1cb78f391b39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:49.869959Z",
     "iopub.status.busy": "2023-03-30T22:53:49.869422Z",
     "iopub.status.idle": "2023-03-30T22:53:49.873806Z",
     "shell.execute_reply": "2023-03-30T22:53:49.872880Z",
     "shell.execute_reply.started": "2023-03-30T22:53:49.869934Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt='NLP is'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b16da5-ffc4-453a-b511-e933ef013de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:49.875248Z",
     "iopub.status.busy": "2023-03-30T22:53:49.874978Z",
     "iopub.status.idle": "2023-03-30T22:53:51.520820Z",
     "shell.execute_reply": "2023-03-30T22:53:51.519943Z",
     "shell.execute_reply.started": "2023-03-30T22:53:49.875223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NLP is a new type of data structure that is used to store and retrieve data from a database.\\n\\nThe data structure is a collection of data structures that are used to store and retrieve data from a database.\\n\\nThe data structure is a collection of data structures that are used to store and retrieve data from a database.\\n\\nThe data structure is a collection of data structures that are used to store and retrieve data from a database.\\n\\nThe data structure is a collection of data'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(vanilla_gpt2, vanilla_tokenizer,prompt, default_generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32ebbb20-8112-4dd9-831b-13e2a0aa821a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T22:53:51.522591Z",
     "iopub.status.busy": "2023-03-30T22:53:51.522302Z",
     "iopub.status.idle": "2023-03-30T22:53:51.548936Z",
     "shell.execute_reply": "2023-03-30T22:53:51.547374Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.522566Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate() missing 2 required positional arguments: 'prompt' and 'generation_args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate() missing 2 required positional arguments: 'prompt' and 'generation_args'"
     ]
    }
   ],
   "source": [
    "generate(prompt, sampling_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb2dba-4276-4022-9ac6-03b6a92ca374",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.549618Z",
     "iopub.status.idle": "2023-03-30T22:53:51.549920Z",
     "shell.execute_reply": "2023-03-30T22:53:51.549787Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.549770Z"
    }
   },
   "outputs": [],
   "source": [
    "generate(finetuned_gpt2, finetuned_tokenizer,prompt, nucleus_sampling_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba804fda-8f1f-41c0-9d06-bd5dc3ae6eca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.550612Z",
     "iopub.status.idle": "2023-03-30T22:53:51.550923Z",
     "shell.execute_reply": "2023-03-30T22:53:51.550791Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.550775Z"
    }
   },
   "outputs": [],
   "source": [
    "generate(prompt, nucleus_sampling_args_with_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496951e-a16d-48d5-afcd-f9cac28cd9e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.552211Z",
     "iopub.status.idle": "2023-03-30T22:53:51.552522Z",
     "shell.execute_reply": "2023-03-30T22:53:51.552383Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.552366Z"
    }
   },
   "outputs": [],
   "source": [
    "generate(vanilla_gpt2, vanilla_tokenizer, prompt, default_generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db69c7-365e-4e2a-92d2-673ad8f08fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5150c40-3745-438d-a73c-01e9397cdde1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.554048Z",
     "iopub.status.idle": "2023-03-30T22:53:51.554462Z",
     "shell.execute_reply": "2023-03-30T22:53:51.554237Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.554217Z"
    }
   },
   "outputs": [],
   "source": [
    "generate(vanilla_gpt2, vanilla_tokenizer, prompt, nucleus_sampling_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a1e20-6b78-4c2d-b589-2ba0578e65b1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.555533Z",
     "iopub.status.idle": "2023-03-30T22:53:51.555843Z",
     "shell.execute_reply": "2023-03-30T22:53:51.555706Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.555688Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt='NLP is'\n",
    "print(generate(finetuned_gpt2, finetuned_tokenizer,prompt, nucleus_sampling_args))\n",
    "print(generate(vanilla_gpt2, vanilla_tokenizer,prompt, nucleus_sampling_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a4a5b-c30f-42f5-939d-b0820080811e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.556923Z",
     "iopub.status.idle": "2023-03-30T22:53:51.557233Z",
     "shell.execute_reply": "2023-03-30T22:53:51.557095Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.557078Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt='Neural networks'\n",
    "print(generate(finetuned_gpt2, finetuned_tokenizer,prompt, nucleus_sampling_args))\n",
    "print(generate(vanilla_gpt2, vanilla_tokenizer,prompt, nucleus_sampling_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63d09c-6959-40b9-a284-309a2434afcf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.558484Z",
     "iopub.status.idle": "2023-03-30T22:53:51.558806Z",
     "shell.execute_reply": "2023-03-30T22:53:51.558658Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.558640Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt='Computers are more'\n",
    "print(f\"Finetuned: {generate(finetuned_gpt2, finetuned_tokenizer,prompt, nucleus_sampling_args)}\")\n",
    "print(f\"Vanilla: {generate(vanilla_gpt2, vanilla_tokenizer,prompt, nucleus_sampling_args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df220ee8-d522-4eb7-817f-71cdb63bc8f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T22:53:51.560964Z",
     "iopub.status.idle": "2023-03-30T22:53:51.561591Z",
     "shell.execute_reply": "2023-03-30T22:53:51.561310Z",
     "shell.execute_reply.started": "2023-03-30T22:53:51.561283Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt='The definition of NLP is'\n",
    "print(f\"Finetuned: {generate(finetuned_gpt2, finetuned_tokenizer,prompt, nucleus_sampling_args)}\")\n",
    "print(f\"Vanilla: {generate(vanilla_gpt2, vanilla_tokenizer,prompt, nucleus_sampling_args)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
