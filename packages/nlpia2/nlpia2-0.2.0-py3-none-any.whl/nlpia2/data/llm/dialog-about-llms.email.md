Thank you Edward! 

I think I now understand better Chomsky's proposition/thesis. You're right. My examples weren't well-posed to elicit grammatical mistakes. If you think of any underappreciated ideas/researchers in philosophy/linguistics/AI, let me know. It feels like it's going to take some brilliant new ideas and collective "sense making" to save humanity from large language models and AI. And if you think of some better ways to stress test ChatGPT I'm all ears.

--Hobson

P.S. More thinking out loud:

The fact that ChatGPT is parsing and generating text that is grammatically correct is uninteresting to me. To me, it has seemed obvious for quite while, that LLMs would scale up to solve the problem of generating complex and grammatically correct text and conversation that fools the masses. But ChatGPT seems to be edging beyond grammar. It seems to be getting gradually better at filling the holes in it's Swiss Cheese statistical model of language and the world:
- common sense understanding
- prosocial conversation (e.g. Grice's Rules)
- truthfulness/honesty/fact-checking
- agency/willfulness
- morality/ethics
- metacognition & learning
- context & theory of mind

Perhaps these are things beyond what can be learned from language and conversation, even for a human brain.

LLMs seem to handle the fuzziness/ambiguity/statistics of language while maintaining grammatically. And LLMs are becoming "influencers" and "thought leaders" by imitating social behavior, with fewer and fewer factual and common sense errors. I'm worried that the holes in the Swiss Cheese will soon be imperceptible. But the holes will still dominate LLMs models of the world -- e.g. AI will make mistakes that are different from our mistakes and we will perceive them as genius despite them being wrong. I'm thinking of big picture things like equity, social evolutionary dynamics, quantum physics, the Drake Equation and Fermi Paradox. It will recommend a particular way forward for humanity that is different from what ours would be and we will follow it (such as approaches to reducing wealth disparity, saving the planet from ecological collapse, healthcare & biotech & intelligence augmentation (AI) accessibility, stopping nuclear and bioweapon proliferation, biotech, etc.). It will have different answers to the "21 Lessons of the 21st Century"

So I'm trying to compose new prompts that it is unlikely to have seen before, patterns that a machine would interpret *differently* than most intelligent humans (who also would not ever have read/heard a similar prompt+answer pair). I'm trying to find the diff between what brains do and what neural nets do. And trying to find researchers who are doing the same, rather than trying to shoehorn ChatGPT into their world view (or trying to pick up pennies in front of the chatgpt+bigtech steamroller before their way of life (and what it means to be human?) is flattened.

On Sun, Apr 2, 2023 at 5:50 AM Edward A. Lee <eal@berkeley.edu> wrote:


    Hello Hobson.

    Thanks for sharing these.

    Actually, to me, your examples very strongly refute Chomsky’s hypothesis.
    Chomsky has always advocated that natural language grammar is a built in to the human brain.
    None of your examples yields an incorrect answer because of misunderstanding the _grammar_.
    The answers don’t correspond to our expectations because of real world experience with materials (steel balls are unlikely to fall apart).

    I suspect GPT-4 would not make the same mistakes…

    As for whom to follow, there is complete chaos out there now, and I think nearly everyone is making mistakes while trying to figure out what is going on.  The behavior of the LLMs is nothing short of astonishing. Anyone who is not surprised is not paying attention.

    Best,
    Edward

    ---------
    Edward A. Lee
    EECS, UC Berkeley
    eal@berkeley.edu
    http://eecs.berkeley.edu/~eal

>     On Mar 31, 2023, at 10:28 PM, Hobson Lane <hobson@tangibleai.com> wrote:
>
>     ﻿
>
>     Hi Dr. Lee,
>
>     I'm writing the second edition of Natural Language Processing in Action, and your article "Is ChatGPT a False Promise?"  helped me understand Chomsky's thinking about LLMs.  I reproduced and expanded your test cases by changing the name/ethnicity of the villain and rewording the question to hopefully fall in the Swiss Cheese holes of ChatGPT's priors:
>
>     * https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/data/llm/chatgpt-testset.yaml
>
>     * https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/data/llm/chatgpt-testy-conversation-log-copypasta-safety-reasoning-truthfulness.txt
>
>     My tests don't seem to refute Chomsky's hypothesis to the same degree that yours did, but there's no smoking gun.
>
>     I'm self-taught, so I'd appreciate any other resources you have for rigorous testing of LLMs for understanding, reasoning and intelligence -- linguistic/information-theory/philosophy questions like the one you tested for Chomsky's ideas.
>
>     Do you know any researchers' names I should follow who are also thinking critically about the degree to which statistical LLMs are "understanding/thinking" (Dennett, ), "reasoning" (Chomsky, Beth Rudden?, Rowan Zellers?), or even "computing" (Wolfram)?
>
>     Sincerely,
>
>     Hobson
>
>     <49D0W98H2qugZNwo.png>
>
>     <0WoTg0uFrjQmwMWl.png>
>


-- 
Hobson Lane
hobson@tangibleai.com
(503) 974-6274
CTO, Tangible AI
tangibleai.com
