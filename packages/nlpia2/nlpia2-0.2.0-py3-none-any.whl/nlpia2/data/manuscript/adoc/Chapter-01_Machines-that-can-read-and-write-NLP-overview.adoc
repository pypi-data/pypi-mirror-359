= Natural Language Processing in Action, Second Edition
:chapter: 1
:part: 1
:sectnums:
:imagesdir: .
:xrefstyle: short
:figure-caption: Figure {chapter}.
:listing-caption: Listing {chapter}.
:table-caption: Table {chapter}.
:leveloffset: 1
:stem: latexmath
:toc:
:source-highlighter: coderay
:bibliography-database: dl4nlp.bib
:bibliography-style: ieee
:index::[]

= Machines that read and write (NLP overview)

This chapter covers

* The power of human language
* How natural language processing (NLP) is changing society
* The kinds of NLP tasks that machines can now do well
* Why unleashing the NLP genie is profitable ... and dangerous
* How to start building a simple chatbot
* How NLP technology is programming itself and making itself smarter

Words are powerful.
They can change minds.
And they can change the world.
Natural language processing puts the power of words into algorithms.
Those algorithms are changing your world right before your eyes.
You are about to see how the majority of the words and ideas that enter your mind are filtered and generated by NLP and how you can take back some of that control over your world.

Imagine what you would do with a machine that could understand and act on every word it reads on the Internet?
Imagine the information and knowledge you'd be able to harvest and profit from.
NLP promises to create the second information revolution by turning vast amounts of unstructured data into actionable knowledge and understanding.

Early on, Big Tech discovered the power of NLP to glean knowledge from natural language text.
They use that power to affect our behavior and our minds in order to improve their bottom line.footnote:[In 2013 The Guardian and other news organizations revealed Facebook's experiments to maniuplate users' emotions using NLP (https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds). Search engine giants and their algorithms perform these same kinds of experiments each time you enter text into the search box (https://www.computerservicesolutions.in/all-google-search-algorithm-updates/).]
Governments too are waking up to the impact NLP has on culture, society and humanity.
Fortunately, a few courageous liberal democracies are attempting to free your mind by steering businesses towards sustainable and ethical uses for NLP.

On the other end of the spectrum, authoritarian governments are using NLP to coopt our prosocial instincts to make us easier to track and control.
The Chinese government uses NLP to prevent you from even talking about Tibet or Hong Kong in the video games you play.footnote:["Genshin Impact won't let players write 'Tibet', 'Hong Kong', 'Taiwan' because of Chinese censorship" (https://www.msn.com/en-us/news/technology/genshin-impact-won-t-let-players-write-tibet-hong-kong-taiwan-because-of-chinese-censorship/ar-BB19MQYE)]
And governments that censor public media are beginning to affect even the most benign and open source AI algorithms by corrupting NLP training sets.footnote:["Censorship of Online Encyclopedias Implications for NLP Models" (https://www.researchgate.net/publication/348757384_Censorship_of_Online_Encyclopedias_Implications_for_NLP_Models)]
And surprisingly, even US corporations, politicians, and government agencies are using NLP to influence the public discourse about pandemics, climate change, and many other of the __21 Lessons for the 21st Century__. footnote:[Yuval Noah Harari seminal book _21 Lessons for the 21st Century_ - Wikipedia article (https://en.wikipedia.org/wiki/21_Lessons_for_the_21st_Century)]
NLP is even being used to influence what you think about AI and NLP itself.
Of course, not all corporations and politicians have your best interests at heart.

In this chapter, you will begin to build your NLP understanding and skill so you can take control of the information and ideas that affect what you believe and think.
You first need to see all the ways NLP is used in the modern world.
This chapter will open your eyes to these NLP applications happening behind the scenes in your everyday life.
Hopefully this will help you write a few lines of Python code to help you track, classify, and influence the packets of thought bouncing around on the Internet and into your brain.
Your understanding of natural language processing will give you greater influence and control over the words and ideas in your world.
And it will give you and your business the ability to escape Big Tech's stranglehold on information, so you can succeed.

== Programming language vs. natural language

Programming languages are very similar to natural languages like English.
Both kinds of languages are used to communicate instructions from one information processing system to another.
Both languages can communicate thoughts from human to human, human to machine, or even machine to machine.
Both languages define the concept of _tokens_, the smallest packet of meaningful text.
No matter whether your text is natural language or a programming language, the first thing that a machine does is to split the text into tokens.
For natural language, tokens are usually words or combinations of words that go together (compound words).

And both natural and programming languages use _grammars_.
A grammar is a set of rules that tell you how to combine words in a sequence to create an expression or statement that others will understand.
And the words "expression" and "statement" mean similar things whether you are in a computer science class or an English grammar class.
And you may have heard of _regular expressions_ in computer science.
They give you a way to create grammar rules for processing text.
In this book, you will use regular expressions to match patterns in all kinds of text, including natural language and computer programs.

Despite these similarities between programming and natural language, you need new skills and new tools to process natural language with a machine.
Programming languages are artificially designed languages we use to tell a computer what to do.
Computer programming languages are used to explicitly define a sequence of mathematical operations on bits of information, ones and zeros.
And programming languages only need to be _processed_ by machines rather than _understood_.
A machine needs to do _what_ the programmer asks it to do.
It does not need to understand _why_ the program is the way it is.
And it doesn't need abstractions or mental models of the computer program to understand anything outside of the world of ones and zeroes that it is processing.
And almost all computers use the Von Neumann architecture developed in 1945.footnote:[Von Neumann Architecture on Wikipedia (https://en.wikipedia.org/wiki/Von_Neumann_architecture)]
Modern CPUs (Central Processing Units) implement the _Von Neumann architecture_ as a register machine, a version of the _universal Turing machine_ idea of 1936.footnote:["The secrets of computer power revealed" by Daniel Dennett (https://sites.tufts.edu/rodrego/)]

Natural languages, however, evolved naturally, _organically_.
Natural languages communicate ideas, understanding, and knowledge between living organisms that have brains rather than CPUs.
These natural languages must be "runnable" or _understandable_ on a wide variety of wetware (brains).
In some cases, natural language even enables communication across animal species.
Koko (gorilla), Woshoe (chimpanzee), Alex (parrot) and other famous animals have demonstrated command of some English words.footnote:[Animal Language" on Wikipedia (https://en.wikipedia.org/wiki/Animal_language)].
Reportedly, Alex the parrot discovered the meaning of the word "none" on its own.
Alex's dying words to its grieving owner were "Be good, I love you" (https://www.wired.com/2007/09/super-smart-par).
And Alex's words inspired Ted Chiang's masterful short story "The Great Silence."
That is profound cross-species communication, no matter whether the words came from intelligence and sentience or not.

Given how differently natural languages and programming languages evolved, it is no surprise they're used for different things.
We do not use programming languages to tell each other about our day or to give directions to the grocery store.
Similarly, natural languages did not evolve to be readily compiled into thought packets that can be manipulated by machines to derive conclusions.
But that's exactly what you are going to learn how to do with this book.
With NLP you can program machines to process natural language text to derive conclusions, infer new facts, create meaningful abstractions, and even respond meaningfully in a conversation.

Even though there are no compilers for natural language there are _parsers_ and _parser generators_, such as PEGN footnote:[Parsing Expression Grammar Notation home page (https://pegn.dev/)] and SpaCy's Matcher class.
And SpaCy allows you to define word patterns or grammars with a syntax similar to regular expressions.
But there is no single algorithm or Python package that takes natural language text and turns it into machine instructions for automatic computation or execution.
Stephen Wolfram has essentially spent his life trying to build a general-purpose intelligent "computational" machine that can interact with us in plain English.
Even he has resorted to assembling a system out of many different NLP and AI algorithms that must be constantly expanded and evolved to handle new kinds of natural language instructions.footnote:[(https://writings.stephenwolfram.com/2023/02/a-50-year-quest-my-personal-journey-with-the-second-law-of-thermodynamics/)]
And towards the end of this book you will learn about our open source chatbot framework `qary.ai` that allows you to plug in any Python algorithm you can find or dream up.footnote:[The ConvoHub project at (https://qary.ai) and on GitLab (https://gitlab.com/tangibleai/community/convohub)]

With this book, you can build on the shoulders of giants.
If you understand all the concepts in this book, you too will be able to combine these approaches to create remarkably intelligent conversational chatbots.
You will even be able to build bots that understand and generate more meaningful and truthful text than ChatGPT or whatever comes next in this world of rent-seeking AI apps.footnote:[Wikipedia article on Enshittification and rent-seeking (https://en.wikipedia.org/wiki/Enshittification)]
You have a big advantage over BigTech, you actually care about your users.footnote:[At DefCon 31, Cory Doctorow explained how interoperable APIs will win out over walled gardens and rent-seeking  on YouTube(https://www.youtube.com/watch?v=rimtaSgGz_4)]

.Natural language processing
[IMPORTANT, definition]
====
Natural language processing is an evolving practice in computer science and artificial intelligence (AI) concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data (numbers) that a computer can use to learn about the world. This understanding of the world is sometimes used to generate natural language text that reflects that understanding.
====

This chapter shows you how your software can _process_ natural language to produce useful output.
You might even think of your program as a natural language interpreter, similar to how the Python interpreter processes source code.
When the computer program you develop processes natural language, it will be able to act on those statements or even reply to them.

Unlike a programming language where each keyword has an unambiguous interpretation, natural languages are much more fuzzy.
This fuzziness of natural language leaves open to you the interpretation of each word.
So, you get to choose how the bot responds to each situation.
Later you will explore advanced techniques in which the machine can learn from examples, without you knowing anything about the content of those examples.

.Pipeline
[IMPORTANT, definition]
====
A natural language processing system is called a "pipeline" because it natural language must be processed in several stages.
Natural language text flows in one end and text or data flows out of the other end, depending on what sections of "pipe" (Python code) you include in your pipeline.
It's like a conga line of Python snakes passing the data along from one to the next.
====

You will soon have the power to write software that does interesting, human-like things with text.
This book will teach you how to teach machines to carry on a conversation.
It may seem a bit like magic, as new technology often does, at first.
But you will pull back the curtain and explore the technology behind these magic shows. You will soon discover all the props and tools you need to do the magic tricks yourself.

=== Natural Language Understanding (NLU)

A really important part of NLP is the automatic processing of text to extract a numerical representation of the _meaning_ of that text.
This is the _natural language understanding_ (NLU) part of NLP.
The numerical representation of the meaning of natural language usually takes the form of a vector called an embedding.
Machines can use embeddings to do all sorts of useful things.
Embeddings are used by search engines to understand what your search query means and then find you web pages that contain information about that topic.
And the embedding vectors for emails in your inbox are used by your email service to classify those emails as Important or not.


.Natural Language Understanding (NLU)
image::../images/ch01/text-NLU-vector-graphviz.png[alt=numbers (vector embedding) -> NLG (rules, templates or decoder) -> text (natural language), width=80%, link="../images/ch01/text-NLU-vector-graphviz.png"]

Machines can accomplish many common NLU tasks with high accuracy:

* semantic search
* text alignment (for translation or plagiarism detection)
* paraphrase recognition
* intent classification
* authorship attribution

And recent advances in deep learning have made it possible to solve many NLU tasks that were  impossible only ten years ago:

* analogy problem solving
* reading comprehension
* extractive summarization
* medical diagnosis based on symptom descriptions

However, there remain many NLU tasks where humans significantly outperform machines.
Some problems require the machine to have common-sense knowledge, learn the logical relationships between those common-sense facts, and use all of this on the context surrounding a particular piece of text.
This makes these problems much more difficult for machines:

* euphemism & pun recognition
* humor & sarcasm recognition
* hate-speech & troll detection
* logical entailment and fallacy recognition
* database schema discovery
* knowledge extraction

You'll learn the current state-of-the-art approaches to NLU and what is possible for these difficult problems.
And your _behind-the-scenes_ understanding of NLU will help you increase the effectiveness of your NLU pipelines for your particular applications, even on these hard problems.

=== Natural Language Generation (NLG)

You may not be aware that machines can also compose text that sounds human-like.
Machines can create human-readable text based on a numerical representation of the  meaning and sentiment you would like to convey.
This is the _natural language generation_ (NLG) side of NLP.

.Natural Language Generation (NLG)
image::../images/ch01/vector-NLG-text-graphviz.png[alt="text (natural language) -> NLU (rules, patterns, or encoder)-> numbers (vector embedding)", width=80%, link="../images/ch01/vector-NLG-text-graphviz.png"]

You will soon master many common NLG tasks that build on your NLU skills.
The following tasks mainly rely on your ability to _encode_ natural language into meaningful embedding vectors with NLU.

* synonym substitution
* frequently-asked question answering (information retrieval)
* extractive generation of question answers (reading comprehension tests)
* spelling and grammar correction
* casual conversation

Once you understand how to accomplish these foundational tasks that help you hone your NLU skill, more advanced NLG tasks will be within your reach.

* abstractive summarization and simplification
* machine translation with neural networks
* sentence paraphrasing
* therapeutic conversational AI
* factual question generation
* discussion facilitation and moderation
* argumentative essay writing

Once you understand how to summarize, paraphrase and translate text that gives you the ability to "translate" a text message into an appropriate response.
You can even suggest new text for your user to include in their own writing.
And you will discover approaches that help you summarize and generate longer and longer, and more complicated text.

* build a bot that can participate in debate on social media
* compose poetry and song lyrics that don't sound robotic
* compose jokes and sarcastic comments
* generate text that fools (hacks) other people's NLU pipelines into doing what you want
* measure the robustness of NLP pipelines
* automatically summarize long technical documents
* compose programming language expressions from natural language descriptions

This last development in NLG is particularly powerful.
Machines can now write correct code that comes close to matching your intent based only on a natural language description.
Machines aren't programming themselves yet, but they may soon, according to the latest (September 2023) consensus on Metaculus.
The community predicts that by September, 2026, we will have "AIs program programs that can program AIs."footnote:["When will AIs program programs that can program AIs" on Metaculus (https://www.metaculus.com/questions/406/when-will-ais-program-programs-that-can-program-ais/)]

The combination of NLU and NLG will give you the tools to create machines that interact with humans in surprising ways.footnote:[You may have heard of Microsoft's and OpenAI's Copilot project. GPT-J can do almost as well, and it's completely open source and open data. (https://huggingface.co/models?sort=likes&search=gpt-j)]

=== Plumbing it all together for positive-impact AI

Once you understand how NLG and NLU work, you will be able to assemble them into your own NLP pipelines, like a plumber.
Businesses are already using pipelines like these to extract value from their users.

You too can use these pipelines to further _your_ own objectives in life, business, and social impact.
This technology explosion is a rocket that you can ride and maybe steer a little bit.
You can use it in your life to handle your inbox and journals while protecting your privacy and maximizing your mental well-being.
Or you can advance your career by showing your peers how machines that understand and generate words can improve the efficiency and quality of almost any information-age task.
And as an engineer who thinks about the impact of your work on society, you can help nonprofits build NLU and NLG pipelines that lift up the needy.
As an entrepreneur, you can help create a regenerative prosocial business that spawns whole new industries and communities that thrive together.

Understanding how NLP works will open your eyes and empower you.
You will soon see all the ways machines are being used to mine your words for profit, often at your expense.
And you will see how machines are training you to become more easily manipulated.
This will help you insulate yourself, and perhaps even fight back.
You will soon learn how to survive in a world overrun with algorithms that manipulate you.
You will harness the power of NLP to protect your well-being and contribute to the health of society as a whole.

Machines that can understand and generate natural language harness the power of words.
Because machines can now understand and generate text that seems human, they can act on your behalf in the world.
You'll be able to create bots that will automatically follow your wishes and accomplish the goals you program them to achieve.
But, beware Aladdin's Three Wishes trap.
Your bots may create a tsunami of blowback for your business or your personal life.
Be careful about the goals you give your bots.footnote:[_Human Compatible: Artificial Intelligence and the Problem of Control_ by Stuart Russell]
This is called the "AI control problem" or the challenge of "AI safety."footnote:[AI safety article on Wikipedia (https://en.wikipedia.org/wiki/AI_safety)]
Like the age-old three-wishes problem, you may find yourself trying to undo all the damage caused by your earlier wishes and bots.

The control problem and AI safety are not the only challenges you will face on your quest for positive-impact NLP.
The danger of superintelligent AI that can manipulate us into giving it ever greater power and control may be decades away, but the danger of dumb AI that deceives and manipulates us has been around for years.
The search and recommendation engine NLP that determines which posts you are allowed to see is not doing what you want, it is doing what investors want, stealing your attention, time and money.

For example, if you use the search feature of meetup.com to try to find when the next San Diego Python User Group meetup is happening, you will find that they give you everything except what you are looking for.
It doesn't matter if you have previously signed up for and attended these meetups for years, no matter how much information you give them their NLP will always choose money-making links for them over useful links for you.
Try searching for "DefCon 31 Cory Doctorow" on YouTube.
Instead of his famous rant against platform rent-seeking, you will only see ads and videos that the platform's owners think will keep you enthralled in ads and prevent you from waking up from this trance.
Researchers call this the "AI ethics" challenge, and the more direct ones call it what it is, the AI enshittification problem.

== The magic

What is so magical about a machine that can read and write in a natural language?
Machines have been processing languages since computers were invented.
But those were computer languages, such as Ada, Bash, and C, designed for computers to be able to understand.
Programming languages avoid ambiguity so that computers can always do exactly what you _tell_ them to do, even if that is not always what you _want_ them to do. 

Computer languages can only be interpreted (or compiled) in one correct way.
With NLP you can talk to machines in your own language rather than having to learn computerese.
When software can process languages not designed for machines to understand, it is magic -- something we thought only humans could do.

Moreover, machines can access a massive amount of natural language text, such as Wikipedia, to learn about the world and human thought.
Google's index of natural language documents is well over 100 million gigabytes,footnote:[See the web page titled, "How Google's Site Crawlers Index Your Site - Google Search" (https://proai.org/google-search).] and that is just the index.
And that index is incomplete.
The size of the actual natural language content currently online probably exceeds 100 billion gigabytes.footnote:[You can estimate the amount of actual natural language text out there to be at least a thousand times the size of Google's index.]
This massive amount of natural language text makes NLP a useful tool.

[NOTE]
Today, Wikipedia lists approximately 700 programming languages.
Ethnologue_ footnote:[http://ethnologue.com maintains statistics about natural languages. ISO 639-3 lists 7,486 three-letter language codes (http://proai.org/language-codes).] identifies more than 7,000 natural languages.
And that doesn't include many other natural language sequences that can be processed using the techniques you'll learn in this book.
The sounds, gestures, and body language of animals, as well as the DNA and RNA sequences within their cells, can all be processed with NLP.footnote:[_The Great Silence_ by Ted Chiang (https://proai.org/great-silence) describes an imagined dialog with an endangered species of parrot that concludes with the parrot saying to humanity, "Be Good. I love you."]footnote:[Dolphin Communication Project (https://proai.org/dolphin-communication)]

Machines with the capability to process something natural is not natural.
It is kind of like building a building that can do something useful with architectural designs.
When software can process languages not designed for machines to understand, it seems magical -- something we thought was a uniquely human capability.

For now, you only need to think about one natural language --  English.
You'll ease into more difficult languages like Mandarin Chinese later in the book.
But you can use the techniques you learn in this book to build software that can process any language, even a language you do not understand or has yet to be deciphered by archaeologists and linguists.
We are going to show you how to write software to process and generate that language using only one programming language, Python.

Python was designed from the ground up to be a readable language.
It also exposes a lot of its own language processing "guts."
Both of these characteristics make it a natural choice for learning natural language processing.
It is a great language for building maintainable production pipelines for NLP algorithms in an enterprise environment, with many contributors to a single codebase.
We even use Python in lieu of the "universal language" of mathematics and mathematical symbols, wherever possible.
After all, Python is an unambiguous way to express mathematical algorithms, footnote:[Mathematical notation is ambiguous. See the "Mathematical notation" section of the Wikipedia article "Ambguity" (https://en.wikipedia.org/wiki/Ambiguity#Mathematical_notation).] and it is designed to be as readable as possible by programmers like you.

=== Language and thought

Linguists and philosophers such as Sapir and Whorf postulated that our vocabulary affects the thoughts we think.
For example, Australian Aborigines have words to describe the position of objects on their body according to the cardinal points of the compass.
They don't talk about the boomerang in their right hand, they talk about the boomerang on the north side of their body.
This makes them adept at communicating and orienteering during hunting expeditions.
Their brains are constantly updating their understanding of their orientation in the world.

Stephen Pinker flips that notion around and sees language as a window into our brains and how we think: "Language is a collective human creation, reflecting human nature, how we conceptualize reality, how we relate to one another."footnote:[Thank you to "Tudor" on MEAP for setting me straight about this. (https://www.ted.com/talks/steven_pinker_what_our_language_habits_reveal/transcript)]
Whether you think of words as affecting your thoughts or as helping you see and understand your thoughts, either way, they are packets of thought.
You will soon learn the power of NLP to manipulate those packets of thought and amp up your understanding of words, ... and maybe thought itself.
It's no wonder many businesses refer to NLP and chatbots as AI - Artificial Intelligence.

What about math?
We think with precise mathematical symbols and programming languages as well as with fuzzier natural language words and symbols.
And we can use fuzzy words to express logical thoughts like mathematics concepts, theorems, and proofs.
But words aren't the only way we think.
Jordan Elenberg, a geometer at Harvard, writes in his new book _Shape_ about how he first "discovered" the commutative property of algebra while staring at a stereo speaker with a grid of dots, 6x8.
He'd memorized the multiplication table, the symbols for numbers.
And he knew that you could reverse the order of symbols on either side of a multiplication symbol.
But he didn't really _know_ it until he realized that he could visualize the 48 dots as 6 columns of 8 dots, or 8 rows of 6 dots.
And it was the same dots!
So it had to be the same number.
It hit him at a deeper level, even deeper than the symbol manipulation rules that he learned in algebra class.

So you use words to communicate thoughts with others and with yourself.
When ephemeral thoughts can be gathered up into words or symbols, they become compressed packets of thought that are easier to remember and to work with in your brain.
You may not realize it, but as you are composing sentences you are actually rethinking and manipulating and repackaging these thoughts.
What you want to say, and the idea you want to share is crafted while you are speaking or writing.
This act of manipulating packets of thought in your mind is called "symbol manipulation" by AI researchers and neuroscientists.
In fact, in the age of GOFAI (Good Old-Fashioned AI) researchers assumed that AI would need to learn to manipulate natural language symbols and logical statements the same way it compiles programming languages.
In this book, you're going to learn how to teach a machine to do symbol manipulation on natural language in Chapter 11.

But that's not the most impressive power of NLP.
Think back to a time when you had a difficult email to send to someone close.
Perhaps you needed to apologize to a boss or teacher, or maybe your partner or a close friend.
Before you started typing, you probably started thinking about the words you would use, the reasons or excuses for why you did what you did.
And then you imagined how your boss or teacher would perceive those words.
You probably reviewed in your mind what you would say many many times before you finally started typing.
You manipulated packets of thought as words in your mind.
And when you did start typing, you probably wrote and rewrote twice as many words as you actually sent.
You chose your words carefully, discarding some words or ideas and focusing on others.

The act of revision and editing is a thinking process.
It helps you gather your thoughts and revise them.
And in the end, whatever comes out of your mind is not at all like the first thoughts that came to you.
The act of writing improves how you think, and it will improve how machines think as they get better and better at reading and writing.

So reading and writing is thinking.
And words are packets of thought that you can store and manipulate to improve those thoughts.
We use words to put thoughts into clumps or compartments that we can play with in our minds.
We break complicated thoughts into several sentences.
And we reorder those thoughts so they make more sense to our reader or even our future self.
Every sentence in this 2nd edition of the book has been edited several times - sometimes with the help of generous readers of the LiveBook. footnote:[Thank you "Tudor" for improving this section and my thinking about linguistic relativism]
I've deleted, rewritten and reordered these paragraphs several times just now, with the help of suggestions and ideas from friends and readers like you.footnote:[Thank you Leo Hepis!]

But words and writing aren't the _only_ way to think logically and deeply.
Drawing, diagramming, and even dancing and acting out are all expressions of thought.
And we visually imagine these drawings in our minds -- sketching ideas and concepts and thoughts in our head.
And sometimes you just physically move things around or act things out in the real world.
But the act of composing words into sentences and sentences into paragraphs is something that we do almost constantly.

Reading and writing is also a special kind of thought.
It seems to compress our thoughts and make them easier to remember and manage within our heads.
Once we know the perfect word for a concept, we can file it away in our minds.
We don't have to keep refreshing it to understand it.
We know that once we think of the word again, the concept will come flooding back and we can use it again.

This is all thinking or what is sometimes called _cognition_.
So by teaching machines to understand and compose text, you are in some small way, teaching them to think.
This is why people think of NLP as artificial intelligence (AI).
And conversational AI is one of the most widely recognized and useful forms of AI.

=== Machines that converse

Though you spend a lot of time working with words as packets of thought internally within your head, the real fun is when you use those words to interact with others.
The act of conversation brings two (or more!) people into your thinking.
This can create a powerful positive feedback loop that reinforces good ideas and weeds out weak ones.

Words are critical to this process.
They are our shared thought vocabulary.
When you want to trigger a thought in another person's brain, all you need to do is to say the right words so that they understand some of the thoughts in your mind.
For example, when you are feeling great pain, frustration or shock, you can use a curse word.
And you can almost be guaranteed to cause that shock and discomfort to be conveyed to your listener or reader.
That is the sole purpose of curse words -- to shock (and awe?) your listener.

[NOTE]
====
There is _another_NLP_ that takes this idea to the extreme.
Neuro-linguistic programming (the _other_NLP_) is a pseudoscientific psychotherapy approach that claims to change your behavior through the use of words.
Because there is money to be made in claiming to help people achieve their life goals, this pseudoscience has taken on a cult status for the practitioners who teach it (preach it?).footnote:[From the Wikipedia article on Neuro-linguistic-programming (https://en.wikipedia.org/wiki/Neuro-linguistic_programming)]

As with astrology, fortune telling, hypnotherapy, conspiracy theories, religions and cults, there is usually a small hint of truth somewhere within it.
Words do indeed affect our thoughts.
And thoughts do affect our behavior.
====

Though we cannot "program" another human with our words, we can use them to communicate extremely complex ideas.
When you engage in conversation you are acting as a neuron in the collective consciousness, the hive mind.
Unfortunately, when profit motives and unfettered competition is the rule of the day, the hornet nest of social media is the result.

Natural language cannot be directly translated into a precise set of mathematical operations.
But natural language does contain information and instructions that can be extracted.
Those pieces of information and instruction can be stored, indexed, searched, or immediately acted upon.
One of those actions could be to generate a sequence of words in response to a statement.
This is the function of the "dialog engine" or chatbot that you will build.

This book focuses entirely on English text documents and messages, not spoken statements.
Chapter 7 does give you a brief foray into processing audio files, Morse code.
But most of NLPiA is focused on the words that have been put to paper... or at least put to transistors in a computer.
There are whole books on speech recognition and speech-to-text (STT) systems and text-to-speech (TTS) systems.
There are ready-made open-source projects for STT and TTS.
If your application is a mobile application, modern smartphone SDKs provide you with speech recognition and speech generation APIs.
If you want your virtual assistant to live in the cloud, there are Python packages to accomplish SST and TTS on any Linux server with access to your audio stream.

In this book you will focus on what happens between the _ears_ of the machine.
This can help you build a smarter voice assistant when you add your _brains_ to open source projects such as Mycroft AI footnote:[You can install MyCroft AI on any RaspberryPi with a speaker and a microphone (https://mycroft.ai/)] or OVAL Genie,footnote:[Stanford's Open Virtual Assistant Lab within their Human-centered AI Institute (https://hai.stanford.edu/news/open-source-challenger-popular-virtual-assistants)].
And you'll understand all the helpful NLP that the big boys could be giving you within their voice assistants ... assuming commercial voice assistants wanted to help you with more than just lightening your wallet.

.Speech recognition systems
====
If you want to build a customized speech recognition or generation system, that undertaking is a whole book in itself; we leave that as an "exercise for the reader."
It requires a lot of high-quality labeled data, voice recordings annotated with their phonetic spellings, and natural language transcriptions aligned with the audio files.
Some of the algorithms you learn in this book might help, but most of the algorithms are quite different.footnote:[Some open source voice assistants you could contribute to (https://gitlab.com/tangibleai/team/-/tree/main/exercises/1-voice/).]
====

=== The math

Processing natural language to extract useful information can be difficult.
It requires tedious statistical bookkeeping, but that is what machines are for.
Like many other technical problems, solving it is a lot easier once you know the answer.
Machines still cannot perform most practical NLP tasks, such as conversation and reading comprehension, as accurately and reliably as humans.
So you might be able to tweak the algorithms you learn in this book to do some NLP tasks a bit better.

The techniques you will learn, however, are powerful enough to create machines that can surpass humans in both accuracy and speed for some surprisingly subtle tasks.
For example, you might not have guessed that recognizing sarcasm in an isolated Twitter message can be done more accurately by a machine than by a human. Well-trained human judges could not match the performance (68% accuracy) of a simple sarcasm detection NLP algorithm.footnote:["Identifying Sarcasm in Twitter: A Closer Look" by Roberto González-Ibáñez (https://aclanthology.org/P11-2102.pdf)] Simple BOW (bag-of-words) models achieve 63% accuracy and state of the art transformer models achieve 81% accuracy. footnote:[Interpretable Multi-Head Self-Attention Architecture for Sarcasm Detection in Social Media by Ramya Akula et al., 2021 (https://www.mdpi.com/1099-4300/23/4/394/pdf)]
// footnote:[dataset from "Sarcasm Detection on Czech and English Twitter" by Tomás Ptácek et al., 2014 (https://aclanthology.org/C14-1022.pdf)]
Do not worry, humans are still better at recognizing humor and sarcasm within an ongoing dialog because we are able to maintain information about the context of a statement. 
However, machines are getting better and better at maintaining context.
This book helps you incorporate context (metadata) into your NLP pipeline if you want to try your hand at advancing the state of the art.

Once you extract structured numerical data, or vectors, from natural language, you can take advantage of all the tools of mathematics and machine learning.
We use the same linear algebra tricks as the projection of 3D objects onto a 2D computer screen, something that computers and drafters were doing long before natural language processing came into its own. These breakthrough ideas opened up a world of "semantic" analysis, allowing computers to interpret and store the "meaning" of statements rather than just word or character counts.
Semantic analysis, along with statistics, can help resolve the ambiguity of natural language -- the fact that words or phrases often have multiple meanings or interpretations.

So extracting information is not at all like building a programming language compiler (fortunately for you).
The most promising techniques bypass the rigid rules of regular grammars (patterns) or formal languages.
You can rely on statistical relationships between words instead of a deep system of logical rules.footnote:[Some grammar rules can be implemented in a computer science abstraction called a finite state machine. Regular grammars can be implemented in regular expressions. There are two Python packages for running regular expression finite state machines, `re` which is built in, and `regex` which must be installed, but may soon replace `re`. Finite state machines are just trees of if...then...else statements for each token (character/word/n-gram) or action that a machine needs to react to or generate.]
Imagine if you had to define English grammar and spelling rules in a nested tree of if...then statements.
Could you ever write enough rules to deal with every possible way that words, letters, and punctuation can be combined to make a statement?
Would you even begin to capture the semantics, the meaning of English statements?
Even if it were useful for some kinds of statements, imagine how limited and brittle this software would be.
Unanticipated spelling or punctuation would break or befuddle your algorithm.

Natural languages have an additional "decoding" challenge that is even harder to solve.
Speakers and writers of natural languages assume that a human is the one doing the processing (listening or reading), not a machine.
So when I say "good morning," I assume that you have some knowledge about what makes up a morning, including that the morning comes before noon, afternoon, and evening, but it also comes after midnight.
You need to know that morning can represent times of day as well as a general period of time.
The interpreter is assumed to know that "good morning" is a common greeting, and that it does not contain much information at all about the morning.
Rather, it reflects the state of mind of the speaker and her readiness to speak with others.

This theory of mind about the human processor of language turns out to be a powerful assumption.
It allows us to say a lot with few words if we assume that the "processor" has access to a lifetime of common sense knowledge about the world.
This degree of compression is still out of reach for machines.
There is no clear "theory of mind" you can point to in an NLP pipeline.
However, we show you techniques in later chapters to help machines build ontologies, or knowledge bases, of common sense knowledge to help interpret statements that rely on this knowledge.

== Applications

Natural language processing is everywhere.
It is so ubiquitous that you'd have a hard time getting through the day without interacting with several NLP algorithms every hour.
Some of the examples here may surprise you.

[[Graph-of-NLP-applications]]
.Graph of NLP applications
image::../images/ch01/nlp-applications.png[alt="Network (graph) of NLP applications and technology use in the real world.", width=95%, link="../images/ch01/nlp-applications.png"]

At the core of this network diagram are the NLU and NLG *sides* of NLP.
Branching out from the NLU hub node are foundational applications like sentiment analysis and search.
These eventually connect with foundational NLG tools such as spelling correctors and automatic code generators to create conversational AI and even pair programming assistants.

A search engine can provide more meaningful results if it indexes web pages or document archives in a way that takes into account the meaning of natural language text.
Autocomplete uses NLP to complete your thought and is common among search engines and mobile phone keyboards.
Many word processors, browser plugins, and text editors have spelling correctors, grammar checkers, concordance composers, and most recently, style coaches.
Some dialog engines (chatbots) use natural language search to find a response to their conversation partner's message.

NLP pipelines that generate text can be used not only to compose short replies in chatbots and virtual assistants but also to assemble much longer passages of text.
The Associated Press uses NLP "robot journalists" to write entire financial news articles and sporting event reports.footnote:["AP's 'robot journalists' are writing their own stories now", The Verge, Jan 29, 2015, http://www.theverge.com/2015/1/29/7939067/ap-journalism-automation-robots-financial-reporting]
Bots can compose weather forecasts that sound a lot like what your hometown weather person might say, perhaps because human meteorologists use word processors with NLP features to draft scripts.

More and more businesses are using NLP to automate their business processes.
This can improve team productivity and job satisfaction, as well as the quality of the product.
For example, chatbots can automate the responses to many customer service requests.footnote:[Many chatbot frameworks, such as qary (http://gitlab.com/tangibleai.com/qary) allow importing of legacy FAQ lists to automatically compose a rule-based dialog engine for your chatbot.]
NLP spam filters in early email programs helped email overtake telephone and fax communication channels in the '90s.
And some teams use NLP to automate and personalize e-mails between teammates or communicate with job applicants.

NLP pipelines, like all algorithms, make mistakes and are almost always biased in many ways.
So if you use NLP to automate communication with humans, be careful.
At Tangible AI we use NLP for the critical job of helping us find developers to join our team, so we were extremely cautious.
We used NLP to help us filter out job applications only when the candidate was nonresponsive or did not appear to understand several questions on the application.
We had rigorous quality control on the NLP pipeline with periodic random sampling of the model predictions.
We used simple models and sample-efficient NLP models footnote:["Are Sample-Efficient NLP Models More Robust?" by Nelson F. Liu, Ananya Kumar, Percy Liang, Robin Jia (https://arxiv.org/abs/2210.06456)] to focus human attention on those predictions where the machine learning was least confident -- see the `predict_proba` method on SciKit Learn classifiers.
As a result NLP for HR (human relations) actually cost us more time and attention and did not save us money.
But it did help us cast a broader net when looking for candidates.
We had hundreds of applications from around the globe for a junior developer role, including applicants located in Ukraine, Africa, Asia and South America.
NLP helped us quickly evaluate English and technical skill before proceeding with interviews and paid take-home assignments.

The spam filters have retained their edge in the cat-and-mouse game between spam filters and spam generators for email but may be losing in other environments like social networks.
An estimated 20% of the tweets about the 2016 US presidential election were composed by chatbots.footnote:[New York Times, Oct 18, 2016, https://www.nytimes.com/2016/11/18/technology/automated-pro-trump-bots-overwhelmed-pro-clinton-messages-researchers-say.html and MIT Technology Review, Nov 2016, https://www.technologyreview.com/s/602817/how-the-bot-y-politic-influenced-this-election/]
These bots amplify their owners' and developers' viewpoints with the resources and motivation to influence popular opinion.
And these "puppet masters" tend to be foreign governments or large corporations.

NLP systems can generate more than just short social network posts.
NLP can be used to compose lengthy movie and product reviews on online shop websites and elsewhere.
Many reviews are the creation of autonomous NLP pipelines that have never set foot in a movie theater or purchased the product they are reviewing.
And it's not just movies, a large portion of all product reviews that bubble to the top in search engines and online retailers are fake.
You can use NLP to help search engines and prosocial social media communities (Mastodon) footnote:["A beginners guide to Mastodon" on Tech Crunch (https://techcrunch.com/2022/11/08/what-is-mastodon/) by Amanda Silberling on Mastodon (https://mstdn.social/@amanda@journa.host)] detect and remove misleading or fake posts and reviews.footnote:[2021, E.Madhorubagan et al "Intelligent Interface for Fake Product Review Monitoring and Removal" (https://ijirt.org/master/publishedpaper/IJIRT151055_PAPER.pdf)]

There are chatbots on Slack, IRC, and even customer service websites -- places where chatbots have to deal with ambiguous commands or questions.
And chatbots paired with voice recognition and generation systems can even handle lengthy conversations with an indefinite goal or "objective function" such as making a reservation at a local restaurant.footnote:[Google Blog May 2018 about their _Duplex_ system https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html]
NLP systems can answer phones for companies that want something better than a phone tree, but they do not want to pay humans to help their customers.

[WARNING]
====
Consider the ethical implications whenever you, or your boss, decide to deceive your users. With its *Duplex* demonstration at Google IO, engineers and managers overlooked concerns about the ethics of teaching chatbots to deceive humans. In most "entertainment" social networks, bots are not required to reveal themselves. We unknowingly interact with these bots on Facebook, Reddit, Twitter and even dating apps. Now that bots and deep fakes can so convincingly deceive us, the AI control problem footnote:[Wikipedia is probably your most objective reference on the "AI control problem" (https://en.wikipedia.org/wiki/AI_control_problem).]. Yuval Harari's cautionary forecast of "Homo Deus"footnote:[WSJ Blog, March 10, 2017 https://blogs.wsj.com/cio/2017/03/10/homo-deus-author-yuval-noah-harari-says-authority-shifting-from-people-to-ai/] may come sooner than we think.
====

NLP systems exist that can act as email "receptionists" for businesses or executive assistants for managers.
These assistants schedule meetings and record summary details in an electronic Rolodex, or CRM (customer relationship management system), interacting with others by email on their boss's behalf.
Companies are putting their brand and face in the hands of NLP systems, allowing bots to execute marketing and messaging campaigns.
And some inexperienced daredevil NLP textbook authors are letting bots author several sentences in their book.
More on that later.

The most surprising and powerful application of NLP is in psychology.
If you think that a chatbot could never replace your therapist, you may be surprised by recent advancements.footnote:[John Michael Innes and Ben W. Morrison at the University of South Australia
"Machines can do most of a psychologist's job", 2021, (https://theconversation.com/machines-can-do-most-of-a-psychologists-job-the-industry-must-prepare-for-disruption-154064)]
Commercial virtual companions such as Xiaoice in China and Replika.AI in the US helped hundreds of millions of lonely people survive the emotional impact of social isolation during Covid-19 lockdowns in 2020 and 2021.footnote:[C.S. Voll "Humans Bonding with Virtual Companions" (https://medium.com/predict/humans-bonding-with-virtual-companions-6d19beae0077)]
Fortunately, you don't have to rely on engineers at large corporations to look out for your best interests. Many psychotherapy and cognitive assistant technology is completely free and open source.footnote:[Tangible AI builds open source cognitive assistants that help users take control of their emotions such as Syndee and `qary` (https://gitlab.com/tangibleai/qary) Some of Replika.AI's core technologies are open source (https://github.com/lukalabs)]


=== Processing programming languages with NLP

Modern deep-learning NLP pipelines have proven so powerful and versatile that they can now accurately understand and generate programming languages.
Rule-based compilers and generators for NLP were helpful for simple tasks like autocomplete and providing snippet suggestions.
And users can often use information retrieval systems, or search engines, to find snippets of code to complete their software development project.

And these tools just got a whole lot smarter.
Previous code generation tools were *extractive*.
Extractive text generation algorithms find the most relevant text in your history and just regurgitate it, verbatim as a suggestion to you.
So if the term "prosocial artificial intelligence" appears a lot in the text an algorithm was trained on, an auto-complete will recommend the word "artificial intelligence" to follow prosocial rather than just "intelligence".
You can see how this might start to influence what you type and how you think.

And transformers have advanced NLP even further recently with massive deep learning networks that are more *abstractive*, generating new text you haven't seen or typed before.
For example, the 175 billion parameter version of GPT-3 was trained on all of GitHub to create a model called Codex.
Codex is part of the Copilot plugin for VSCode.
It suggests entire function and class definitions and all you have to supply is a short comment and the first line of the function definition.
Here is the example for the typescript prompt shown on the copilot home page: footnote:[Taken from animation on copilot.github.com that was unchanged from 2022 to March 2023 (https://copilot.github.com/)]

[source,javascript]
----
// Determine whether the sentiment of text is positive
// Use a web service
async function isPositive(text: string): Promise<boolean> {
----

In the demo animation, Copilot then generated the rest of the typescript required for a working function that estimated the sentiment of a body of text.
//
// [source,javascript]
// ----
// async function isPositive(text: string): Promise<boolean> {
//   const response = await fetch(`http://text-processing.com/api/sentiment/`, {
//     method: "POST",
//     body: `text=${text}`,
//     headers: {
//       "Content-Type": "application/x-www-form-urlencoded",
//     },
//   });
//   const json = await response.json();
//   return json.label === "pos";
// }
// ----
//
Think about that for a second.
Microsoft's algorithm is writing code for you to analyze the sentiment of natural language text, such as the text you might be writing up in your emails or personal essay.
And the examples shown on the Copilot home page all lean towards Microsoft products and services.
This means you will end up with an NLP pipeline that has *Microsoft's* perspective on what is positive and what is not.
It values what *Microsoft* told it to value.
Just as Google Search influenced the kind of code you wrote indirectly, now Microsoft algorithms are directly writing code for you.

Since you're reading this book, you are probably planning to build some pretty cool NLP pipelines. You may even build a pipeline that helps you write blog posts and chatbots and core NLP algorithms.
This can create a positive feedback loop that shifts the kinds of NLP pipelines and models that are built and deployed by engineers like you.
So pay attention to the *meta* tools that you use to help you code and think.
These have huge leverage on the direction of your code, and the direction of your life.

== Language through a computer's "eyes"

When you type "Good Morning Rosa", a computer sees only "01000111 01101111 01101111 ...". How can you program a chatbot to respond to this binary stream intelligently?
Could a nested tree of conditionals (`if`... `else`..." statements) check each one of those bits and act on them individually?
This would be equivalent to writing a special kind of program called a finite state machine (FSM).
An FSM that outputs a sequence of new symbols as it runs, like the Python `str.translate` function, is called a finite state transducer (FST).
You've probably already built a FSM without even knowing it. Have you ever written a regular expression?
That's the kind of FSM we use in the next section to show you one possible approach to NLP: the pattern-based approach.

What if you decided to search a memory bank (database) for the exact same string of bits, characters, or words, and use one of the responses that other humans and authors have used for that statement in the past? 
But imagine if there was a typo or variation in the statement. 
Our bot would be sent off the rails. 
And bits aren't continuous or forgiving -- they either match or they do not. 
There is no obvious way to find a similarity between two streams of bits that takes into account what they signify. 
The bits for "good" will be just as similar to "bad!" as they are to "okay".

But let's see how this approach would work before we show you a better way. Let's build a small regular expression to recognize greetings like "Good morning Rosa" and respond appropriately -- our first tiny chatbot!

=== The language of locks

Surprisingly the humble combination lock is actually a simple language processing machine.
So, if you are mechanically inclined, this section may be illuminating.
But if you do not need mechanical analogies to help you understand algorithms and how regular expressions work, then you can skip this section.

After finishing this section, you will never think of your combination bicycle lock the same way again.
A combination lock certainly can't read and understand the textbooks stored inside a school locker, but it can understand the language of locks.
It can understand when you try to "tell" it a "password": a combination.
A padlock combination is any sequence of symbols that matches the "grammar" (pattern) of lock language.
Even more importantly, the padlock can tell if a lock "statement" matches a particularly meaningful statement, the one for which there is only one correct "response," to release the catch holding the U-shaped hasp so you can get into your locker.

This lock language (regular expressions) is a particularly simple one.
But it's not so simple that we can't use it in a chatbot.
We can use it to recognize a key phrase or command to unlock a particular action or behavior.

For example, we'd like our chatbot to recognize greetings such as "Hello Rosa," and respond to them appropriately.
This kind of language, like the language of locks, is a formal language because it has strict rules about how an acceptable statement must be composed and interpreted.
If you've ever written a math equation or coded a programming language expression, you've written a formal language statement.

Formal languages are a subset of natural languages.
Many natural language statements can be matched or generated using a formal language grammar, such as regular expressions or regular grammars.
That's the reason for this diversion into the mechanical, "click, whirr"footnote:[One of Cialdini's six psychology principles in his popular book _Influence_ http://changingminds.org/techniques/general/cialdini/click-whirr.htm] language of locks.

=== Regular expressions

Regular expressions use a special class of formal language grammars called a regular grammar.
Regular grammars have predictable, provable behavior, and yet are flexible enough to power some of the most sophisticated dialog engines and chatbots on the market.
Amazon Alexa and Google Now are mostly pattern-based engines that rely on regular grammars.
Deep, complex regular grammar rules can often be expressed in a single line of code called a regular expression.
There are successful chatbot frameworks in Python, like `Will`, footnote:[Steven Skoczen's Will chatbot framework (https://github.com/skoczen/will)] and `qary` footnote:[Tangible AI's chatbot framework called `qary` (https://docs.qary.ai) with examples deployed for WeSpeakNYC (https://wespeaknyc.cityofnewyork.us/) and others] that rely exclusively on this kind of language processing to produce some effective chatbots.

[NOTE]
====
Regular expressions implemented in Python and in Posix (Unix) applications such as `grep` are not true regular grammars.
They have language and logic features such as look-ahead and look-back that make leaps of logic and recursion that aren't allowed in a regular grammar.
As a result, regular expressions aren't provably halting; they can sometimes "crash" or run forever. footnote:[Stack Exchange Went Down for 30 minutes on July 20, 2016 when a regex "crashed" (http://stackstatus.net/post/147710624694/outage-postmortem-july-20-2016)]
====


You may be saying to yourself, "I've heard of regular expressions. I use `grep`. But that's only for search!"
And you are right. **R**egular **E**xpressions are indeed used mostly for search, for sequence matching.
But anything that can find matches within text is also great for carrying out a dialog.
Some chatbots, use "search" to find sequences of characters within a user statement that they know how to respond to.
These recognized sequences then trigger a scripted response appropriate to that particular regular expression match.
And that same regular expression can also be used to extract a useful piece of information from a statement.
A chatbot can add that bit of information to its knowledge base about the user or about the world the user is describing.

A machine that processes this kind of language can be thought of as a formal mathematical object called a finite state machine or deterministic finite automaton (DFA).
FSMs come up again and again in this book.
So, you will eventually get a good feel for what they're used for without digging into FSM theory and math.
For those who can't resist trying to understand a bit more about these computer science tools, figure 1.1 shows where FSMs fit into the nested world of automata (bots).
And the side note that follows explains a bit more formal detail about formal languages.

.Kinds of automata
image::../images/ch01/kinds-of-automata.png[alt="Figure 1.1: Kinds of automata", link="../images/ch01/kinds-of-automata.png"]

//p12 "formal grammar" --HL

.Formal mathematical explanation of formal languages
****
Kyle Gorman describes programming languages this way:

* Most (if not all) programming languages are drawn from the class of context-free languages.
* Context free languages are parsed with context-free grammars, which provide efficient parsing.
* The regular languages are also efficiently parsable and used extensively in computing for string matching.
* String matching applications rarely require the expressiveness of context-free.
* There are a number of formal language classes, a few of which are shown here (in decreasing complexity):footnote:[See the web page titled "Chomsky hierarchy - Wikipedia" (https://en.wikipedia.org/wiki/Chomsky_hierarchy).]
** Recursively enumerable
** Context-sensitive
** Context-free
** Regular

Natural languages are:

* Not regular footnote:["English is not a regular language" (http://cs.haifa.ac.il/~shuly/teaching/08/nlp/complexity.pdf#page=20) by Shuly Wintner]
* Not context-free footnote:["Is English context-free?" (http://cs.haifa.ac.il/~shuly/teaching/08/nlp/complexity.pdf#page=24) by Shuly Wintner]
* Can't be defined by any formal grammar footnote:[See the web page titled "1.11. Formal and Natural Languages — How to Think like a Computer Scientist: Interactive Edition" (https://runestone.academy/ns/books/published/fopp/GeneralIntro/FormalandNaturalLanguages.html).]
****

== A simple chatbot

Let us build a quick and dirty chatbot.
It will not be very capable, and it will require a lot of thinking about the English language.
You will also have to hardcode regular expressions to match the ways people may try to say something.
But do not worry if you think you couldn't have come up with this Python code yourself.
You will not have to try to think of all the different ways people can say something, like we did in this example.
You will not even have to write regular expressions (regexes) to build an awesome chatbot.
We show you how to build a chatbot of your own in later chapters without hardcoding anything.
A modern chatbot can learn from reading (processing) a bunch of English text.
And we show you how to do that in later chapters.

This pattern-matching chatbot is an example of a tightly controlled chatbot.
Pattern-matching chatbots were common before modern machine learning chatbot techniques were developed.
And a variation of the pattern-matching approach we show you here is used in chatbots like Amazon Alexa and other virtual assistants.

For now let's build an FSM, a regular expression, that can speak lock language (regular language).
We could program it to understand lock language statements, such as "01-02-03."
Even better, we'd like it to understand greetings, things like "open sesame" or "hello Rosa."

An important feature of a prosocial chatbot is to be able to respond to a greeting.
In high school, teachers often chastised me for being impolite when I'd ignore greetings like this while rushing to class.
We surely do not want that for our benevolent chatbot.

For communication between two machines, you would define a handshake with something like an `ACK` (acknowledgement) signal to confirm receipt of each message.
But our machines are going to be interacting with humans who say things like "Good morning, Rosa".
We do not want it sending out a bunch of chirps, beeps, or `ACK` messages, like it's syncing up a modem or HTTP connection at the start of a conversation or web browsing session.

Human greetings and handshakes are a little more informal and flexible.
So recognizing the greeting _intent_ won't be as simple as building a machine handshake.
You will want a few different approaches in your toolbox.

[NOTE]
====
An intent is a category of possible intentions the user has for the NLP system or chatbot.
Words "hello" and "hi" might be collected together under the _greeting_ intent, for when the user wants to start a conversation.
Another intent might be to carry out some task or command, such as a "translate" command or the query "How do I say 'Hello' in Ukrainian?".
You'll learn about intent recognition throughout the book and put it to use in a chatbot in chapter 12.
====

== Keyword-based greeting recognizer

Your first chatbot will be straight out of the 80's.
Imagine you want a chatbot to help you select a game to play, like chess... or a Thermonuclear War.
But first, your chatbot must find out if you are Professor Falken or General Beringer, or some other user that knows what they are doing.footnote:[The code here simplifies the behavior of the chatbot called "Joshua" in the "War Games" movie. See Wikiquote (https://en.wikiquote.org/wiki/WarGames) for more chatbot script ideas.]
It will only be able to recognize a few greetings.
But this approach can be extended to help you implement simple keyword-based intent recognizers on projects similar to those mentioned earlier in this chapter.

[[hello_joshua_split_py]]
.Keyword detection using `str.split`
[source,python]
----
>>> greetings = "Hi Hello Greetings".split()
>>> user_statement = "Hello Joshua"
>>> user_token_sequence = user_statement.split()
>>> user_token_sequence
['Hello', 'Joshua']
>>> if user_token_sequence[0] in greetings:
...     bot_reply = "Themonucluear War is a strange game. "  # <1>
...     bot_reply += "The only winning move is NOT TO PLAY."
>>> else:
...     bot_reply = "Would you like to play a nice game of chess?"
>>> bot_reply
'Themonucluear War is a strange game. The only winning move is NOT TO PLAY.'
----
<1> "Hi", "Hello", and "Greetings" might be the keywords programmed into Joshua, running on a supercomputer called "WOPR" in _War Games_.

This simple NLP pipeline (program) has only two intent categories: "greeting" and "unknown" (`else`).
And it uses a very simple algorithm called keyword detection.
Chatbots that recognize the user's intent like this have capabilities similar to modern command line applications or phone trees from the 90's.

Rule-based chatbots can be much more fun and flexible than this simple program.
Developers have so much fun building and interacting with chatbots that they build chatbots to make even deploying and monitoring servers a lot of fun.
_Chatops_, or DevOps with chatbots, has become popular on most software development teams.
You can build a chatbot like this to recognize more intents by adding `elif` statements before the `else`.
Or you can go beyond keyword-based NLP and start thinking about ways to improve it using regular expressions.

=== Pattern-based intent recognition

A keyword-based chatbot would recognize "Hi", "Hello", and "Greetings", but it wouldn't recognize "Hiiii" or "Hiiiiiiiiiiii" - the more excited renditions of "Hi".
Perhaps you could hardcode the first 200 versions of "Hi", such as `["Hi", "Hii", "Hiii", ...]`.
Or you could programmatically create such a list of keywords.
Or you could save yourself a lot of trouble and make your bot deal with literally infinite variations of "Hi" using  _regular expressions_.
Regular expression _patterns_ can match text much more robustly than any hard-coded rules or lists of keywords.

Regular expressions recognize patterns for any sequence of characters or symbols.footnote:[SpaCy 'Matcher' (https://spacy.io/api/matcher) is a regular expression interpreter for patterns of words, parts of speech, and other symbol sequences.]
With keyword-based NLP, you and your users need to spell keywords and commands in exactly the same way for the machine to respond correctly.
So your keyword greeting recognizer would miss greetings like "Hey" or even "hi" because those strings aren't in your list of greeting words.
And what if your "user" used a greeting that starts or ends with punctuation, such as "'sup" or "Hi,".
You could do _case folding_ with the `str.split()` method on both your greetings and the user statement.
And you could add more greetings to your list of greeting words.
You could even add misspellings and typos to ensure they aren't missed.
But that is a lot of manual "hard-coding" of data into your NLP pipeline.

You will soon learn how to use machine learning for more data-driven and automated NLP pipelines.
And when you graduate to the much more complex and accurate _deep learning_ models of chapter 7 and beyond, you will find that there is still much "brittleness" in modern NLP pipelines.
Robin Jia's thesis explains how to measure and improve NLP robustness in his thesis (https://proai.org/robinjia-thesis)]
But for now, you need to understand the basics.
When your user wants to specify actions with precise patterns of characters similar to programming language commands, that's where regular expressions shine.

[source,python]
----
>>> import re  # <1>
>>> r = "(hi|hello|hey)[ ,:.!]*([a-z]*)"  # <2>
>>> re.match(r, 'Hello Rosa', flags=re.IGNORECASE)  # <3>
<re.Match object; span=(0, 10), match='Hello Rosa'>
>>> re.match(r, "hi ho, hi ho, it's off to work ...", flags=re.IGNORECASE)
<re.Match object; span=(0, 5), match='hi ho'>
>>> re.match(r, "hey, what's up", flags=re.IGNORECASE)
<re.Match object; span=(0, 9), match='hey, what'>
----
<1> There are two "official" regular expression packages in Python. The `re` package is pre-installed with all versions of Python. The `regex` package includes additional features such as fuzzy pattern matching.
<2> `'|'` means "OR", '\*' means the preceding characters can occur 0 or more times and still match.
<3> Ignoring the character case means this regular expression will match "Hey" as well as "hey".

In regular expressions, you can specify a character class with square brackets.
And you can use a dash (`-`) to indicate a range of characters without having to type them all out individually.
So the regular expression `"[a-z]"` will match any single lowercase letter, "a" through "z".
The star ("\*") after a character class means that the regular expression will match any number of consecutive characters if they are all within that character class.

Let's make our regular expression a lot more detailed to try to match more greetings.

[source,python]
----
>>> r = r"[^a-z]*([y]o|[h']?ello|ok|hey|(good[ ])(morn[gin']{0,3}|"
>>> r += r"afternoon|even[gin']{0,3}))[\s,;:]{1,3}([a-z]{1,20})"
>>> re_greeting = re.compile(r, flags=re.IGNORECASE)  # <1>
>>> re_greeting.match('Hello Rosa')
<re.Match object; span=(0, 10), match='Hello Rosa'>
>>> re_greeting.match('Hello Rosa').groups()
('Hello', None, None, 'Rosa')
>>> re_greeting.match("Good morning Rosa")
<re.Match object; span=(0, 17), match="Good morning Rosa">
>>> re_greeting.match("Good Manning Rosa")  # <2>
>>> re_greeting.match('Good evening Rosa Parks').groups()  # <3>
('Good evening', 'Good ', 'evening', 'Rosa')
>>> re_greeting.match("Good Morn'n Rosa")
<re.Match object; span=(0, 16), match="Good Morn'n Rosa">
>>> re_greeting.match("yo Rosa")
<re.Match object; span=(0, 7), match='yo Rosa'>
----
<1> You can compile regular expressions so you do not have to specify the options (`flags`) each time you use it.
<2> Notice that this regular expression cannot recognize (match) words with typos.
<3> Our chatbot can separate different parts of the greeting into `groups`, but it will be unaware of Rosa's famous last name, because we do not have a pattern to match any characters after the first name.

[TIP]
====
The "r" before the quote symbol (`r'`) indicates that the quoted string literal is a _raw_ string.
The "r" does not mean *regular* expression.
A Python raw string just makes it easier to use the backslashes used to escape special symbols within a regular expression.
Telling Python that a string is "raw" means that Python will skip processing the backslashes and pass them on to the regular expression parser (`re` package).
Otherwise, you would have to escape each and every backslash in your regular expression with a double backslash (`'\\'`).
So the whitespace matching symbol `'\s'` would become `'\\s'`, and special characters like literal curly braces would become `'\\{'` and `'\\}'`.
====

There is a lot of logic packed into that first line of code, the regular expression.
It gets the job done for a surprising range of greetings.
But it missed that "Manning" typo, which is one of the reasons NLP is hard.
In machine learning and medical diagnostic testing, that's called a _false negative_ classification error.
Unfortunately, it will also match some statements that humans would be unlikely to ever say -- a _false positive_, which is also a bad thing.
Having both false positive and false negative errors means that our regular expression is both too liberal (inclusive) and too strict (exclusive).
These mistakes could make our bot sound a bit dull and mechanical.
We'd have to do a lot more work to refine the phrases it matches for the bot to behave in a more intelligent human-like way.

And this tedious work would be highly unlikely to ever succeed at capturing all the slang and misspellings people use.
Fortunately, composing regular expressions by hand isn't the only way to train a chatbot.
Stay tuned for more on that later (the entire rest of the book).
So we only use them when we need precise control over a chatbot's behavior, such as when issuing commands to a voice assistant on your mobile phone.

But let's go ahead and finish up our one-trick chatbot by adding an output generator.
It needs to say something.
We use Python's string formatter to create a "template" for our chatbot response.

[source,python]
----
>>> my_names = set(['rosa', 'rose', 'chatty', 'chatbot', 'bot',
...     'chatterbot'])
>>> curt_names = set(['hal', 'you', 'u'])
>>> greeter_name = ''  # <1>
>>> match = re_greeting.match(input())
...
>>> if match:
...     at_name = match.groups()[-1]
...     if at_name in curt_names:
...         print("Good one.")
...     elif at_name.lower() in my_names:
...         print("Hi {}, How are you?".format(greeter_name))
----
<1> We do not yet know who is chatting with the bot, and we will not worry about it here.

So if you run this little script and chat to our bot with a phrase like "Hello Rosa", it will respond by asking about your day.
If you use a slightly rude name to address the chatbot, she will be less responsive, but not inflammatory, to encourage politeness.footnote:[The idea for this defusing response originated with Viktor Frankl's _Man's Search for Meaning_, his Logotherapy (https://en.wikipedia.org/wiki/Logotherapy) approach to psychology and the many popular novels where a child protagonist like Owen Meany has the wisdom to respond to an insult with a response like this.]
If you name someone else who might be monitoring the conversation on a party line or forum, the bot will keep quiet and allow you and whomever you are addressing to chat.
Obviously, there is no one else out there watching our `input()` line, but if this were a function within a larger chatbot, you want to deal with these sorts of things.

Because of the limitations of computational resources, early NLP researchers had to use their human brain's computational power to design and hand-tune complex logical rules to extract information from a natural language string.
This is called a pattern-based approach to NLP.
The patterns do not have to be merely character sequence patterns, like our regular expression.
NLP also often involves patterns of word sequences, or parts of speech, or other "higher level" patterns.
The core NLP building blocks like stemmers and tokenizers as well as sophisticated end-to-end NLP dialog engines (chatbots) like ELIZA were built this way, from regular expressions and pattern matching.
The art of pattern-matching approaches to NLP is coming up with elegant patterns that capture just what you want, without too many lines of regular expression code.

[TIP]
.Theory of a computational mind
====
This classical NLP pattern-matching approach is based on the computational theory of mind (CTM).
CTM theorizes that thinking is a deterministic computational process that acts in a single logical thread or sequence.footnote:[Stanford Encyclopedia of Philosophy, Computational Theory of Mind, https://plato.stanford.edu/entries/computational-mind/]
Advancements in neuroscience and NLP led to the development of a "connectionist" theory of mind around the turn of the century.
This newer theory inspired the artificial neural networks of deep learning used that process natural language sequences in many different ways simultaneously, in parallel.footnote:[Stanford Encyclopedia of Philosophy, Connectionism, https://plato.stanford.edu/entries/connectionism/] footnote:[Christiansen and Chater, 1999, Southern Illinois University (https://crl.ucsd.edu/~elman/Bulgaria/christiansen-chater-soa.pdf)]
====

In Chapter 2 you will learn more about pattern-based approaches to tokenizing -- splitting text into tokens or words with algorithms such as the "Treebank tokenizer."
You will also learn how to use pattern matching to stem (shorten and consolidate) tokens with something called a Porter stemmer.
But in later chapters we take advantage of the exponentially greater computational resources, as well as our larger datasets, to shortcut this laborious hand programming and refining.

If you are new to regular expressions and want to learn more, you can check out Appendix B or the online documentation for Python regular expressions. 
But you do not have to understand them just yet. 
We'll continue to provide you with sample regular expressions as we use them for the building blocks of our NLP pipeline. 
So, do not worry if they look like gibberish. 
Human brains are pretty good at generalizing from a set of examples, and I'm sure it will become clear by the end of this book. 
And it turns out machines can learn this way as well...

=== Another way

Imagine a giant database containing sessions of dialog between humans.
You might have statements paired with responses from thousands or even millions of conversations.
One way to build a chatbot would be to search such a database for the exact same string of characters the user just "said" to your chatbot.
And then you could use one of the responses to that statement that other humans have said in the past.
That would result in a statistical or data-driven approach to chatbot design.
And that could take the place of all that tedious pattern-matching algorithm design.

Think about how a single typo or variation in the statement would trip up a pattern-matching bot or even a data-driven bot with millions of statements (utterances) in its database.
Bit and character sequences are discrete and very precise.
They either match or they do not.
And people are creative.
It may not seem like it sometimes, but very often people say something with new patterns of characters never seen before.
So you'd like your bot to be able to measure the difference in _meaning_ between character sequences.
In later chapters, you'll get better and better at extracting meaning from text!

When we use character sequence matches to measure distance between natural language phrases, we'll often get it wrong.
Phrases with similar meanings, like "good" and "okay", can often have different character sequences and large distances when we count up character-by-character matches to measure distance.
And sometimes two words look almost the same but mean completely different things: "bad" and "bag."
You can count the number of characters that change from one word to another with algorithms such as Jaccard and Levenshtein algorithms.
But these distance or "change" counts fail to capture the essence of the relationship between two dissimilar strings of characters such as "good" and "okay.".=
And they fail to account for how small spelling differences might not really be typos but rather completely different words, such as "bad" and "bag".

Distance metrics designed for numerical sequences and vectors are useful for a few NLP applications, like spelling correctors and recognizing proper nouns.
So we use these distance metrics when they make sense.
But for NLP applications where we are more interested in the meaning of the natural language than its spelling, there are better approaches.
We use vector representations of natural language words and text and some distance metrics for those vectors for those NLP applications.
We show you each approach, one by one, as we talk about these different applications and the kinds of vectors they are used with.

We do not stay in this confusing binary world of logic for long, but let's imagine we're famous World War II-era code-breaker Mavis Batey at Bletchley Park and we have just been handed that binary, Morse code message intercepted from communication between two German military officers. 
It could hold the key to winning the war. Where would we start? 
Well, the first layer of deciding would be to do something statistical with that stream of bits to see if we can find patterns. 
We can first use the Morse code table (or ASCII table, in our case) to assign letters to each group of bits. 
Then, if the characters are gibberish to us, as they are to a computer or a cryptographer in WWII, we could start counting them up, looking up the short sequences in a dictionary of all the words we have seen before and putting a mark next to the entry every time it occurs. 
We might also make a mark in some other log book to indicate which message the word occurred in, creating an encyclopedic index to all the documents we have read before. 
This collection of documents is called a _corpus_, and the words or sequences we have listed in our index are called a _lexicon_.

If we're lucky, and we're not at war, and the messages we're looking at aren't strongly encrypted, we'll see patterns in those German word counts that mirror counts of English words used to communicate similar kinds of messages.
Unlike a cryptographer trying to decipher German Morse code intercepts, we know that the symbols have consistent meaning and aren't changed with every key click to try to confuse us.
This tedious counting of characters and words is just the sort of thing a computer can do without thinking.
And surprisingly, it's nearly enough to make the machine appear to understand our language.
It can even do math on these statistical vectors that coincides with our human understanding of those phrases and words.
When we show you how to teach a machine our language using Word2Vec in later chapters, it may seem magical, but it's not.
It's just math, computation.

But let's think for a moment about what information has been lost in our effort to count all the words in the messages we receive. 
We assign the words to bins and store them away as bit vectors like a coin or token sorter (see Figure 1.2) directing different kinds of tokens to one side or the other in a cascade of decisions that piles them in bins at the bottom.
 Our sorting machine must take into account hundreds of thousands if not millions of possible token "denominations," one for each possible word that a speaker or author might use. 
 Each phrase or sentence or document we feed into our token sorting machine will come out the bottom, where we have a "vector" with a count of the tokens in each slot. 
 Most of our counts are zero, even for large documents with verbose vocabulary. 
 But we have not lost any words yet. 
 What have we lost? 
 Could you, as a human understand a document that we presented you in this way, as a count of each possible word in your language, without any sequence or order associated with those words? 
 I doubt it. 
 But if it was a short sentence or tweet, you'd probably be able to rearrange them into their intended order and meaning most of the time.

////
This is likely a copyrighted image. -HL
////

.Canadian coin sorter
image::../images/ch01/canadian-coin-sorter.jpg[alt="Figure 1.2: Canadian coin sorter",width=200,link="../images/ch01/canadian-coin-sorter.jpg"]

Here's how our token sorter fits into an NLP pipeline right after a tokenizer (see Chapter 2). 
We have included a stopword filter as well as a "rare" word filter in our mechanical token sorter sketch. 
Strings flow in from the top, and bag-of-word vectors are created from the height profile of the token "stacks" at the bottom.

.Token sorting tray
image::../images/ch01/sketch-token-sorter.png[alt="Figure 1.3: Token Sorting Tray",width=500,link="../images/ch01/sketch-token-sorter.png"]

It turns out that machines can handle this bag of words quite well and glean most of the information content of even moderately long documents this way. 
Each document, after token sorting and counting, can be represented as a vector, a sequence of integers for each word or token in that document. 
You see a crude example in Figure 1.3, and then Chapter 2 shows some more useful data structures for bag-of-word vectors.

This is our first vector space model of a language. 
Those bins and the numbers they contain for each word are represented as long vectors containing a lot of zeros and a few ones or twos scattered around wherever the word for that bin occurred. 
All the different ways that words could be combined to create these vectors is called a _vector space_. 
And relationships between vectors in this space are what make up our model, which is attempting to predict combinations of these words occurring within a collection of various sequences of words (typically sentences or documents). 
In Python, we can represent these sparse (mostly empty) vectors (lists of numbers) as dictionaries. 
And a Python `Counter` is a special kind of dictionary that bins objects (including strings) and counts them just like we want.

[source,python]
----
>>> from collections import Counter

>>> Counter("Guten Morgen Rosa".split())
Counter({'Guten': 1, 'Rosa': 1, 'morgen': 1})
>>> Counter("Good morning, Rosa!".split())
Counter({'Good': 1, 'Rosa!': 1, 'morning,': 1})
----

You can probably imagine some ways to clean those tokens up. 
We do just that in the next chapter. 
But you might also think to yourself that these sparse, high-dimensional vectors (many bins, one for each possible word) aren't very useful for language processing. 
They are, however, good enough for some industry-changing tools like spam filters, which we discuss in Chapter 3.

And we can imagine feeding into this machine, one at a time, all the documents, statements, sentences, and even single words we could find. 
We'd count up the tokens in each slot at the bottom after each of these statements was processed, and we'd call that a vector representation of that statement. 
All the possible vectors a machine might create this way is called a _vector space_. 
And this model of documents and statements and words is called a _vector space model_. 
It allows us to use linear algebra to manipulate these vectors and compute things like distances and statistics about natural language statements, which helps us solve a much wider range of problems with less human programming and less brittleness in the NLP pipeline. 
One statistical question that is asked of bag-of-words vector sequences is, "What is the combination of words most likely to follow a particular bag of words?" 
Or, even better, if a user enters a sequence of words, "What is the closest bag of words in our database to a bag-of-words vector provided by the user?" 
This is a search query. 
The input words are the words you might type into a search box, and the closest bag-of-words vector corresponds to the document or web page you were looking for. 
The ability to efficiently answer these two questions would be sufficient to build a machine learning chatbot that could get better and better as we gave it more and more data.

But wait a minute, perhaps these vectors aren't like any you've ever worked with before.
They're extremely high-dimensional.
It's possible to have millions of dimensions for a 3-gram vocabulary computed from a large corpus.
In Chapter 3, we discuss the curse of dimensionality and some other properties that make high-dimensional vectors difficult to work with.

== A brief overflight of hyperspace

In Chapter 3 you will learn how to consolidate words into a smaller number of vector dimensions to deal with the _curse of dimensionality_.
You may even be able to turn the curse into a blessing by using all those dimensions to identify the subtle things that you want your NLU pipeline to understand.
You project vectors onto each other to determine the distance between each pair.
This gives you a reasonable estimate of the similarity in their _meaning_ rather than merely their statistical word usage.
When you compute a vector distance this way it is called a _cosine distance metric_.
You will first use cosine distance in Chapter 3, and then uncover its true power when you are able to reduce the thousands of dimensions of topic vectors down to just a few in Chapter 4.
You can even project ("embed" is the more precise term) these vectors onto a 2D plane to have a "look" at them in plots and diagrams.
This is one of the best ways to find patterns and clusters in high dimensional data.
You can then teach a computer to recognize and act on these patterns in ways that reflect the underlying meaning of the words that produced those vectors.

Imagine all the possible tweets or messages or sentences that humans might write.
Even though we do repeat ourselves a lot, that's still a lot of possibilities.
And when those tokens are each treated as separate, distinct dimensions, there is no concept that "Good morning, Hobs" has some shared meaning with "Guten Morgen, Hannes."
We need to create some reduced dimension vector space model of messages so we can label them with a set of continuous (float) values.
We could rate messages and words for qualities like subject matter and sentiment. We could ask questions like:

* How likely is this message to be a question?
* How much is it about a person?
* How much is it about me?
* How angry or happy does it sound?
* Is it something I need to respond to?

Think of all the ratings we could give statements.
We could put these ratings in order and "compute" them for each statement to compile a "vector" for each statement.
The list of ratings or dimensions we could give a set of statements should be much smaller than the number of possible statements, and statements that mean the same thing should have similar values for all our questions.

These rating vectors become something that a machine can be programmed to react to. 
We can simplify and generalize vectors further by clumping (clustering) statements together, making them close on some dimensions and not on others.

But how can a computer assign values to each of these vector dimensions? 
Well, if we simplified our vector dimension questions to things like, "Does it contain the word 'good'? Does it contain the word 'morning'?" 
And so on. You can see that we might be able to come up with a million or so questions resulting in numerical value assignments that a computer could make to a phrase. 
This is the first practical vector space model, called a bit vector language model, or the sum of "one-hot encoded" vectors. 
You can see why computers are just now getting powerful enough to make sense of natural language. 
The millions of million-dimensional vectors that humans might generate simply "Does not compute!" on a supercomputer of the 80s, but is no problem on a commodity laptop in the 21st century. 
More than just raw hardware power and capacity made NLP practical; incremental, constant-RAM, linear algebra algorithms were the final piece of the puzzle that allowed machines to crack the code of natural language.

There is an even simpler, but much larger representation that can be used in a chatbot.
What if our vector dimensions completely described the exact sequence of characters?
The vector for each character would contain the answer to binary (yes/no) questions about every letter and punctuation mark in your alphabet:

"Is the first letter an 'A'?"
"Is the first letter a 'B'?"
...
"Is the first letter a 'z'?"

And the next vector would answer the same boring questions about the next letter in the sequence.

"Is the second letter an A?"
"Is the second letter a B?"
...

Despite all the "no" answers or zeroes in this vector sequence, it does have one advantage over all other possible representations of text - it retains every tiny detail, every bit of information contained in the original text, including the order of the characters and words.
This is like the paper representation of a song for a player piano that only plays a single note at a time.
The "notes" for this natural language mechanical player piano are the 26 uppercase and lowercase letters plus any punctuation that the piano must know how to "play."
The paper roll wouldn't have to be much wider than for a real player piano and the number of notes in some long piano songs doesn't exceed the number of characters in a small document.

But this one-hot character sequence encoding representation is mainly useful for recording and then replaying an exact piece rather than composing something new or extracting the essence of a piece.
We can't easily compare the piano paper roll for one song to that of another.
And this representation is longer than the original ASCII-encoded representation of the document.
The number of possible document representations just exploded to retain information about each sequence of characters.
We retained the order of characters and words but expanded the dimensionality of our NLP problem.

These representations of documents do not cluster together well in this character-based vector world.  
The Russian mathematician Vladimir Levenshtein came up with a brilliant approach for quickly finding similarities between vectors (strings of characters) in this world. 
Levenshtein's algorithm made it possible to create some surprisingly fun and useful chatbots, with only this simplistic, mechanical view of language. 
But the real magic happened when we figured out how to compress/embed these higher dimensional spaces into a lower dimensional space of fuzzy meaning or topic vectors.
 We peek behind the magician's curtain in Chapter 4, when we talk about latent semantic indexing and latent Dirichlet allocation, two techniques for creating much more dense and meaningful vector representations of statements and documents.


== Word order and grammar

The order of words matters. 
Those rules that govern word order in a sequence of words (like a sentence) are called the grammar of a language. 
That's something that our bag of words or word vector discarded in the earlier examples. 
Fortunately, in most short phrases and even many complete sentences, this word vector approximation works OK. 
If you just want to encode the general sense and sentiment of a short sentence, word order is not terribly important. 
Take a look at all these orderings of our "Good morning Rosa" example.

[source,python]
----
>>> from itertools import permutations

>>> [" ".join(combo) for combo in\
...     permutations("Good morning Rosa!".split(), 3)]
['Good morning Rosa!',
 'Good Rosa! morning',
 'morning Good Rosa!',
 'morning Rosa! Good',
 'Rosa! Good morning',
 'Rosa! morning Good']
----

Now if you tried to interpret each of those strings in isolation (without looking at the others), you'd probably conclude that they all probably had similar intent or meaning. 
You might even notice the capitalization of the word "Good" and place the word at the front of the phrase in your mind. 
But you might also think that "Good Rosa" was some sort of proper noun, like the name of a restaurant or flower shop. 
Nonetheless, a smart chatbot or clever woman of the 1940s in Bletchley Park would likely respond to any of these six permutations with the same innocuous greeting, "Good morning my dear General."

Let's try that (in our heads) on a much longer, more complex phrase, a logical statement where the order of the words matters a lot:

[source,python]
----
>>> s = """Find textbooks with titles containing 'NLP',
...     or 'natural' and 'language', or
...     'computational' and  'linguistics'."""
>>> len(set(s.split()))
12
>>> import numpy as np
>>> np.arange(1, 12 + 1).prod()  # factorial(12) = arange(1, 13).prod()
479001600
----

The number of permutations exploded from `factorial(3) == 6` in our simple greeting to `factorial(12) ==  479001600` in our longer statement!
And it's clear that the logic contained in the order of the words is important to any machine that would like to reply with the correct response.
Even though common greetings are not usually garbled by bag-of-words processing, more complex statements can lose most of their meaning when thrown into a bag.
A bag of words is not the best way to begin processing a database query, like the natural language query in the preceding example.

Whether a statement is written in a formal programming language like SQL, or in an informal natural language like English, word order and grammar are important when a statement intends to convey logical relationships between things.
That's why computer languages depend on rigid grammar and syntax rule parsers.
Fortunately, recent advances in natural language syntax tree parsers have made possible the extraction of syntactical and logical relationships from natural language with remarkable accuracy (greater than 90%).footnote:[A comparison of the syntax parsing accuracy of SpaCy (93%), SyntaxNet (94%), Stanford's CoreNLP (90%), and others is available at https://spacy.io/docs/api/]
In later chapters, we show you how to use packages like `SyntaxNet` (Parsey McParseface) and `SpaCy` to identify these relationships.

And just as in the Bletchley Park example greeting, even if a statement doesn't rely on word order for logical interpretation, sometimes paying attention to that word order can reveal subtle hints of meaning that might facilitate deeper responses. 
These deeper layers of natural language processing are discussed in the next section. 
And Chapter 2 shows you a trick for incorporating some of the information conveyed by word order into our word-vector representation. 
It also shows you how to refine the crude tokenizer used in the previous examples  (`str.split()`) to more accurately bin words into more appropriate slots within the word vector, so that strings like "good" and "Good" are assigned the same bin, and separate bins can be allocated for tokens like "rosa" and "Rosa" but not "Rosa!".

== A chatbot natural language pipeline

The NLP pipeline required to build a dialog engine, or chatbot, is similar to the pipeline required to build a question answering system described in _Taming Text_ (Manning, 2013).footnote:[Ingersol, Morton, and Farris, http://www.manning.com/books/taming-text/?a_aid=totalgood] However, some of the algorithms listed within the five subsystem blocks may be new to you. We help you implement these in Python to accomplish various NLP tasks essential for most applications, including chatbots.

.Chatbot recirculating (recurrent) pipeline
image::../images/ch01/chatbot-pipeline.png[alt="Chatbot Recirculating (Recurrent) Pipeline",align="center",width=70%,alt="Figure 1.4: Chatbot block diagram showing text flowing in and responses flowing out with 4 blocks: parse, analyze, generate, execute. Execute selects the generated text to output. Analyze is run twice, once on the parsed input text and again on the set of generated candidate responses. Execute uses this analysis of things like sentiment and grammaticality to select a response." link="../images/ch01/chatbot-pipeline.png"]

A chatbot requires four kinds of processing as well as a database to maintain a memory of past statements and responses. 
Each of the four processing stages can contain one or more processing algorithms working in parallel or in series (see figure 1.4).

1. _Parse_ -- Extract features, structured numerical data, from natural language text.
2. _Analyze_ -- Generate and combine features by scoring text for sentiment, grammaticality, semantics.
3. _Generate_ -- Compose possible responses using templates, search, or language models.
4. _Execute_ -- Plan statements based on conversation history and objectives, and select the next response.

Each of these four stages can be implemented using one or more of the algorithms listed within the corresponding boxes in the block diagram.
We show you how to use Python to accomplish near-state-of-the-art performance for each of these processing steps. And we show you several alternative approaches to implementing these five subsystems.

Most chatbots will contain elements of all five of these subsystems (the four processing stages as well as the database). 
But many applications require only simple algorithms for many of these steps. 
Some chatbots are better at answering factual questions, and others are better at generating lengthy, complex, convincingly human responses. 
Each of these capabilities requires different approaches; we show you techniques for both.

In addition, deep learning and data-driven programming (machine learning, or probabilistic language modeling) have rapidly diversified the possible applications for NLP and chatbots. 
This data-driven approach allows ever greater sophistication for an NLP pipeline by providing it with greater and greater amounts of data in the domain you want to apply it to. 
And when a new machine learning approach is discovered that makes even better use of this data, with more efficient model generalization or regularization, then large jumps in capability are possible.

The NLP pipeline for a chatbot shown in Figure 1.4 contains all the building blocks for most of the NLP applications that we described at the start of this chapter. 
As in _Taming Text_, we break out our pipeline into four main subsystems or stages. 
In addition, we have explicitly called out a database to record data required for each of these stages and persist their configuration and training sets over time. 
This can enable batch or online retraining of each of the stages as the chatbot interacts with the world.
We have also shown a "feedback loop" on our generated text responses so that our responses can be processed using the same algorithms used to process the user statements. 
The response "scores" or features can then be combined in an objective function to evaluate and select the best possible response, depending on the chatbot's plan or goals for the dialog. 
This book is focused on configuring this NLP pipeline for a chatbot, but you may also be able to see the analogy to the NLP problem of text retrieval or "search," perhaps the most common NLP application. 
And our chatbot pipeline is certainly appropriate for the question-answering application that was the focus of _Taming Text_.

The application of this pipeline to financial forecasting or business analytics may not be so obvious.
But imagine the features generated by the analysis portion of your pipeline.
These features of your analysis or feature generation can be optimized for your particular finance or business prediction.
That way they can help you incorporate natural language data into a machine learning pipeline for forecasting.
Despite focusing on building a chatbot, this book gives you the tools you need for a broad range of NLP applications, from search to financial forecasting.

One processing element in Figure 1.4 that is not typically employed in search, forecasting, or question-answering systems is natural language _generation_. 
For chatbots, this is their central feature. 
Nonetheless, the text generation step is often incorporated into a search engine NLP application and can give such an engine a large competitive advantage. 
The ability to consolidate or summarize search results is a winning feature for many popular search engines (DuckDuckGo, Bing, and Google). 
And you can imagine how valuable it is for a financial forecasting engine to be able to generate statements, tweets, or entire articles based on the business-actionable events it detects in natural language streams from social media networks and news feeds.

The next section shows how the layers of such a system can be combined to create greater sophistication and capability at each stage of the NLP pipeline.


== Processing in depth

The stages of a natural language processing pipeline can be thought of as layers, like the layers in a feed-forward neural network. 
Deep learning is all about creating more complex models and behavior by adding additional processing layers to the conventional two-layer machine learning model architecture of feature extraction followed by modeling. 
In Chapter 5 we explain how neural networks help spread the learning across layers by backpropagating model errors from the output layers back to the input layers. 
But here we talk about the top layers and what can be done by training each layer independently of the other layers.

.Example layers for an NLP pipeline
image::../images/ch01/nlp-layers.png[alt="Example layers for an NLP pipeline: Algorithms, data structures, example data, and applications in four columns for the layers of a 'deep' NLP pipeline. Layers of features shown from the top to bottom with characters at the top, tokens below that, tagged tokens next, syntax trees next, and finally a knowledge base at the bottom. A knowledge base is the deepest feature in an NLP pipeline. These features are analogous to the layers of a deep learning neural network like a CNN or LSTM.",link="../images/ch01/nlp-layers.png"]

The top four layers in Figure 1.8 correspond to the first two stages in the chatbot pipeline (feature extraction and feature analysis) in the previous section.
For example, part-of-speech tagging (POS tagging), is one way to generate features within the Analyze stage of our chatbot pipeline.
POS tags are generated automatically by the default `SpaCY` pipeline, which includes all the top four layers in this diagram.
POS tagging is typically accomplished with a finite state transducer like the methods in the `nltk.tag` package.

The bottom two layers (Entity Relationships and a Knowledge Base) are used to populate a database containing information (knowledge) about a particular domain. 
And the information extracted from a particular statement or document using all six of these layers can then be used in combination with that database to make inferences. 
Inferences are logical extrapolations from a set of conditions detected in the environment, like the logic contained in the statement of a chatbot user. 
This kind of "inference engine" in the deeper layers of this diagram is considered the domain of artificial intelligence, where machines can make inferences about their world and use those inferences to make logical decisions. 
However, chatbots can make reasonable decisions without this knowledge database, using only the algorithms of the upper few layers. And these decisions can combine to produce surprisingly human-like behaviors.

Over the next few chapters, we dive down through the top few layers of NLP. 
The top three layers are all that is required to perform meaningful sentiment analysis and semantic search and to build human-mimicking chatbots. 
In fact, it's possible to build a useful and interesting chatbot using only a single layer of processing, using the text (character sequences) directly as the features for a language model. 
A chatbot that only does string matching and search is capable of participating in a reasonably convincing conversation if given enough example statements and responses.

For example, the open source project `ChatterBot` simplifies this pipeline by merely computing the string "edit distance" (Levenshtein distance) between an input statement and the statements recorded in its database. 
If its database of statement-response pairs contains a matching statement, the corresponding reply (from a previously "learned" human or machine dialog) can be reused as the reply to the latest user statement. 
For this pipeline, all that is required is step 3 (Generate) of our chatbot pipeline. 
And within this stage, only a brute-force search algorithm is required to find the best response. With this simple technique (no tokenization or feature generation required), `ChatterBot` can maintain a convincing conversion as the dialog engine for Salvius, a mechanical robot built from salvaged parts by Gunther Cox.footnote:[ChatterBot by Gunther Cox and others at https://github.com/gunthercox/ChatterBot]

`Will` is an open source Python chatbot framework by Steven Skoczen with a completely different approach.footnote:[See the GitHub page for "Will," a chatbot for HipChat, by Steven Skoczen and the HipChat community (https://github.com/skoczen/will). In 2018 it was updated to integrate with Slack]
`Will` can only be trained to respond to statements by programming it with regular expressions.
This is the labor-intensive and data-light approach to NLP.
This grammar-based approach is especially effective for question-answering systems and task-execution assistant bots, like Lex, Siri, and Google Now.
These kinds of systems overcome the "brittleness" of regular expressions by employing "fuzzy regular expressions."footnote:[The Python `regex` package is backward compatible with `re` and adds fuzziness among other features.
The `regex` will replace the `re` package in future Python versions (https://pypi.python.org/pypi/regex).

Similarly `TRE agrep`, or "approximate grep," (https://github.com/laurikari/tre) is an alternative to the UNIX command-line application `grep.`] and other techniques for finding approximate grammar matches.
Fuzzy regular expressions find the closest grammar matches among a list of possible grammar rules (regular expressions) instead of exact matches by ignoring some maximum number of insertion, deletion, and substitution errors.
However, expanding the breadth and complexity of behaviors for pattern-matching chatbots requires a lot of difficult human development work.
Even the most advanced grammar-based chatbots, built and maintained by some of the largest corporations on the planet (Google, Amazon, Apple, Microsoft), remain in the middle of the pack for depth and breadth of chatbot IQ.

A lot of powerful things can be done with shallow NLP.
And little, if any, human supervision (labeling or curating of text) is required.
Often a machine can be left to learn perpetually from its environment (the stream of words it can pull from Twitter or some other source).footnote:[Simple neural networks are often used for unsupervised feature extraction from character and word sequences.]
We show you how to do this in Chapter 6.

== Natural language IQ

Like human brainpower, the power of an NLP pipeline cannot be easily gauged with a single IQ score without considering multiple "smarts" dimensions. 
A common way to measure the capability of a robotic system is along the dimensions of behavior complexity and the degree of human supervision required.
But for a natural language processing pipeline, the goal is to build systems that fully automate the processing of natural language, eliminating all human supervision (once the model is trained and deployed). So a better pair of IQ dimensions should capture the breadth and depth of the complexity of the natural language pipeline.

A consumer product chatbot or virtual assistant like Alexa or Allo is usually designed to have extremely broad knowledge and capabilities.
However, the logic used to respond to requests tends to be shallow, often consisting of a set of trigger phrases that all produce the same response with a single if-then decision branch.
Alexa (and the underlying Lex engine) behave like a single layer, flat tree of (if, elif, elif, ...) statements.footnote:[More complicated logic and behaviors are now possible when you incorporate Lambdas into an AWS Contact Flow dialog tree. See "Creating Call Center Bot with AWS Connect" (https://greenice.net/creating-call-center-bot-aws-connect-amazon-lex-can-speak-understand).]
Google Dialogflow (which was developed independently of Google's Allo and Google Assistant) has similar capabilities to Amazon Lex, Contact Flow, and Lambda, but without the drag-and-drop user interface for designing your dialog tree.

On the other hand, the Google Translate pipeline (or any similar machine translation system) relies on a deep tree of feature extractors, decision trees, and knowledge graphs connecting bits of knowledge about the world. Sometimes these feature extractors, decision trees, and knowledge graphs are explicitly programmed into the system, as in Figure 1.5.
Another approach rapidly overtaking this "hand-coded" pipeline is the deep learning data-driven approach.
Feature extractors for deep neural networks are learned rather than hard-coded, but they often require much more training data to achieve the same performance as intentionally designed algorithms.

You will use both approaches (neural networks and hand-coded algorithms) as you incrementally build an NLP pipeline for a chatbot capable of conversing within a focused knowledge domain.
This will give you the skills you need to accomplish the natural language processing tasks within your industry or business domain.
Along the way you will probably get ideas about how to expand the breadth of things this NLP pipeline can do.
Figure 1.6 puts the chatbot in its place among the natural language processing systems that are already out there.
Imagine the chatbots you have interacted with.
Where do you think they might fit in a plot like this?
Have you attempted to gauge their intelligence by probing them with difficult questions or something like an IQ test?footnote:[A good question suggested by Byron Reese is: "What's larger? The sun or a nickel?" (https://gigaom.com/2017/11/20/voices-in-ai-episode-20-a-conversation-with-marie-des-jardins). Here are a couple more (https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/data/iq_test.csv) to get you started.]
you will get a chance to do exactly that in later chapters, to help you decide how your chatbot stacks up against some of the others in this diagram.

.IQ of natural language processing systems
image::../images/ch01/nlp-iq.png[title="IQ natural language processing systems",alt="Figure 1.6: 2D scatter plot with breadth of intelligence on the horizontal axis and depth of intelligence on the vertical axis, greater IQ is up and to the right. This book is given a dot in the middle of the scatter plot. Siri, Lex, and Will are to the right while legal advice, match-making, and finance are above and to the left. Chatterbot is below and to the left.",link="../images/ch01/nlp-iq.png"]

As you progress through this book, you will be building the elements of a chatbot.
Chatbots require all the tools of NLP to work well:

* Feature extraction (usually to produce a vector space model)
* Information extraction to be able to answer factual questions
* Semantic search to learn from previously recorded natural language text or dialog
* Natural language generation to compose new, meaningful statements

Machine learning gives us a way to trick machines into behaving as if we had spent a lifetime programming them with hundreds of complex regular expressions or algorithms.
We can teach a machine to respond to patterns similar to the patterns defined in regular expressions by merely providing it examples of user statements and the responses we want the chatbot to mimic.
And the "models" of language, the FSMs, produced by machine learning, are much better.
They are less picky about mispelings and typoz.

And machine learning NLP pipelines are easier to "program."
We do not have to anticipate every possible use of symbols in our language.
We just have to feed the training pipeline with examples of the phrases that match and with example phrases that do not match.
As long as we label the example phrases during training so that the chatbot knows which is which, it will learn to discriminate between them.
And there are even machine learning approaches that require little if any "labeled" data.

We have given you some exciting reasons to learn about natural language processing.
You want to help save the world, do you not?
And we have attempted to pique your interest with some practical NLP applications that are revolutionizing the way we communicate, learn, do business, and even think.
It will not be long before you are able to build a system that approaches human-like conversational behavior.
And you should be able to see in upcoming chapters how to train a chatbot or NLP pipeline with any domain knowledge that interests you -- from finance and sports to psychology and literature.
If you can find a corpus of writing about it, then you can train a machine to understand it.

This book is about using machine learning to build smart text-reading machines without you having to anticipate all the ways people can say things.
Each chapter incrementally improves on the basic NLP pipeline for the chatbot introduced in this chapter.
As you learn the tools of natural language processing, you will be building an NLP pipeline that can not only carry on a conversation but help you accomplish your goals in business and in life.

== Test yourself

*Chapter 1 review questions*

Here are some review questions for you to test your understanding:

. Why is NLP considered to be a core enabling feature for AGI (human-like AI)?
. Why do advanced NLP models tend to show significant discriminatory biases?
. How is it possible to create a prosocial chatbot using training data from sources that include antisocial examples?
. What are 4 different approaches or architectures for building a chatbot?
. How is NLP used within a search engine?
. Write a regular expression to recognize your name and all the variations on its spelling (including nicknames) that you've seen.
. Write a regular expression to try to recognize a sentence boundary (usually a period ("."), question mark "?", or exclamation mark "!")


[TIP]
====
Active learning, quizzing yourself with questions such as these, is a fast way to gain deep understanding of any new topic. 
It turns out, this same approach is effective for machine learning and model evaluation as well.footnote:[Suggested answers are provided within the Python packages `nlpia` (https://gitlab.com/tangibleai/nlpia) and `qary` (https://gitlab.com/tangibleai/qary) where they are used to evaluate advanced NLP models for reading comprehension and question answering. Pooja Sethi will share active learning NLP insights on Substack (https://activelearning.substack.com) and github (https://poojasethi.github.io) by the time this book goes to print. ProAI.org, the team of contributing authors for this book is doing the same on substack (https://proai.substack.com) and their home page (https://proai.org).
====

== Summary

* Good NLP may help save the world.
* The meaning and intent of words can be deciphered by machines.
* A smart NLP pipeline will be able to deal with ambiguity.
* We can teach machines common sense knowledge without spending a lifetime training them.
* Chatbots can be thought of as semantic search engines.
* Regular expressions are useful for more than just search.
