
:toc: left
:toclevels: 6

++++
  <style>
  .first-sentence {
    text-align: left;
    margin-left: 0%;
    margin-right: auto;
    width: 66%;
    background: Beige;
  }
  .last-sentence {
    text-align: right;
    margin-left: auto;
    margin-right: 0%;
    width: 66%;
    background: AliceBlue;
  }
  </style>
++++
= Natural Language Processing in Action, Second Edition
= Machines that read and write (NLP overview)
[.first-sentence]
This chapter covers

[.last-sentence]
This chapter covers

[.first-sentence]
Words are powerful.

[.last-sentence]
You are about to see how the majority of the words and ideas that enter your mind are filtered and generated by NLP.

[.first-sentence]
Imagine what you would do with a machine that could understand and act on every word it reads on the Internet?

[.last-sentence]
NLP promises to create the second information revolution by turning vast amounts of unstructured data into actionable knowledge and understanding.

[.first-sentence]
Early on, Big Tech discovered this power of NLP to harvest knowledge from natural language text.

[.last-sentence]
Some advanced liberal democracies are attempting to free your mind by steering business towards sustainable and ethical uses for NLP.

[.first-sentence]
On the other end of the spectrum, authoritarian governments are using NLP to coopt our prosocial instincts to make us easier to track and control.

[.last-sentence]
And surprisingly, even US corporations, politicians, and government agencies are using NLP to influence the public discourse about COVID-19, endangering countless lives.footnote:[Lex Fridman interview of Bret Weinstein titled "Truth, Science, and Censorship in the Time of a Pandemic" (https://lexfridman.com/bret-weinstein/)]

[.first-sentence]
In this chapter, you will begin to build your NLP understanding and skill so you can take control of the information and ideas that affect what you believe and think.

[.last-sentence]
And it will give you and your business the ability to escape Big Tech's stranglehold on information, so you can succeed.

== Programming language vs. natural language
[.first-sentence]
Programming languages are very similar to natural languages like English.

[.last-sentence]
And these grammars employ vocabularies that define the tokens with shared meaning for the agents that process these languages -- humans or machines.

[.first-sentence]
Despite these similarities, programming languages are quite different from natural languages.

[.last-sentence]
Modern CPUs (Central Processing Units) implement the _Von Neumann architecture_ as a register machine, a version of the _universal Turing machine_ idea of 1936.footnote:["The secrets of computer power revealed" by Daniel Dennett (https://sites.tufts.edu/rodrego/)]

[.first-sentence]
Natural languages, however, evolved naturally, _organically_.

[.last-sentence]
And Alex's words inspired Ted Chiang's masterful short story "The Great Silence" -- that's profound cross-species communication.

[.first-sentence]
Given how differently natural languages and programming languages evolved, it is no surprise they're used for different things.

[.last-sentence]
With NLP you can program machines to process natural language text to derive conclusions, infer new facts, create meaningful abstractions, and even respond meaningfully in a conversation.

[.first-sentence]
Even though there are no compilers for natural language there are _parsers_ and _parser generators_, such as PEGN footnote:[Parsing Expression Grammar Notation home page (https://pegn.dev/)] and SpaCy's Matcher class.

[.last-sentence]
They may even understand and generate more meaningful and truthful text than ChatGPT or the next hype-optimizing closed-source model from BigTech.

.Natural language processing

[.first-sentence]
Natural language processing is an evolving practice in computer science and artificial intelligence (AI) concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data (numbers) that a computer can use to learn about the world. This understanding of the world is sometimes used to generate natural language text that reflects that understanding.

[.last-sentence]
Natural language processing is an evolving practice in computer science and artificial intelligence (AI) concerned with processing natural languages such as English or Mandarin. This processing generally involves translating natural language into data (numbers) that a computer can use to learn about the world. This understanding of the world is sometimes used to generate natural language text that reflects that understanding.

[.first-sentence]
This chapter shows you how your software can _process_ natural language to produce useful output.

[.last-sentence]
When the computer program you develop processes natural language, it will be able to act on those statements or even reply to them.

[.first-sentence]
Unlike a programming language where each keyword has an unambiguous interpretation, natural languages are much more fuzzy.

[.last-sentence]
Later you will explore advanced techniques in which the machine can learn from examples, without you knowing anything about the content of those examples.

.Pipeline

[.first-sentence]
A natural language processing system is often referred to as a "pipeline" because it usually involves several stages of processing where natural language flows in one end and the processed output flows out of the other end.

[.last-sentence]
A natural language processing system is often referred to as a "pipeline" because it usually involves several stages of processing where natural language flows in one end and the processed output flows out of the other end.

[.first-sentence]
You will soon have the power to write software that does interesting, human-like things with text.

[.last-sentence]
But you will pull back the curtain and explore the technology behind these magic shows. You will soon discover all the props and tools you need to do the magic tricks yourself.

=== Natural Language Understanding (NLU)
[.first-sentence]
A really important part of NLP is the automatic processing of text to extract a numerical representation of the _meaning_ of that text.

[.last-sentence]
And the embedding vectors for emails in your inbox are used by your email service to classify those emails as Important or not.

.Natural Language Understanding (NLU)

[.first-sentence]
Machines can accomplish many common NLU tasks with high accuracy:

[.last-sentence]
Machines can accomplish many common NLU tasks with high accuracy:

[.first-sentence]
And recent advances in deep learning have made it possible to solve many NLU tasks that were  impossible only ten years ago:

[.last-sentence]
And recent advances in deep learning have made it possible to solve many NLU tasks that were  impossible only ten years ago:

[.first-sentence]
However, there remain many NLU tasks where humans significantly outperform machines.

[.last-sentence]
This makes these problems much more difficult for machines:

[.first-sentence]
You'll learn the current state-of-the-art approaches to NLU and what is possible for these difficult problems.

[.last-sentence]
And your _behind-the-scenes_ understanding of NLU will help you increase the effectiveness of your NLU pipelines for your particular applications, even on these hard problems.

=== Natural Language Generation (NLG)
[.first-sentence]
You may not be aware that machines can also compose text that sounds human-like.

[.last-sentence]
This is the _natural language generation_ (NLG) side of NLP.

.Natural Language Generation (NLG)

[.first-sentence]
You will soon master many common NLG tasks.

[.last-sentence]
You will soon master many common NLG tasks.

[.first-sentence]
And even the more advanced NLG tasks will soon be within your reach.

[.last-sentence]
And even the more advanced NLG tasks will soon be within your reach.

[.first-sentence]
And this will give you the foundation to customize your NLG pipeline for even the most challenging NLG tasks.

[.last-sentence]
And this will give you the foundation to customize your NLG pipeline for even the most challenging NLG tasks.

[.first-sentence]
This last development in NLG is particularly powerful.

[.last-sentence]
Machines can now write correct code to match your intent based only on a natural language description.

[.first-sentence]
The combination of NLU and NLG will give you the tools to create machines that interact with humans in surprising ways.footnote:[You may have heard of Microsoft's and OpenAI's Copilot project. GPT-J can do almost as well, and it's completely open source and open data. (https://huggingface.co/models?sort=likes&search=gpt-j)]

[.last-sentence]
The combination of NLU and NLG will give you the tools to create machines that interact with humans in surprising ways.footnote:[You may have heard of Microsoft's and OpenAI's Copilot project. GPT-J can do almost as well, and it's completely open source and open data. (https://huggingface.co/models?sort=likes&search=gpt-j)]

=== Plumbing it all together for positive impact
[.first-sentence]
Once you understand how NLG and NLU work, you will be able to assemble them into your own NLP pipelines, like a plumber.

[.last-sentence]
Businesses are already using pipelines like these to extract value from their users.

[.first-sentence]
You too can use these pipelines to further _your_ own objectives in life, business, and social impact.

[.last-sentence]
As an entrepreneur, you can help create a regenerative prosocial business that spawn whole new industries and communities that thrive together.

[.first-sentence]
Understanding how NLP works will open your eyes and empower you.

[.last-sentence]
You will harness the power of NLP to protect your own well-being and contribute to the health of society as a whole.

[.first-sentence]
Machines that can understand and generate natural language harness the power of words.

[.last-sentence]
Like the age-old three-wishes problem, you may find yourself trying to undo all the damage caused by your earlier wishes and bots.

== The magic
[.first-sentence]
What is so magical about a machine that can read and write in a natural language?

[.last-sentence]
When software can process languages not designed for machines to understand, it is magic -- something we thought only humans could do.

[.first-sentence]
Moreover, machines can access a massive amount of natural language text, such as Wikipedia, to learn about the world and human thought.

[.last-sentence]
This massive amount of natural language text makes NLP a useful tool.

[.first-sentence]
Machines with the capability to process something natural is not natural.

[.last-sentence]
When software can process languages not designed for machines to understand, it seems magical -- something we thought was a uniquely human capability.

[.first-sentence]
For now, you only need to think about one natural language --  English.

[.last-sentence]
We are going to show you how to write software to process and generate that language using only one programming language, Python.

[.first-sentence]
Python was designed from the ground up to be a readable language.

[.last-sentence]
After all, Python is an unambiguous way to express mathematical algorithms, footnote:[Mathematical notation is ambiguous. See the "Mathematical notation" section of the Wikipedia article "Ambguity" (https://en.wikipedia.org/wiki/Ambiguity#Mathematical_notation).] and it is designed to be as readable as possible by programmers like you.

=== Language and thought
[.first-sentence]
Linguists and philosophers such as Sapir and Whorf postulated that our vocabulary affects the thoughts we think.

[.last-sentence]
Their brains are constantly updating their understanding of their orientation in the world.

[.first-sentence]
Stephen Pinker flips that notion around and sees language as a window into our brains and how we think: "Language is a collective human creation, reflecting human nature, how we conceptualize reality, how we relate to one another."footnote:[Thank you to "Tudor" on MEAP for setting me straight about this. (https://www.ted.com/talks/steven_pinker_what_our_language_habits_reveal/transcript)]

[.last-sentence]
It's no wonder many businesses refer to NLP and chatbots as AI - Artificial Intelligence.

[.first-sentence]
What about math?

[.last-sentence]
It hit him at a deeper level, even deeper than the symbol manipulation rules that he learned in algebra class.

[.first-sentence]
So you use words to communicate thoughts with others and with yourself.

[.last-sentence]
In this book, you're going to learn how to teach a machine to do symbol manipulation on natural language in Chapter 11.

[.first-sentence]
But that's not the most impressive power of NLP.

[.last-sentence]
You chose your words carefully, discarding some words or ideas and focusing on others.

[.first-sentence]
The act of revision and editing is a thinking process.

[.last-sentence]
The act of writing improves how you think, and it will improve how machines think as they get better and better at reading and writing.

[.first-sentence]
So reading and writing is thinking.

[.last-sentence]
I've deleted, rewritten and reordered these paragraphs several times just now, with the help of suggestions and ideas from friends and readers like you.footnote:[Thank you Leo Hepis!]

[.first-sentence]
But words and writing aren't the _only_ way to think logically and deeply.

[.last-sentence]
But the act of composing words into sentences and sentences into paragraphs is something that we do almost constantly.

[.first-sentence]
Reading and writing is also a special kind of thought.

[.last-sentence]
We know that once we think of the word again, the concept will come flooding back and we can use it again.

[.first-sentence]
This is all thinking or what is sometimes called _cognition_.

[.last-sentence]
And conversational AI is one of the most widely recognized and useful forms of AI

=== Machines that converse
[.first-sentence]
Though you spend a lot of time working with words as packets of thought internally within your head, the real fun is when you use those words to interact with others.

[.last-sentence]
This can create a powerful positive feedback loop that reinforces good ideas and weeds out weak ones.

[.first-sentence]
Words are critical to this process.

[.last-sentence]
That is the sole purpose of curse words -- to shock (and awe?) your listener.

[.first-sentence]
There is _another_NLP_ that takes this idea to the extreme.

[.last-sentence]
Because there is money to be made in claiming to help people achieve their life goals, this pseudoscience has taken on a cult status for the practitioners who teach it (preach it?).footnote:[From the Wikipedia article on Neuro-linguistic-programming (https://en.wikipedia.org/wiki/Neuro-linguistic_programming)]

[.first-sentence]
As with astrology, fortune telling, hypnotherapy, conspiracy theories, religions and cults, there is usually a small hint of truth somewhere within it.

[.last-sentence]
And thoughts do affect our behavior.

[.first-sentence]
Though we cannot "program" another human with our words, we can use them to communicate extremely complex ideas.

[.last-sentence]
Unfortunately, when profit motives and unfettered competition is the rule of the day, the hornet nest of social media is the result.

[.first-sentence]
Natural language cannot be directly translated into a precise set of mathematical operations.

[.last-sentence]
This is the function of the "dialog engine" or chatbot that you will build.

[.first-sentence]
This book focuses entirely on English text documents and messages, not spoken statements.

[.last-sentence]
If you want your virtual assistant to live in the cloud, there are Python packages to accomplish SST and TTS on any Linux server with access to your audio stream.

[.first-sentence]
In this book you will focus on what happens between the _ears_ of the machine.

[.last-sentence]
And you'll understand all the helpful NLP that the big boys could be giving you within their voice assistants ... assuming commercial voice assistants wanted to help you with more than just lightening your wallet.

.Speech recognition systems

[.first-sentence]
If you want to build a customized speech recognition or generation system, that undertaking is a whole book in itself; we leave that as an "exercise for the reader."

[.last-sentence]
Some of the algorithms you learn in this book might help, but most of the algorithms are quite different.footnote:[Some open source voice assistants you could contribute to (https://gitlab.com/tangibleai/team/-/tree/main/exercises/1-voice/).]

=== The math
[.first-sentence]
Processing natural language to extract useful information can be difficult.

[.last-sentence]
So you might be able to tweak the algorithms you learn in this book to do some NLP tasks a bit better.

[.first-sentence]
The techniques you will learn, however, are powerful enough to create machines that can surpass humans in both accuracy and speed for some surprisingly subtle tasks.

[.last-sentence]
This book helps you incorporate context (metadata) into your NLP pipeline if you want to try your hand at advancing the state of the art.

[.first-sentence]
Once you extract structured numerical data, or vectors, from natural language, you can take advantage of all the tools of mathematics and machine learning.

[.last-sentence]
Semantic analysis, along with statistics, can help resolve the ambiguity of natural language -- the fact that words or phrases often have multiple meanings or interpretations.

[.first-sentence]
So extracting information is not at all like building a programming language compiler (fortunately for you).

[.last-sentence]
Unanticipated spelling or punctuation would break or befuddle your algorithm.

[.first-sentence]
Natural languages have an additional "decoding" challenge that is even harder to solve.

[.last-sentence]
Rather, it reflects the state of mind of the speaker and her readiness to speak with others.

[.first-sentence]
This theory of mind about the human processor of language turns out to be a powerful assumption.

[.last-sentence]
However, we show you techniques in later chapters to help machines build ontologies, or knowledge bases, of common sense knowledge to help interpret statements that rely on this knowledge.

== Applications
[.first-sentence]
Natural language processing is everywhere.

[.last-sentence]
Some of the examples here may surprise you.

.Graph of NLP applications

[.first-sentence]
At the core of this network diagram are the NLU and NLG *sides* of NLP.

[.last-sentence]
These eventually connect with foundational NLG tools such as spelling correctors and automatic code generators to create conversational AI and even pair programming assistants.

[.first-sentence]
A search engine can provide more meaningful results if it indexes web pages or document archives in a way that takes into account the meaning of natural language text.

[.last-sentence]
Some dialog engines (chatbots) use natural language search to find a response to their conversation partner's message.

[.first-sentence]
NLP pipelines that generate text can be used not only to compose short replies in chatbots and virtual assistants but also to assemble much longer passages of text.

[.last-sentence]
Bots can compose weather forecasts that sound a lot like what your hometown weather person might say, perhaps because human meteorologists use word processors with NLP features to draft scripts.

[.first-sentence]
More and more businesses are using NLP to automate their business processes.

[.last-sentence]
And some teams use NLP to automate and personalize e-mails between teammates or communicate with job applicants.

[.first-sentence]
NLP pipelines, like all algorithms, make mistakes and are almost always biased in many ways.

[.last-sentence]
NLP helped us quickly evaluate English and technical skill before proceeding with interviews and paid take-home assignments.

[.first-sentence]
The spam filters have retained their edge in the cat-and-mouse game between spam filters and spam generators for email but may be losing in other environments like social networks.

[.last-sentence]
And these "puppet masters" tend to be foreign governments or large corporations.

[.first-sentence]
NLP systems can generate more than just short social network posts.

[.last-sentence]
You can use NLP to help search engines and prosocial social media communities (Mastodon) footnote:["A beginners guide to Mastodon" on Tech Crunch (https://techcrunch.com/2022/11/08/what-is-mastodon/) by Amanda Silberling on Mastodon (https://mstdn.social/@amanda@journa.host)] detect and remove misleading or fake posts and reviews.footnote:[2021, E.Madhorubagan et al "Intelligent Interface for Fake Product Review Monitoring and Removal" (https://ijirt.org/master/publishedpaper/IJIRT151055_PAPER.pdf)]

[.first-sentence]
There are chatbots on Slack, IRC, and even customer service websites -- places where chatbots have to deal with ambiguous commands or questions.

[.last-sentence]
NLP systems can answer phones for companies that want something better than a phone tree, but they do not want to pay humans to help their customers.

[.first-sentence]
Consider the ethical implications whenever you, or your boss, decide to deceive your users. With its *Duplex* demonstration at Google IO, engineers and managers overlooked concerns about the ethics of teaching chatbots to deceive humans. In most "entertainment" social networks, bots are not required to reveal themselves. We unknowingly interact with these bots on Facebook, Reddit, Twitter and even dating apps. Now that bots and deep fakes can so convincingly deceive us, the AI control problem footnote:[Wikipedia is probably your most objective reference on the "AI control problem" (https://en.wikipedia.org/wiki/AI_control_problem).]. Yuval Harari's cautionary forecast of "Homo Deus"footnote:[WSJ Blog, March 10, 2017 https://blogs.wsj.com/cio/2017/03/10/homo-deus-author-yuval-noah-harari-says-authority-shifting-from-people-to-ai/] may come sooner than we think.

[.last-sentence]
Consider the ethical implications whenever you, or your boss, decide to deceive your users. With its *Duplex* demonstration at Google IO, engineers and managers overlooked concerns about the ethics of teaching chatbots to deceive humans. In most "entertainment" social networks, bots are not required to reveal themselves. We unknowingly interact with these bots on Facebook, Reddit, Twitter and even dating apps. Now that bots and deep fakes can so convincingly deceive us, the AI control problem footnote:[Wikipedia is probably your most objective reference on the "AI control problem" (https://en.wikipedia.org/wiki/AI_control_problem).]. Yuval Harari's cautionary forecast of "Homo Deus"footnote:[WSJ Blog, March 10, 2017 https://blogs.wsj.com/cio/2017/03/10/homo-deus-author-yuval-noah-harari-says-authority-shifting-from-people-to-ai/] may come sooner than we think.

[.first-sentence]
NLP systems exist that can act as email "receptionists" for businesses or executive assistants for managers.

[.last-sentence]
More on that later.

[.first-sentence]
The most surprising and powerful application of NLP is in psychology.

[.last-sentence]
Fortunately, you don't have to rely on engineers at large corporations to look out for your best interests. Many psychotherapy and cognitive assistant technology is completely free and open source.footnote:[Tangible AI builds open source cognitive assistants that help users take control of their emotions such as Syndee and `qary` (https://gitlab.com/tangibleai/qary) Some of Replika.AI's core technologies are open source (https://github.com/lukalabs)]

=== Processing programming languages with NLP
[.first-sentence]
Modern deep-learning NLP pipelines have proven so powerful and versatile that they can now accurately understand and generate programming languages.

[.last-sentence]
And users can often use information retrieval systems, or search engines, to find snippets of code to complete their software development project.

[.first-sentence]
And these tools just got a whole lot smarter.

[.last-sentence]
You can see how this might start to influence what you type and how you think.

[.first-sentence]
And transformers have advanced NLP even further recently with massive deep learning networks that are more *abstractive*, generating new text you haven't seen or typed before.

[.last-sentence]
Here is the example for the typescript prompt shown on the copilot home page: footnote:[Taken from animation on copilot.github.com that was unchanged from 2022 to March 2023 (https://copilot.github.com/)]

[.first-sentence]
In the demo animation, Copilot then generated the rest of the typescript required for a working function that estimated the sentiment of a body of text.

[.last-sentence]
Just as Google Search influenced the kind of code you wrote indirectly, now Microsoft algorithms are directly writing code for you.

[.first-sentence]
Since you're reading this book, you are probably planning to build some pretty cool NLP pipelines. You may even build a pipeline that helps you write blog posts and chatbots and core NLP algorithms.

[.last-sentence]
These have huge leverage on the direction of your code, and the direction of your life.

== Language through a computer&#8217;s "eyes"
[.first-sentence]
When you type "Good Morning Rosa", a computer sees only "01000111 01101111 01101111 ...". How can you program a chatbot to respond to this binary stream intelligently?

[.last-sentence]
That's the kind of FSM we use in the next section to show you one possible approach to NLP: the pattern-based approach.

[.first-sentence]
What if you decided to search a memory bank (database) for the exact same string of bits, characters, or words, and use one of the responses that other humans and authors have used for that statement in the past?

[.last-sentence]
The bits for "good" will be just as similar to "bad!" as they are to "okay".

[.first-sentence]
But let's see how this approach would work before we show you a better way. Let's build a small regular expression to recognize greetings like "Good morning Rosa" and respond appropriately -- our first tiny chatbot!

[.last-sentence]
But let's see how this approach would work before we show you a better way. Let's build a small regular expression to recognize greetings like "Good morning Rosa" and respond appropriately -- our first tiny chatbot!

=== The language of locks
[.first-sentence]
Surprisingly the humble combination lock is actually a simple language processing machine.

[.last-sentence]
But if you do not need mechanical analogies to help you understand algorithms and how regular expressions work, then you can skip this section.

[.first-sentence]
After finishing this section, you will never think of your combination bicycle lock the same way again.

[.last-sentence]
Even more importantly, the padlock can tell if a lock "statement" matches a particularly meaningful statement, the one for which there is only one correct "response," to release the catch holding the U-shaped hasp so you can get into your locker.

[.first-sentence]
This lock language (regular expressions) is a particularly simple one.

[.last-sentence]
We can use it to recognize a key phrase or command to unlock a particular action or behavior.

[.first-sentence]
For example, we'd like our chatbot to recognize greetings such as "Hello Rosa," and respond to them appropriately.

[.last-sentence]
If you've ever written a math equation or coded a programming language expression, you've written a formal language statement.

[.first-sentence]
Formal languages are a subset of natural languages.

[.last-sentence]
That's the reason for this diversion into the mechanical, "click, whirr"footnote:[One of Cialdini's six psychology principles in his popular book _Influence_ http://changingminds.org/techniques/general/cialdini/click-whirr.htm] language of locks.

=== Regular expressions
[.first-sentence]
Regular expressions use a special class of formal language grammars called a regular grammar.

[.last-sentence]
There are successful chatbot frameworks in Python, like `Will`, footnote:[Steven Skoczen's Will chatbot framework (https://github.com/skoczen/will)] and `qary` footnote:[Tangible AI's chatbot framework called `qary` (https://docs.qary.ai) with examples deployed for WeSpeakNYC (https://wespeaknyc.cityofnewyork.us/) and others] that rely exclusively on this kind of language processing to produce some effective chatbots.

[.first-sentence]
Regular expressions implemented in Python and in Posix (Unix) applications such as `grep` are not true regular grammars.

[.last-sentence]
As a result, regular expressions aren't provably halting; they can sometimes "crash" or run forever. footnote:[Stack Exchange Went Down for 30 minutes on July 20, 2016 when a regex "crashed" (http://stackstatus.net/post/147710624694/outage-postmortem-july-20-2016)]

[.first-sentence]
You may be saying to yourself, "I've heard of regular expressions. I use `grep`. But that's only for search!"

[.last-sentence]
A chatbot can add that bit of information to its knowledge base about the user or about the world the user is describing.

[.first-sentence]
A machine that processes this kind of language can be thought of as a formal mathematical object called a finite state machine or deterministic finite automaton (DFA).

[.last-sentence]
And the side note that follows explains a bit more formal detail about formal languages.

.Kinds of automata

.Formal mathematical explanation of formal languages

[.first-sentence]
Kyle Gorman describes programming languages this way:

[.last-sentence]
Kyle Gorman describes programming languages this way:

[.first-sentence]
Natural languages are:

[.last-sentence]
Natural languages are:

== A simple chatbot
[.first-sentence]
Let us build a quick and dirty chatbot.

[.last-sentence]
And we show you how to do that in later chapters.

[.first-sentence]
This pattern-matching chatbot is an example of a tightly controlled chatbot.

[.last-sentence]
And a variation of the pattern-matching approach we show you here is used in chatbots like Amazon Alexa and other virtual assistants.

[.first-sentence]
For now let's build an FSM, a regular expression, that can speak lock language (regular language).

[.last-sentence]
Even better, we'd like it to understand greetings, things like "open sesame" or "hello Rosa."

[.first-sentence]
An important feature of a prosocial chatbot is to be able to respond to a greeting.

[.last-sentence]
We surely do not want that for our benevolent chatbot.

[.first-sentence]
For communication between two machines, you would define a handshake with something like an `ACK` (acknowledgement) signal to confirm receipt of each message.

[.last-sentence]
We do not want it sending out a bunch of chirps, beeps, or `ACK` messages, like it's syncing up a modem or HTTP connection at the start of a conversation or web browsing session.

[.first-sentence]
Human greetings and handshakes are a little more informal and flexible.

[.last-sentence]
You will want a few different approaches in your toolbox.

[.first-sentence]
An intent is a category of possible intentions the user has for the NLP system or chatbot.

[.last-sentence]
You'll learn about intent recognition throughout the book and put it to use in a chatbot in chapter 12.

== Keyword-based greeting recognizer
[.first-sentence]
Your first chatbot will be straight out of the 80's.

[.last-sentence]
But this approach can be extended to help you implement simple keyword-based intent recognizers on projects similar to those mentioned earlier in this chapter.

.Keyword detection using <code>str.split</code>

[.first-sentence]
This simple NLP pipeline (program) has only two intent categories: "greeting" and "unknown" (`else`).

[.last-sentence]
Chatbots that recognize the user's intent like this have capabilities similar to modern command line applications or phone trees from the 90's.

[.first-sentence]
Rule-based chatbots can be much more fun and flexible than this simple program.

[.last-sentence]
Or you can go beyond keyword-based NLP and start thinking about ways to improve it using regular expressions.

=== Pattern-based intent recognition
[.first-sentence]
A keyword-based chatbot would recognize "Hi", "Hello", and "Greetings", but it wouldn't recognize "Hiiii" or "Hiiiiiiiiiiii" - the more excited renditions of "Hi".

[.last-sentence]
Regular expression _patterns_ can match text much more robustly than any hard-coded rules or lists of keywords.

[.first-sentence]
Regular expressions recognize patterns for any sequence of characters or symbols.footnote:[SpaCy 'Matcher' (https://spacy.io/api/matcher) is a regular expression interpreter for patterns of words, parts of speech, and other symbol sequences.]

[.last-sentence]
But that is a lot of manual "hard-coding" of data into your NLP pipeline.

[.first-sentence]
You will soon learn how to use machine learning for more data-driven and automated NLP pipelines.

[.last-sentence]
When your user wants to specify actions with precise patterns of characters similar to programming language commands, that's where regular expressions shine.

[.first-sentence]
In regular expressions, you can specify a character class with square brackets.

[.last-sentence]
The star ("\*") after a character class means that the regular expression will match any number of consecutive characters if they are all within that character class.

[.first-sentence]
Let's make our regular expression a lot more detailed to try to match more greetings.

[.last-sentence]
Let's make our regular expression a lot more detailed to try to match more greetings.

[.first-sentence]
The "r" before the quote symbol (`r'`) indicates that the quoted string literal is a _raw_ string.

[.last-sentence]
So the whitespace matching symbol `'\s'` would become `'\\s'`, and special characters like literal curly braces would become `'\\{'` and `'\\}'`.

[.first-sentence]
There is a lot of logic packed into that first line of code, the regular expression.

[.last-sentence]
We'd have to do a lot more work to refine the phrases it matches for the bot to behave in a more intelligent human-like way.

[.first-sentence]
And this tedious work would be highly unlikely to ever succeed at capturing all the slang and misspellings people use.

[.last-sentence]
So we only use them when we need precise control over a chatbot's behavior, such as when issuing commands to a voice assistant on your mobile phone.

[.first-sentence]
But let's go ahead and finish up our one-trick chatbot by adding an output generator.

[.last-sentence]
We use Python's string formatter to create a "template" for our chatbot response.

[.first-sentence]
So if you run this little script and chat to our bot with a phrase like "Hello Rosa", it will respond by asking about your day.

[.last-sentence]
Obviously, there is no one else out there watching our `input()` line, but if this were a function within a larger chatbot, you want to deal with these sorts of things.

[.first-sentence]
Because of the limitations of computational resources, early NLP researchers had to use their human brain's computational power to design and hand-tune complex logical rules to extract information from a natural language string.

[.last-sentence]
The art of pattern-matching approaches to NLP is coming up with elegant patterns that capture just what you want, without too many lines of regular expression code.

.Theory of a computational mind

[.first-sentence]
This classical NLP pattern-matching approach is based on the computational theory of mind (CTM).

[.last-sentence]
This newer theory inspired the artificial neural networks of deep learning used that process natural language sequences in many different ways simultaneously, in parallel.footnote:[Stanford Encyclopedia of Philosophy, Connectionism, https://plato.stanford.edu/entries/connectionism/] footnote:[Christiansen and Chater, 1999, Southern Illinois University (https://crl.ucsd.edu/~elman/Bulgaria/christiansen-chater-soa.pdf)]

[.first-sentence]
In Chapter 2 you will learn more about pattern-based approaches to tokenizing -- splitting text into tokens or words with algorithms such as the "Treebank tokenizer."

[.last-sentence]
But in later chapters we take advantage of the exponentially greater computational resources, as well as our larger datasets, to shortcut this laborious hand programming and refining.

[.first-sentence]
If you are new to regular expressions and want to learn more, you can check out Appendix B or the online documentation for Python regular expressions.

[.last-sentence]
And it turns out machines can learn this way as well...

=== Another way
[.first-sentence]
Imagine a giant database containing sessions of dialog between humans.

[.last-sentence]
And that could take the place of all that tedious pattern-matching algorithm design.

[.first-sentence]
Think about how a single typo or variation in the statement would trip up a pattern-matching bot or even a data-driven bot with millions of statements (utterances) in its database.

[.last-sentence]
In later chapters, you'll get better and better at extracting meaning from text!

[.first-sentence]
When we use character sequence matches to measure distance between natural language phrases, we'll often get it wrong.

[.last-sentence]
And they fail to account for how small spelling differences might not really be typos but rather completely different words, such as "bad" and "bag".

[.first-sentence]
Distance metrics designed for numerical sequences and vectors are useful for a few NLP applications, like spelling correctors and recognizing proper nouns.

[.last-sentence]
We show you each approach, one by one, as we talk about these different applications and the kinds of vectors they are used with.

[.first-sentence]
We do not stay in this confusing binary world of logic for long, but let's imagine we're famous World War II-era code-breaker Mavis Batey at Bletchley Park and we have just been handed that binary, Morse code message intercepted from communication between two German military officers.

[.last-sentence]
This collection of documents is called a _corpus_, and the words or sequences we have listed in our index are called a _lexicon_.

[.first-sentence]
If we're lucky, and we're not at war, and the messages we're looking at aren't strongly encrypted, we'll see patterns in those German word counts that mirror counts of English words used to communicate similar kinds of messages.

[.last-sentence]
It's just math, computation.

[.first-sentence]
But let's think for a moment about what information has been lost in our effort to count all the words in the messages we receive.

[.last-sentence]
 But if it was a short sentence or tweet, you'd probably be able to rearrange them into their intended order and meaning most of the time.

.Canadian coin sorter

[.first-sentence]
Here's how our token sorter fits into an NLP pipeline right after a tokenizer (see Chapter 2).

[.last-sentence]
Strings flow in from the top, and bag-of-word vectors are created from the height profile of the token "stacks" at the bottom.

.Token sorting tray

[.first-sentence]
It turns out that machines can handle this bag of words quite well and glean most of the information content of even moderately long documents this way.

[.last-sentence]
You see a crude example in Figure 1.3, and then Chapter 2 shows some more useful data structures for bag-of-word vectors.

[.first-sentence]
This is our first vector space model of a language.

[.last-sentence]
And a Python `Counter` is a special kind of dictionary that bins objects (including strings) and counts them just like we want.

[.first-sentence]
You can probably imagine some ways to clean those tokens up.

[.last-sentence]
They are, however, good enough for some industry-changing tools like spam filters, which we discuss in Chapter 3.

[.first-sentence]
And we can imagine feeding into this machine, one at a time, all the documents, statements, sentences, and even single words we could find.

[.last-sentence]
The ability to efficiently answer these two questions would be sufficient to build a machine learning chatbot that could get better and better as we gave it more and more data.

[.first-sentence]
But wait a minute, perhaps these vectors aren't like any you've ever worked with before.

[.last-sentence]
In Chapter 3, we discuss the curse of dimensionality and some other properties that make high-dimensional vectors difficult to work with.

== A brief overflight of hyperspace
[.first-sentence]
In Chapter 3, we show you how to consolidate words into a smaller number of vector dimensions to help mitigate the curse of dimensionality and maybe turn it to our advantage.

[.last-sentence]
We can then teach a computer to recognize and act on these patterns in ways that reflect the underlying meaning of the words that produced those vectors.

[.first-sentence]
Imagine all the possible tweets or messages or sentences that humans might write.

[.last-sentence]
We could rate messages and words for qualities like subject matter and sentiment. We could ask questions like:

[.first-sentence]
Think of all the ratings we could give statements.

[.last-sentence]
The list of ratings or dimensions we could give a set of statements should be much smaller than the number of possible statements, and statements that mean the same thing should have similar values for all our questions.

[.first-sentence]
These rating vectors become something that a machine can be programmed to react to.

[.last-sentence]
We can simplify and generalize vectors further by clumping (clustering) statements together, making them close on some dimensions and not on others.

[.first-sentence]
But how can a computer assign values to each of these vector dimensions?

[.last-sentence]
More than just raw hardware power and capacity made NLP practical; incremental, constant-RAM, linear algebra algorithms were the final piece of the puzzle that allowed machines to crack the code of natural language.

[.first-sentence]
There is an even simpler, but much larger representation that can be used in a chatbot.

[.last-sentence]
The vector for each character would contain the answer to binary (yes/no) questions about every letter and punctuation mark in your alphabet:

[.first-sentence]
"Is the first letter an 'A'?"

[.last-sentence]
"Is the first letter a 'z'?"

[.first-sentence]
And the next vector would answer the same boring questions about the next letter in the sequence.

[.last-sentence]
And the next vector would answer the same boring questions about the next letter in the sequence.

[.first-sentence]
"Is the second letter an A?"

[.last-sentence]
...

[.first-sentence]
Despite all the "no" answers or zeroes in this vector sequence, it does have one advantage over all other possible representations of text - it retains every tiny detail, every bit of information contained in the original text, including the order of the characters and words.

[.last-sentence]
The paper roll wouldn't have to be much wider than for a real player piano and the number of notes in some long piano songs doesn't exceed the number of characters in a small document.

[.first-sentence]
But this one-hot character sequence encoding representation is mainly useful for recording and then replaying an exact piece rather than composing something new or extracting the essence of a piece.

[.last-sentence]
We retained the order of characters and words but expanded the dimensionality of our NLP problem.

[.first-sentence]
These representations of documents do not cluster together well in this character-based vector world.

[.last-sentence]
 We peek behind the magician's curtain in Chapter 4, when we talk about latent semantic indexing and latent Dirichlet allocation, two techniques for creating much more dense and meaningful vector representations of statements and documents.

== Word order and grammar
[.first-sentence]
The order of words matters.

[.last-sentence]
Take a look at all these orderings of our "Good morning Rosa" example.

[.first-sentence]
Now if you tried to interpret each of those strings in isolation (without looking at the others), you'd probably conclude that they all probably had similar intent or meaning.

[.last-sentence]
Nonetheless, a smart chatbot or clever woman of the 1940s in Bletchley Park would likely respond to any of these six permutations with the same innocuous greeting, "Good morning my dear General."

[.first-sentence]
Let's try that (in our heads) on a much longer, more complex phrase, a logical statement where the order of the words matters a lot:

[.last-sentence]
Let's try that (in our heads) on a much longer, more complex phrase, a logical statement where the order of the words matters a lot:

[.first-sentence]
The number of permutations exploded from `factorial(3) == 6` in our simple greeting to `factorial(12) ==  479001600` in our longer statement!

[.last-sentence]
A bag of words is not the best way to begin processing a database query, like the natural language query in the preceding example.

[.first-sentence]
Whether a statement is written in a formal programming language like SQL, or in an informal natural language like English, word order and grammar are important when a statement intends to convey logical relationships between things.

[.last-sentence]
In later chapters, we show you how to use packages like `SyntaxNet` (Parsey McParseface) and `SpaCy` to identify these relationships.

[.first-sentence]
And just as in the Bletchley Park example greeting, even if a statement doesn't rely on word order for logical interpretation, sometimes paying attention to that word order can reveal subtle hints of meaning that might facilitate deeper responses.

[.last-sentence]
It also shows you how to refine the crude tokenizer used in the previous examples  (`str.split()`) to more accurately bin words into more appropriate slots within the word vector, so that strings like "good" and "Good" are assigned the same bin, and separate bins can be allocated for tokens like "rosa" and "Rosa" but not "Rosa!".

== A chatbot natural language pipeline
[.first-sentence]
The NLP pipeline required to build a dialog engine, or chatbot, is similar to the pipeline required to build a question answering system described in _Taming Text_ (Manning, 2013).footnote:[Ingersol, Morton, and Farris, http://www.manning.com/books/taming-text/?a_aid=totalgood] However, some of the algorithms listed within the five subsystem blocks may be new to you. We help you implement these in Python to accomplish various NLP tasks essential for most applications, including chatbots.

[.last-sentence]
The NLP pipeline required to build a dialog engine, or chatbot, is similar to the pipeline required to build a question answering system described in _Taming Text_ (Manning, 2013).footnote:[Ingersol, Morton, and Farris, http://www.manning.com/books/taming-text/?a_aid=totalgood] However, some of the algorithms listed within the five subsystem blocks may be new to you. We help you implement these in Python to accomplish various NLP tasks essential for most applications, including chatbots.

.Chatbot recirculating (recurrent) pipeline

[.first-sentence]
A chatbot requires four kinds of processing as well as a database to maintain a memory of past statements and responses.

[.last-sentence]
Each of the four processing stages can contain one or more processing algorithms working in parallel or in series (see figure 1.4).

[.first-sentence]
Each of these four stages can be implemented using one or more of the algorithms listed within the corresponding boxes in the block diagram.

[.last-sentence]
We show you how to use Python to accomplish near-state-of-the-art performance for each of these processing steps. And we show you several alternative approaches to implementing these five subsystems.

[.first-sentence]
Most chatbots will contain elements of all five of these subsystems (the four processing stages as well as the database).

[.last-sentence]
Each of these capabilities requires different approaches; we show you techniques for both.

[.first-sentence]
In addition, deep learning and data-driven programming (machine learning, or probabilistic language modeling) have rapidly diversified the possible applications for NLP and chatbots.

[.last-sentence]
And when a new machine learning approach is discovered that makes even better use of this data, with more efficient model generalization or regularization, then large jumps in capability are possible.

[.first-sentence]
The NLP pipeline for a chatbot shown in Figure 1.4 contains all the building blocks for most of the NLP applications that we described at the start of this chapter.

[.last-sentence]
And our chatbot pipeline is certainly appropriate for the question-answering application that was the focus of _Taming Text_.

[.first-sentence]
The application of this pipeline to financial forecasting or business analytics may not be so obvious.

[.last-sentence]
Despite focusing on building a chatbot, this book gives you the tools you need for a broad range of NLP applications, from search to financial forecasting.

[.first-sentence]
One processing element in Figure 1.4 that is not typically employed in search, forecasting, or question-answering systems is natural language _generation_.

[.last-sentence]
And you can imagine how valuable it is for a financial forecasting engine to be able to generate statements, tweets, or entire articles based on the business-actionable events it detects in natural language streams from social media networks and news feeds.

[.first-sentence]
The next section shows how the layers of such a system can be combined to create greater sophistication and capability at each stage of the NLP pipeline.

[.last-sentence]
The next section shows how the layers of such a system can be combined to create greater sophistication and capability at each stage of the NLP pipeline.

== Processing in depth
[.first-sentence]
The stages of a natural language processing pipeline can be thought of as layers, like the layers in a feed-forward neural network.

[.last-sentence]
But here we talk about the top layers and what can be done by training each layer independently of the other layers.

.Example layers for an NLP pipeline

[.first-sentence]
The top four layers in Figure 1.8 correspond to the first two stages in the chatbot pipeline (feature extraction and feature analysis) in the previous section.

[.last-sentence]
POS tagging is typically accomplished with a finite state transducer like the methods in the `nltk.tag` package.

[.first-sentence]
The bottom two layers (Entity Relationships and a Knowledge Base) are used to populate a database containing information (knowledge) about a particular domain.

[.last-sentence]
However, chatbots can make reasonable decisions without this knowledge database, using only the algorithms of the upper few layers. And these decisions can combine to produce surprisingly human-like behaviors.

[.first-sentence]
Over the next few chapters, we dive down through the top few layers of NLP.

[.last-sentence]
A chatbot that only does string matching and search is capable of participating in a reasonably convincing conversation if given enough example statements and responses.

[.first-sentence]
For example, the open source project `ChatterBot` simplifies this pipeline by merely computing the string "edit distance" (Levenshtein distance) between an input statement and the statements recorded in its database.

[.last-sentence]
And within this stage, only a brute-force search algorithm is required to find the best response. With this simple technique (no tokenization or feature generation required), `ChatterBot` can maintain a convincing conversion as the dialog engine for Salvius, a mechanical robot built from salvaged parts by Gunther Cox.footnote:[ChatterBot by Gunther Cox and others at https://github.com/gunthercox/ChatterBot]

[.first-sentence]
`Will` is an open source Python chatbot framework by Steven Skoczen with a completely different approach.footnote:[See the GitHub page for "Will," a chatbot for HipChat, by Steven Skoczen and the HipChat community (https://github.com/skoczen/will). In 2018 it was updated to integrate with Slack]

[.last-sentence]
The `regex` will replace the `re` package in future Python versions (https://pypi.python.org/pypi/regex).

[.first-sentence]
Similarly `TRE agrep`, or "approximate grep," (https://github.com/laurikari/tre) is an alternative to the UNIX command-line application `grep.`] and other techniques for finding approximate grammar matches.

[.last-sentence]
Even the most advanced grammar-based chatbots, built and maintained by some of the largest corporations on the planet (Google, Amazon, Apple, Microsoft), remain in the middle of the pack for depth and breadth of chatbot IQ.

[.first-sentence]
A lot of powerful things can be done with shallow NLP.

[.last-sentence]
We show you how to do this in Chapter 6.

== Natural language IQ
[.first-sentence]
Like human brainpower, the power of an NLP pipeline cannot be easily gauged with a single IQ score without considering multiple "smarts" dimensions.

[.last-sentence]
But for a natural language processing pipeline, the goal is to build systems that fully automate the processing of natural language, eliminating all human supervision (once the model is trained and deployed). So a better pair of IQ dimensions should capture the breadth and depth of the complexity of the natural language pipeline.

[.first-sentence]
A consumer product chatbot or virtual assistant like Alexa or Allo is usually designed to have extremely broad knowledge and capabilities.

[.last-sentence]
Google Dialogflow (which was developed independently of Google's Allo and Google Assistant) has similar capabilities to Amazon Lex, Contact Flow, and Lambda, but without the drag-and-drop user interface for designing your dialog tree.

[.first-sentence]
On the other hand, the Google Translate pipeline (or any similar machine translation system) relies on a deep tree of feature extractors, decision trees, and knowledge graphs connecting bits of knowledge about the world. Sometimes these feature extractors, decision trees, and knowledge graphs are explicitly programmed into the system, as in Figure 1.5.

[.last-sentence]
Feature extractors for deep neural networks are learned rather than hard-coded, but they often require much more training data to achieve the same performance as intentionally designed algorithms.

[.first-sentence]
You will use both approaches (neural networks and hand-coded algorithms) as you incrementally build an NLP pipeline for a chatbot capable of conversing within a focused knowledge domain.

[.last-sentence]
you will get a chance to do exactly that in later chapters, to help you decide how your chatbot stacks up against some of the others in this diagram.

.2D IQ of some natural language processing systems

[.first-sentence]
As you progress through this book, you will be building the elements of a chatbot.

[.last-sentence]
Chatbots require all the tools of NLP to work well:

[.first-sentence]
Machine learning gives us a way to trick machines into behaving as if we had spent a lifetime programming them with hundreds of complex regular expressions or algorithms.

[.last-sentence]
They are less picky about mispelings and typoz.

[.first-sentence]
And machine learning NLP pipelines are easier to "program."

[.last-sentence]
And there are even machine learning approaches that require little if any "labeled" data.

[.first-sentence]
We have given you some exciting reasons to learn about natural language processing.

[.last-sentence]
If you can find a corpus of writing about it, then you can train a machine to understand it.

[.first-sentence]
This book is about using machine learning to build smart text-reading machines without you having to anticipate all the ways people can say things.

[.last-sentence]
As you learn the tools of natural language processing, you will be building an NLP pipeline that can not only carry on a conversation but help you accomplish your goals in business and in life.

== Test yourself
[.first-sentence]
*Chapter 1 review questions*

[.last-sentence]
*Chapter 1 review questions*

[.first-sentence]
Here are some review questions for you to test your understanding:

[.last-sentence]
Here are some review questions for you to test your understanding:

[.first-sentence]
Active learning, quizzing yourself with questions such as these, is a fast way to gain deep understanding of any new topic.

[.last-sentence]
It turns out, this same approach is effective for machine learning and model evaluation as well.footnote:[Suggested answers are provided within the Python packages `nlpia` (https://gitlab.com/tangibleai/nlpia) and `qary` (https://gitlab.com/tangibleai/qary) where they are used to evaluate advanced NLP models for reading comprehension and question answering. Pooja Sethi will share active learning NLP insights on Substack (https://activelearning.substack.com) and github (https://poojasethi.github.io) by the time this book goes to print. ProAI.org, the team of contributing authors for this book is doing the same on substack (https://proai.substack.com) and their home page (https://proai.org).

== Summary
