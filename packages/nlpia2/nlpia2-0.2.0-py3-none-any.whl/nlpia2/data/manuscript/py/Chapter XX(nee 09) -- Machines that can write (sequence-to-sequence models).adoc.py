from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequencefrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequenceclass Encoder(nn.Module):class Encoder(nn.Module):   def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):   def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):       super(Encoder, self).__init__()       super(Encoder, self).__init__()       self.batch_sz = batch_sz       self.batch_sz = batch_sz       self.enc_units = enc_units       self.enc_units = enc_units       self.vocab_size = vocab_size       self.vocab_size = vocab_size       self.embedding_dim = embedding_dim       self.embedding_dim = embedding_dim       self.embedding = nn.Embedding(                self.vocab_size, self.embedding_dim)       self.embedding = nn.Embedding(                self.vocab_size, self.embedding_dim)       self.embedding = nn.Embedding(                self.vocab_size, self.embedding_dim)       self.gru = nn.GRU(                self.embedding_dim, self.enc_units) # <1>       self.gru = nn.GRU(                self.embedding_dim, self.enc_units) # <1>       self.gru = nn.GRU(                self.embedding_dim, self.enc_units) # <1>   def forward(self, x, lens, device=device):   def forward(self, x, lens, device=device):       x = self.embedding(x)       x = self.embedding(x)       x = pack_padded_sequence(x, lens) # <2>       x = pack_padded_sequence(x, lens) # <2>       self.hidden = self.initialize_hidden_state(device)       self.hidden = self.initialize_hidden_state(device)       output, self.hidden = self.gru(x, self.hidden) # <3>       output, self.hidden = self.gru(x, self.hidden) # <3>       output, _ = pad_packed_sequence(output) # <4>       output, _ = pad_packed_sequence(output) # <4>       return output, self.hidden       return output, self.hidden   def initialize_hidden_state(self, device=device):   def initialize_hidden_state(self, device=device):       return torch.zeros(               (1, self.batch_sz, self.enc_units)               ).to(device) # <5>       return torch.zeros(               (1, self.batch_sz, self.enc_units)               ).to(device) # <5>       return torch.zeros(               (1, self.batch_sz, self.enc_units)               ).to(device) # <5>       return torch.zeros(               (1, self.batch_sz, self.enc_units)               ).to(device) # <5>class Decoder(nn.Module):class Decoder(nn.Module):    def __init__(self, config,vocab_size):    def __init__(self, config,vocab_size):        super(Decoder, self).__init__()        super(Decoder, self).__init__()        self.dec_units = config.get("decoder_hidden", 64)        self.dec_units = config.get("decoder_hidden", 64)        self.enc_units = config.get("encoder_hidden", 64)        self.enc_units = config.get("encoder_hidden", 64)        self.vocab_size = vocab_size        self.vocab_size = vocab_size        self.embedding_dim = config.get("embedding_dim", 256)        self.embedding_dim = config.get("embedding_dim", 256)        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)        self.gru = nn.GRU(self.embedding_dim,                          self.dec_units,                          batch_first=True)  # <1>        self.gru = nn.GRU(self.embedding_dim,                          self.dec_units,                          batch_first=True)  # <1>        self.gru = nn.GRU(self.embedding_dim,                          self.dec_units,                          batch_first=True)  # <1>        self.gru = nn.GRU(self.embedding_dim,                          self.dec_units,                          batch_first=True)  # <1>        self.fc = nn.Linear(self.dec_units, self.vocab_size)  # <2>        self.fc = nn.Linear(self.dec_units, self.vocab_size)  # <2>    def forward(self, inputs, hidden):    def forward(self, inputs, hidden):        inputs = self.embedding(inputs)        inputs = self.embedding(inputs)        output, state = self.gru(inputs,hidden)        output, state = self.gru(inputs,hidden)        output = output.view(-1, output.size(2))  # <3>        output = output.view(-1, output.size(2))  # <3>        decoder_output  = self.fc(output)  # <4>        decoder_output  = self.fc(output)  # <4>        return decoder_output, state        return decoder_output, stateclass Seq2Seq(nn.Module):class Seq2Seq(nn.Module):   def __init__(self, config,vocab_inp_size,vocab_out_size):   def __init__(self, config,vocab_inp_size,vocab_out_size):       super(Seq2Seq, self).__init__()       super(Seq2Seq, self).__init__()       self.SOS = 5       self.SOS = 5       self.EOS = 4       self.EOS = 4       self.vocab_inp_size = vocab_inp_size       self.vocab_inp_size = vocab_inp_size       self.vocab_out_size = vocab_out_size       self.vocab_out_size = vocab_out_size       self.batch_size = 64       self.batch_size = 64       self.training = False       self.training = False       self.gpu = False       self.gpu = False       self.device = torch.device("cuda" if self.gpu else "cpu")       self.device = torch.device("cuda" if self.gpu else "cpu")       self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)       self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)       self.encoder = Encoder(config,vocab_inp_size)       self.encoder = Encoder(config,vocab_inp_size)       self.decoder = Decoder(config,vocab_out_size)       self.decoder = Decoder(config,vocab_out_size)       self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)       self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)   def encode(self,x,x_len):   def encode(self,x,x_len):       cur_batch_size = x.size()[1]       cur_batch_size = x.size()[1]       encode_init_state = self.encoder.initialize_hidden_state(cur_batch_size)       encode_init_state = self.encoder.initialize_hidden_state(cur_batch_size)       encoder_state, encoder_outputs = self.encoder.forward(x,                                               encode_init_state, x_len)       encoder_state, encoder_outputs = self.encoder.forward(x,                                               encode_init_state, x_len)       encoder_state, encoder_outputs = self.encoder.forward(x,                                               encode_init_state, x_len)       return encoder_outputs, encoder_state       return encoder_outputs, encoder_state   def decode(self, encoder_outputs,              encoder_hidden, targets, targets_lengths):   def decode(self, encoder_outputs,              encoder_hidden, targets, targets_lengths):   def decode(self, encoder_outputs,              encoder_hidden, targets, targets_lengths):       batch_size = encoder_outputs.size()[1]       batch_size = encoder_outputs.size()[1]       max_length = targets.size()[1]       max_length = targets.size()[1]       decoder_input = torch.tensor([[self.SOS]]* batch_size)       decoder_input = torch.tensor([[self.SOS]]* batch_size)       decoder_hidden = encoder_outputs       decoder_hidden = encoder_outputs      logits = Variable(torch.zeros(max_length,                        batch_size, self.decoder.vocab_size))      logits = Variable(torch.zeros(max_length,                        batch_size, self.decoder.vocab_size))      logits = Variable(torch.zeros(max_length,                        batch_size, self.decoder.vocab_size))       final_sentences = Variable(torch.zeros(batch_size,max_length))       final_sentences = Variable(torch.zeros(batch_size,max_length))       for t in range(1,max_length):       for t in range(1,max_length):           predictions, decoder_hidden = self.decoder.forward(                   decoder_input.to(self.device),                   decoder_hidden.to(self.device))           predictions, decoder_hidden = self.decoder.forward(                   decoder_input.to(self.device),                   decoder_hidden.to(self.device))           predictions, decoder_hidden = self.decoder.forward(                   decoder_input.to(self.device),                   decoder_hidden.to(self.device))           predictions, decoder_hidden = self.decoder.forward(                   decoder_input.to(self.device),                   decoder_hidden.to(self.device))           logits[t] = predictions  # <1>           logits[t] = predictions  # <1>           if self.training: # <2>           if self.training: # <2>               decoder_input = targets[:, t].unsqueeze(1)               decoder_input = targets[:, t].unsqueeze(1)           else:           else:               decoder_input = torch.argmax(predictions,axis=1).unsqueeze(1)               decoder_input = torch.argmax(predictions,axis=1).unsqueeze(1)               final_sentences[:,t] = decoder_input.squeeze(1)               final_sentences[:,t] = decoder_input.squeeze(1)       labels = targets.contiguous().view(-1)       labels = targets.contiguous().view(-1)       mask_value = 0       mask_value = 0       logits = mask_3d(logits.transpose(1,0),targets_lengths,mask_value) # <3>       logits = mask_3d(logits.transpose(1,0),targets_lengths,mask_value) # <3>       logits = logits.contiguous().view(-1,self.vocab_out_size)       logits = logits.contiguous().view(-1,self.vocab_out_size)       return logits, labels.long(), final_sentences       return logits, labels.long(), final_sentences   def step(self, batch):   def step(self, batch):       x, y, x_len,y_len = batch       x, y, x_len,y_len = batch       x_sorted, y_sorted, x_len_sorted, y_len_sorted = sort_batch(x,y,x_len,y_len) # <6>       x_sorted, y_sorted, x_len_sorted, y_len_sorted = sort_batch(x,y,x_len,y_len) # <6>       encoder_out, encoder_state = self.encode(x_sorted, x_len_sorted)  # <4>       encoder_out, encoder_state = self.encode(x_sorted, x_len_sorted)  # <4>       logits, labels, final_sentences = self.decode(encoder_out, encoder_state, y_sorted, y_len_sorted) # <5>       logits, labels, final_sentences = self.decode(encoder_out, encoder_state, y_sorted, y_len_sorted) # <5>       return logits, labels, final_sentences       return logits, labels, final_sentences   def loss(self, batch):   def loss(self, batch):       logits, labels, final_sentences = self.step(batch) # <6>       logits, labels, final_sentences = self.step(batch) # <6>       loss = self.loss_fn(logits, labels)       loss = self.loss_fn(logits, labels)       return loss, logits, labels, final_sentences       return loss, logits, labels, final_sentencesmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # <1>model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # <1>model.fit([encoder_input_data, decoder_input_data],  # <2>model.fit([encoder_input_data, decoder_input_data],  # <2>encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)  # <1>encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)  # <1>thought_input = [Input(shape=(num_neurons,)),    Input(shape=(num_neurons,))]  # <1>thought_input = [Input(shape=(num_neurons,)),    Input(shape=(num_neurons,))]  # <1>thought_input = [Input(shape=(num_neurons,)),    Input(shape=(num_neurons,))]  # <1>decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)  # <2>decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)  # <2>decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)  # <2>decoder_states = [state_h, state_c]  # <3>decoder_states = [state_h, state_c]  # <3>decoder_outputs = decoder_dense(decoder_outputs)  # <4>decoder_outputs = decoder_dense(decoder_outputs)  # <4>decoder_model = Model(  # <5>    inputs=[decoder_inputs] + thought_input,    # <6>    output=[decoder_outputs] + decoder_states)  # <7>decoder_model = Model(  # <5>    inputs=[decoder_inputs] + thought_input,    # <6>    output=[decoder_outputs] + decoder_states)  # <7>decoder_model = Model(  # <5>    inputs=[decoder_inputs] + thought_input,    # <6>    output=[decoder_outputs] + decoder_states)  # <7>decoder_model = Model(  # <5>    inputs=[decoder_inputs] + thought_input,    # <6>    output=[decoder_outputs] + decoder_states)  # <7>thought = encoder_model.predict(input_seq)  # <1>thought = encoder_model.predict(input_seq)  # <1>while not stop_condition:  # <2>    output_tokens, h, c = decoder_model.predict(        [target_seq] + thought)  # <3>while not stop_condition:  # <2>    output_tokens, h, c = decoder_model.predict(        [target_seq] + thought)  # <3>while not stop_condition:  # <2>    output_tokens, h, c = decoder_model.predict(        [target_seq] + thought)  # <3>while not stop_condition:  # <2>    output_tokens, h, c = decoder_model.predict(        [target_seq] + thought)  # <3>from nlpia.loaders import get_datafrom nlpia.loaders import get_datadf = get_data('moviedialog')df = get_data('moviedialog')input_texts, target_texts = [], []  # <1>input_texts, target_texts = [], []  # <1>input_vocabulary = set()  # <2>input_vocabulary = set()  # <2>output_vocabulary = set()output_vocabulary = set()start_token = '\t'  # <3>start_token = '\t'  # <3>stop_token = '\n'stop_token = '\n'max_training_samples = min(25000, len(df) - 1)  # <4>max_training_samples = min(25000, len(df) - 1)  # <4>for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)for input_text, target_text in zip(df.statement, df.reply):    target_text = start_token + target_text \        + stop_token  # <5>    input_texts.append(input_text)    target_texts.append(target_text)    for char in input_text:  # <6>        if char not in input_vocabulary:            input_vocabulary.add(char)    for char in target_text:        if char not in output_vocabulary:            output_vocabulary.add(char)input_vocabulary = sorted(input_vocabulary)  # <1>input_vocabulary = sorted(input_vocabulary)  # <1>output_vocabulary = sorted(output_vocabulary)output_vocabulary = sorted(output_vocabulary)input_vocab_size = len(input_vocabulary)  # <2>input_vocab_size = len(input_vocabulary)  # <2>output_vocab_size = len(output_vocabulary)output_vocab_size = len(output_vocabulary)max_encoder_seq_length = max(    [len(txt) for txt in input_texts])  # <3>max_encoder_seq_length = max(    [len(txt) for txt in input_texts])  # <3>max_encoder_seq_length = max(    [len(txt) for txt in input_texts])  # <3>max_decoder_seq_length = max(    [len(txt) for txt in target_texts])max_decoder_seq_length = max(    [len(txt) for txt in target_texts])max_decoder_seq_length = max(    [len(txt) for txt in target_texts])input_token_index = dict([(char, i) for i, char in    enumerate(input_vocabulary)])  # <4>input_token_index = dict([(char, i) for i, char in    enumerate(input_vocabulary)])  # <4>input_token_index = dict([(char, i) for i, char in    enumerate(input_vocabulary)])  # <4>target_token_index = dict(    [(char, i) for i, char in enumerate(output_vocabulary)])target_token_index = dict(    [(char, i) for i, char in enumerate(output_vocabulary)])target_token_index = dict(    [(char, i) for i, char in enumerate(output_vocabulary)])reverse_input_char_index = dict((i, char) for char, i in    input_token_index.items())  # <5>reverse_input_char_index = dict((i, char) for char, i in    input_token_index.items())  # <5>reverse_input_char_index = dict((i, char) for char, i in    input_token_index.items())  # <5>reverse_target_char_index = dict((i, char) for char, i in    target_token_index.items())reverse_target_char_index = dict((i, char) for char, i in    target_token_index.items())reverse_target_char_index = dict((i, char) for char, i in    target_token_index.items())import numpy as np  # <1>import numpy as np  # <1>encoder_input_data = np.zeros((len(input_texts),    max_encoder_seq_length, input_vocab_size),    dtype='float32')  # <2>encoder_input_data = np.zeros((len(input_texts),    max_encoder_seq_length, input_vocab_size),    dtype='float32')  # <2>encoder_input_data = np.zeros((len(input_texts),    max_encoder_seq_length, input_vocab_size),    dtype='float32')  # <2>encoder_input_data = np.zeros((len(input_texts),    max_encoder_seq_length, input_vocab_size),    dtype='float32')  # <2>decoder_input_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_input_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_input_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_input_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_target_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_target_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_target_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')decoder_target_data = np.zeros((len(input_texts),    max_decoder_seq_length, output_vocab_size),    dtype='float32')for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1for i, (input_text, target_text) in enumerate(            zip(input_texts, target_texts)):  # <3>    for t, char in enumerate(input_text):  # <4>        encoder_input_data[            i, t, input_token_index[char]] = 1.  # <5>    for t, char in enumerate(target_text):  # <6>        decoder_input_data[            i, t, target_token_index[char]] = 1.        if t > 0:            decoder_target_data[i, t - 1, target_token_index[char]] = 1from keras.models import Modelfrom keras.models import Modelfrom keras.layers import Input, LSTM, Densefrom keras.layers import Input, LSTM, Densebatch_size = 64    # <1>batch_size = 64    # <1>epochs = 100       # <2>epochs = 100       # <2>num_neurons = 256  # <3>num_neurons = 256  # <3>encoder_inputs = Input(shape=(None, input_vocab_size))encoder_inputs = Input(shape=(None, input_vocab_size))encoder = LSTM(num_neurons, return_state=True)encoder = LSTM(num_neurons, return_state=True)encoder_outputs, state_h, state_c = encoder(encoder_inputs)encoder_outputs, state_h, state_c = encoder(encoder_inputs)encoder_states = [state_h, state_c]encoder_states = [state_h, state_c]decoder_inputs = Input(shape=(None, output_vocab_size))decoder_inputs = Input(shape=(None, output_vocab_size))decoder_lstm = LSTM(num_neurons, return_sequences=True,                    return_state=True)decoder_lstm = LSTM(num_neurons, return_sequences=True,                    return_state=True)decoder_lstm = LSTM(num_neurons, return_sequences=True,                    return_state=True)decoder_outputs, _, _ = decoder_lstm(decoder_inputs,    initial_state=encoder_states)decoder_outputs, _, _ = decoder_lstm(decoder_inputs,    initial_state=encoder_states)decoder_outputs, _, _ = decoder_lstm(decoder_inputs,    initial_state=encoder_states)decoder_dense = Dense(output_vocab_size, activation='softmax')decoder_dense = Dense(output_vocab_size, activation='softmax')decoder_outputs = decoder_dense(decoder_outputs)decoder_outputs = decoder_dense(decoder_outputs)model = Model([encoder_inputs, decoder_inputs], decoder_outputs)model = Model([encoder_inputs, decoder_inputs], decoder_outputs)model.compile(optimizer='rmsprop', loss='categorical_crossentropy',              metrics=['acc'])model.compile(optimizer='rmsprop', loss='categorical_crossentropy',              metrics=['acc'])model.compile(optimizer='rmsprop', loss='categorical_crossentropy',              metrics=['acc'])model.fit([encoder_input_data, decoder_input_data],    decoder_target_data, batch_size=batch_size, epochs=epochs,    validation_split=0.1)  # <4>model.fit([encoder_input_data, decoder_input_data],    decoder_target_data, batch_size=batch_size, epochs=epochs,    validation_split=0.1)  # <4>model.fit([encoder_input_data, decoder_input_data],    decoder_target_data, batch_size=batch_size, epochs=epochs,    validation_split=0.1)  # <4>model.fit([encoder_input_data, decoder_input_data],    decoder_target_data, batch_size=batch_size, epochs=epochs,    validation_split=0.1)  # <4>encoder_model = Model(encoder_inputs, encoder_states)encoder_model = Model(encoder_inputs, encoder_states)thought_input = [    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]thought_input = [    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]thought_input = [    Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)decoder_outputs, state_h, state_c = decoder_lstm(    decoder_inputs, initial_state=thought_input)decoder_states = [state_h, state_c]decoder_states = [state_h, state_c]decoder_outputs = decoder_dense(decoder_outputs)decoder_outputs = decoder_dense(decoder_outputs)decoder_model = Model(    inputs=[decoder_inputs] + thought_input,    output=[decoder_outputs] + decoder_states)decoder_model = Model(    inputs=[decoder_inputs] + thought_input,    output=[decoder_outputs] + decoder_states)decoder_model = Model(    inputs=[decoder_inputs] + thought_input,    output=[decoder_outputs] + decoder_states)decoder_model = Model(    inputs=[decoder_inputs] + thought_input,    output=[decoder_outputs] + decoder_states)def decode_sequence(input_seq):    thought = encoder_model.predict(input_seq)  # <1>def decode_sequence(input_seq):    thought = encoder_model.predict(input_seq)  # <1>def decode_sequence(input_seq):    thought = encoder_model.predict(input_seq)  # <1>def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)def response(input_text):   input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size),       dtype='float32')   for t, char in enumerate(input_text):  # <1>       input_seq[0, t, input_token_index[char]] = 1.   decoded_sentence = decode_sequence(input_seq)  # <2>   print('Bot Reply (Decoded sentence):', decoded_sentence)response("what is the internet?")response("what is the internet?")response("why?")response("why?")response("do you like coffee?")response("do you like coffee?")response("do you like football?")response("do you like football?")