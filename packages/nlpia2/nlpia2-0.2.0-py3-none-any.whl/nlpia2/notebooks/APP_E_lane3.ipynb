{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d190e6",
   "metadata": {},
   "source": [
    "#### [APP_E_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/APP_E_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920bab9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_intent import INTENT_RECOGNIZER as pipe\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c916cba",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilabel_intent_recognition import *  <1>\n",
    "df = pd.read_csv(DATA_DIR / TRAINING_SET_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6317a0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70170bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78350d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = multilabel_to_unilabel(df)\n",
    "df_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e4fcc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = tags_from_labels(df_uni)\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5a88b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60567133",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/intent/\", response_model=Response)\n",
    "async def intent(request: Request):  # <1>\n",
    "    response = Response()\n",
    "    response.tags = predict_intents(request.text)\n",
    "    response.created_at = datetime.now()\n",
    "    return response\n",
    "----\n",
    "<1> To improve readability, use the same name for the endpoint function and the endpoint URL path.\n",
    "\n",
    "The endpoint function receives a `Request` object and uses it to construct a `Response` object.\n",
    "The `app.post` decorator takes care of all the HTTP POST protocol processing to convert the request payload (JSON string or bytes) into a Python `Request` object that your function can process just like any other Python object.\n",
    "The endpoint decorator also takes care of serializing the returned `Response` object to create the appropriate HTTP protocol responses.\n",
    "So FastAPI takes care of all the difficult work of processing and generating the headers a web API needs to work.\n",
    "\n",
    "How does FastAPI know what a valid `Request` or `Response` object should look like?\n",
    "For example, if the user calls this endpoint with the string `1`, how does it know whether to keep it as a string or convert it to an `int`, `float`, or `bool` type object?\n",
    "The answer is it doesn’t.\n",
    "You need to use the `pydantic` library to tell FastAPI what kind of data the requests and responses will contain.\n",
    "That’s all it needs to insert the appropriate string processing functions needed to create the Python types that you want.\n",
    "Fortunately, `pydantic` just uses the built-in _type hints_ feature of Python 3.8+.\n",
    "\n",
    "Here is the `pydantic` data model (schema) for the incoming `Request` objects:\n",
    "\n",
    "[source,python]\n",
    "----\n",
    "class Request(BaseModel):\n",
    "    text: str = None  # <1>\n",
    "    embedding: list[float] = None  # <2>\n",
    "----\n",
    "<1> Optional natural language text (user chat message, document, LLM text, etc.)\n",
    "<2> Optional embedding vector associated with natural language text from a user\n",
    "\n",
    "Wait a minute, you probably thought this endpoint was designed to handle natural language text.\n",
    "What is this second optional input for a list of ``float``s called an embedding?\n",
    "If you define multiple possible arguments to your endpoint, it gives your user more options when calling your API.\n",
    "You should take the time to think about all the possible use cases for your API.\n",
    "This /intent/ endpoint was designed to be multipurpose and accept either natural language text _or_ an embedding.\n",
    "\n",
    "Best practice API design would split this into two separate endpoints, but in some cases, this multipurpose endpoint can be helpful if you want to upgrade an endpoint while remaining _reverse compatible_.\n",
    "A reverse-compatible API will work in the original way that your users have been using it in the past, but it also enables new features.\n",
    "For web APIs, you should always try to make your endpoints reverse compatible for a period of time before you _deprecate_ a feature and require your users to learn the new API.\n",
    "\n",
    "You define the `Response` object the same way you did for the `Request` class, using Pydantic:\n",
    "\n",
    "[source,python]\n",
    "----\n",
    "class Response(BaseModel):\n",
    "    tags: List[Tag] = []  # <1>\n",
    "    embedding: list[float] = None  # <2>\n",
    "    created_at: datetime = None  # <3>\n",
    "----\n",
    "<1> Sorted list of Tag objects (named tuples) with the most likely tag at the top\n",
    "<2> Embedding or encoding vector (list of floats)\n",
    "<3> Timestamp when the response was composed\n",
    "\n",
    "Here in the `Response` class, you can define all the pieces of information you’d like to send back to the other parts of your app.\n",
    "In the case of this multilabel intent recognizer endpoint, you could return a single intent label, such as `positive` or `greeting`, or you can provide more detail.\n",
    "You built this multilabel classifier to be able to handle ambiguity by providing multiple intent labels for each message.\n",
    "So you probably want to return a ranked list of all the possible intents as the preceding code does.\n",
    "In addition to the label itself, you might want to provide an integer index for that label as well as a floating-point value for the probability or confidence of that particular label.\n",
    "You can think of this as the weight or emphasis that the text places on this particular intent label.\n",
    "Python provides a nice data type for capturing triplets of information like this—a named tuple.\n",
    "\n",
    "The following code creates a standard Python `NamedTuple` class, where you can store the intent label, a confidence score, and the index integer of the intent, in one compact tuple:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d58e52",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag(NamedTuple):\n",
    "    label: str\n",
    "    proba: float = None\n",
    "    index: int = None\n",
    "----\n",
    "\n",
    "Now that you have seen the `pydantic` datatype class for the labels (tags) and the response object, you might now realize how to use that `Response.embedding` attribute to give the caller more information about the intents associated with the text.\n",
    "As you can see in chapter 6, embedding vectors contain a lot of “ness” information (sentiment) about a word or passage of text.\n",
    "So if your user has NLP skills like you do, they may want to get access to the raw BERT encoding (embedding) this endpoint uses under the hood.\n",
    "\n",
    "Here is the code to pop the hood on your /intent/ endpoint and expose the raw embedding vector to NLP engineers or conversation designers who might want to use it within other parts of the application:\n",
    "\n",
    "[source,python]\n",
    "----\n",
    "@app.post(\"/intent/\", response_model=Response)\n",
    "async def intent(request: Request):\n",
    "    response = Response()\n",
    "    response.embedding = predict_encoding_cached(request.text)\n",
    "    response.tags = predict_intents_from_encoding(response.embedding)\n",
    "    response.created_at = datetime.now()\n",
    "    return response\n",
    "----\n",
    "\n",
    "You can see that this multipurpose endpoint reveals two new opportunities for creating additional microservices.\n",
    "You can imagine an /encode_text/ endpoint to provide the raw BERT encoding vector.\n",
    "The user would call that endpoint first and then use that encoding vector to call a second endpoint:/intents_from_encoding/.\n",
    "This would allow you to split your endpoints into separate microservices.\n",
    "You may also be wondering what that ``cached`` suffix means at the end of `predict_encoding_cached`.\n",
    "You can learn more about both caching and splitting in section E.3.3.\n",
    "\n",
    "This microservice for predicting user intent can be kept separate from the rest of your application.\n",
    "This architecture makes it possible for you to continue to improve the NLP pipeline while your teammates work on other parts of the application.\n",
    "Because this microservice focuses on this one prediction task, it remains isolated from other components delivering a successful chat experience.\n",
    "This is called _separation of concerns_, a best practice that ensures more maintainable and performant software.\n",
    "The microservice doing NLU prediction can ignore all the other tasks of a chatbot application, such as authentication and content management.\n",
    "\n",
    "Well-designed and documented microservices are easy for developers to work with.\n",
    "When microservices are clearly defined and have separate tasks, it becomes clear where errors originate.\n",
    "In this prediction microservice’s case, a failure at the prediction step would indicate that the microservice had some issues.\n",
    "Failures in other parts of the application would be easier to track down, as well.\n",
    "Additionally, you should write focused tests to ensure different parts of the prediction service work—the model download, storing the model in memory, making a prediction, and the cache growing with use.\n",
    "These tests ensure the changes don’t break the service as development continues.\n",
    "But the other components of the web application don’t need the NLP-related tests cluttering up their test directories, much like both baseball teams don’t sit in the same dugout to watch the game.\n",
    "A microservice should be independent, only loosely coupled with the rest of the application.\n",
    "The more rigorously you plan for this and make the application configurable, the more reusable your microservice will be for other applications.\n",
    "\n",
    "By breaking out your NLU endpoint as a microservice, in addition to improving the maintainability of your code, it also makes it easier to optimize the NLU for throughput, latency, and accuracy, without sacrificing the user experience in other parts of the app.\n",
    "You can optimize each microservice separately, improving the scalability of your app and reducing server costs.\n",
    "But before you try to optimize and scale up your application, you want to deploy your working prototype.\n",
    "So the next step is creating a container (containerizing or Dockerizing) for your microservice.\n",
    "\n",
    "=== Containerizing a microservice\n",
    "\n",
    "Even as a smaller component, microservices can be challenging to build and deploy correctly.\n",
    "There are many steps to configure and build a microservice, but environments differ in several ways across platforms, services, and developers, such as how they handle `.env` variables.\n",
    "While it’s also good to have as similar staging and production branches as possible, it might be more practical to use settings on staging that reduce costs.\n",
    "It can be easy to miss or even break steps that are necessary to get a microservice set up and running.\n",
    "Developers work across different environments and may need to use different steps to accomplish the same task.\n",
    "A simple example comes from activating a venv virtual environment.\n",
    "Windows uses `source .venv/Scripts/activate`, but Linux uses `source .venv/bin/activate`.\n",
    "The greater a variety of platforms you use, the more challenging it can be to communicate deployment and to collaborate in general.\n",
    "Working through these platform differences can be time-consuming and frustrating.\n",
    "Containerizing can help deal with the complexity of deploying to various systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39253f68",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2be2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_directory = Path(DATA_DIR / \"cache\")\n",
    "memory = joblib.Memory(cache_directory, verbose=0, backend=\"local\")\n",
    "async def clean_prediction_cache():\n",
    "   memory.reduce_size(items_limit=500, bytes_limit=1048576)\n",
    "predict_intents_cached = memory.cache(predict_intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f379e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3972d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_RECOGNIZER_MODEL = None\n",
    "def predict_intents_list(text, num_intents=None):\n",
    "   global INTENT_RECOGNIZER_MODEL\n",
    "   INTENT_RECOGNIZER_MODEL = INTENT_RECOGNIZER_MODEL or joblib.load(\n",
    "       download_model(INTENT_RECOGNIZER_PATH)\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99a451",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd461064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilabel_intent_recognition import *\n",
    "train_validate_save()\n",
    "mv data/multi_intent_recognizer.{timestamp}.pkl data/multi_intent_recognizer.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592738b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "resp = requests.post(\n",
    "    \"http://127.0.0.1:8080/intent/\",\n",
    "    json={\"content\":\n",
    "        \"Disturbing! That made me uncomfortable.\"})\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a40789",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.json()['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca25d0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06033d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.json()['embedding']"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
