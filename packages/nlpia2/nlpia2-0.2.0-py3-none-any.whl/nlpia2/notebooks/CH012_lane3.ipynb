{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224630b6",
   "metadata": {},
   "source": [
    "#### [CH012_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH012_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87f4ea",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad Snisar, Ruslan Borisov build ConvoHub w/ spaCy.\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230a72a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02005910",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar, ruslan borisov build convoHub w/ spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df61414",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0419aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar ruslan borisov convoHub spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d81cd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f14b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_proper_nouns(\n",
    "        context, key=\"user_text\",  # <1>\n",
    "        pos=\"PROPN\", ent_type=None):  # <2>\n",
    "    doc = nlp(context.get(key, ''))  # <3>\n",
    "    names = []\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        tok = doc[i]\n",
    "        ent = []\n",
    "        if ((pos is None or tok.pos_ == pos)\n",
    "                and (ent_type is None or tok.ent_type_ != ent_type)):\n",
    "            for k, t in enumerate(doc[i:]):\n",
    "                if not ((pos is None or t.pos_ == pos)\n",
    "                    and (ent_type is None or t.ent_type_\n",
    "                        != ent_type)):\n",
    "                    break\n",
    "                ent.append(t.text)\n",
    "            names.append(\" \".join(ent))\n",
    "        i += len(ent) + 1\n",
    "    return {'proper_nouns': names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98b5f9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ruslan Borisov and Vlad Snisar rebuilt ConvoHub.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1000758",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc60f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mathtext\n",
    "from mathtext.predict_intent import predict_intents_list\n",
    "predict_intents_list('you are mean forty 2')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a10af",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_intents_list('you are jerk infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0b490",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb82e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_data(start, stop, step, question_num=None):\n",
    "    \"\"\" Generate list of possible questions with their contexts \"\"\"\n",
    "    seq = seq2str(start, stop, step)\n",
    "    templates = [\n",
    "        f\"Let's practice counting {seq2str(start, stop, step)}... \" \\\n",
    "        + f\"What is the next number in the sequence after {stop}?\",\n",
    "        f\"What number comes {step} after {stop}?\\n{seq}\",\n",
    "        f\"We're counting by {step}s. \" \\\n",
    "        + f\"What number is 1 after {stop}?\\n{seq}\",\n",
    "        f\"What is {step} number up from {stop}?\\n{seq}\",\n",
    "        f\"If we count up {step} from {stop}, \" \\\n",
    "        + f\"what number is next?\\n{seq}\",\n",
    "    ]\n",
    "    questions = []\n",
    "    for quest in templates:\n",
    "        questions.append({\n",
    "             \"question\": quest,\n",
    "             \"answer\": stop + step,\n",
    "             \"start\": start,\n",
    "             \"stop\": stop,\n",
    "             \"step\": step,\n",
    "             })\n",
    "    return questions[question_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919da324",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = '<your_API_key_here>'\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:\" +\n",
    "    \"df7690\",  # <1>\n",
    "    input={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 100,\n",
    "        \"top_p\": 1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b37bed",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad65aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor \n",
    "    chatbot Rori and a user who might be a student \n",
    "    in Africa or a parent. \n",
    "\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"message\"],  # <1>\n",
    "    template=template)       \n",
    "chain = LLMChain(\n",
    "    llm=llm, verbose=True, prompt=prompt  # <2>\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1af3e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af453c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"Hi Bot! My name is Maria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e3033",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f59e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a52a9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor chatbot\n",
    "    Rori and a user who might be a student in Africa or a parent. \n",
    "    The chatbot introduces itself and asks if it's talking to a\n",
    "    student or to a parent. \n",
    "    If the user is a parent, Rori asks the parent for \n",
    "    permission for the child to use Rori over Whatsapp. \n",
    "    If the user is a student, Rori asks the student to\n",
    "     call their parents. \n",
    "    If the parent agrees, Rori thanks them and asks to give the phone to the student. \n",
    "    Provide the tutor's next response based on the conversation history.\n",
    "\n",
    "    {chat_history}\n",
    "    Parent: {message}\n",
    "    Tutor:\"\"\"\n",
    "onboarding_prompt = PromptTemplate(\n",
    "    input_variables = [\"chat_history\", \"message\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead110d4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af550fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555ffda",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c462ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory\n",
    "    )\n",
    "onboarding_chain.prompt = onboarding_prompt\n",
    "onboarding_chain.predict(message=\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a71499",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b90d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain.predict(message=\"I'm a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed483d8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathConversation():\n",
    "    def __init__(self, llm, prompt_string):\n",
    "        self.llm = llm\n",
    "        self.memory = \\\n",
    "            ConversationBufferMemory(\n",
    "                memory_key='history',\n",
    "                ai_prefix='tutor',\n",
    "                human_prefix=\"user\")\n",
    "        self.convo_chain = ConversationChain(\n",
    "            llm=llm, memory=self.memory)\n",
    "        self.convo_chain.prompt = PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\"],\n",
    "            template=prompt_string)\n",
    "\n",
    "    def answer(self, user_input):\n",
    "        return self.convo_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb967e9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85925955",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo = MathConversation(llm, onboarding_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68885dae",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"I am a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5249ebf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"Yes, I agree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97acf9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_quiz_pt = \"\"\"\n",
    "You are a math teacher that's teaching math to a third-grade\n",
    "student. Prompt the student to complete number sequences\n",
    "from the following list and compare their answer with the\n",
    "last number in the sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672e392",
   "metadata": {},
   "source": [
    "#### .LLMs can't count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo = MathConversation(llm, math_quiz_pt)\n",
    "math_convo.answer(\"Let's start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4affb3",
   "metadata": {},
   "source": [
    "#### .LLMs can't count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08602c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo.answer(\"12\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
