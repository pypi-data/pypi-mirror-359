{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c957f06a",
   "metadata": {},
   "source": [
    "#### [CH02_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH02_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a5c08",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c66c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"Trust me, though, the words were on their way, and when \"\n",
    "        \"they arrived, Liesel would hold them in her hands like \"\n",
    "        \"the clouds, and she would wring them out, like the rain.\")\n",
    "tokens = text.split()  # <1>\n",
    "tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef183a",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'  # <1>\n",
    "texts = [text]\n",
    "texts.append(\"There's no such thing as survival of the fittest. \"\n",
    "             \"Survival of the most adequate, maybe.\")\n",
    "tokens = list(re.findall(pattern, texts[-1]))\n",
    "tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0717f2",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[8:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a525d",
   "metadata": {},
   "source": [
    "#### .Example quote from _The Book Thief_ split into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e8bf5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = sorted(set(tokens))  # <1>\n",
    "' '.join(vocab[:12])  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857fd61",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a48bb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a609671",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15392f4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy  # <1>\n",
    "spacy.cli.download('en_core_web_sm')  # <2>\n",
    "nlp = spacy.load('en_core_web_sm')  # <3>\n",
    "doc = nlp(texts[-1])\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79373a4d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332886ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tok.text for tok in doc]\n",
    "tokens[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29b75",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[9:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e89cbb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "sentence = list(doc.sents)[0]  # <1>\n",
    "svg = displacy.render(sentence, style=\"dep\",\n",
    "    jupyter=False)  # <2>\n",
    "open('sentence_diagram.svg', 'w').write(svg)  # <3>\n",
    "displacy.render(sentence, style=\"dep\")  # <5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d53e6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b07a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "text = requests.get('https://proai.org/nlpia2-ch2.adoc').text\n",
    "f'{round(len(text) / 10_000)}0k'  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438297c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1411ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "%timeit nlp(text)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817ac56",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(text) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f72ab",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "f'{round(len(list(doc)) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48c7e4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb5b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{round(len(doc) / 1_000 / 4.67)}kWPS'  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59398747",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a034beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b3304",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf31466",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=nlp.pipe_names)\n",
    "%timeit nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df64eb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e29dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d585caf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aec063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "%timeit word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1104bb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf143208",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "f'{round(len(tokens) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b995d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\w+(?:\\'\\w+)?|[^\\w\\s]'\n",
    "tokens = re.findall(pattern, text)  # <1>\n",
    "f'{round(len(tokens) / 10_000)}0k'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000bb8c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1386080",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), analyzer='char')\n",
    "vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad0ff2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpevocab_list = [\n",
    "   sorted((i, s) for s, i in vectorizer.vocabulary_.items())]\n",
    "bpevocab_dict = dict(bpevocab_list[0])\n",
    "list(bpevocab_dict.values())[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00522c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3415577",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.transform(texts)\n",
    "df = pd.DataFrame(\n",
    "    vectors.todense(),\n",
    "    columns=vectorizer.get_feature_names_out())\n",
    "df.index = [t[:8] + '...' for t in texts]\n",
    "df = df.T\n",
    "df['total'] = df.T.sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93823d9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6fe694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('total').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1157db",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n'] = [len(tok) for tok in vectorizer.vocabulary_]\n",
    "df[df['n'] > 1].sort_values('total').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae639169",
   "metadata": {},
   "source": [
    "#### .A broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = (\"https://gitlab.com/tangibleai/nlpia/-/raw/master/\"\n",
    "       \"src/nlpia/data/stopword_lists.json\")\n",
    "response = requests.get(url)\n",
    "stopwords = response.json()['exhaustive']  # <1>\n",
    "tokens = 'the words were just as I remembered them'.split()  # <2>\n",
    "tokens_without_stopwords = [x for x in tokens if x not in stopwords]\n",
    "print(tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2b1d5",
   "metadata": {},
   "source": [
    "#### .A broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d2a6b",
   "metadata": {},
   "source": [
    "#### .A broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ee433",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff171a1",
   "metadata": {},
   "source": [
    "#### .A broad list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sw for sw in stopwords if len(sw) == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417cf40b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e35bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['House', 'Visitor', 'Center']\n",
    "normalized_tokens = [x.lower() for x in tokens]\n",
    "print(normalized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9374fd3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(phrase):\n",
    "    return ' '.join([re.findall('^(.*ss|.*?)(s)?$',\n",
    "        word)[0][0].strip(\"'\") for word in phrase.lower().split()])\n",
    "stem('houses')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7678e8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ffb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem(\"Doctor House's calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce91532",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "' '.join([stemmer.stem(w).strip(\"'\") for w in\n",
    "  \"dish washer's fairly washed dishes\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c082c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0aad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "' '.join([stemmer.stem(w).strip(\"'\") for w in\n",
    "  \"dish washer's fairly washed dishes\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e5fbe",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6308ad",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55917c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461f0f8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb13191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"better\")  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdd41c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"better\", pos=\"a\")  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b3413",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712201fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"good\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76ee6c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"goods\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18e674",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"goods\", pos=\"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5396d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem('goodness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e2f52",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"better good goods goodness best\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412fa7c",
   "metadata": {},
   "source": [
    "#### .Jieba in accurate mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"西安是一座举世闻名的文化古城\")  # <1>\n",
    "list(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763dba8",
   "metadata": {},
   "source": [
    "#### .Jieba in accurate mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"西安是一座举世闻名的文化古城\", cut_all=True)  # <1>\n",
    "list(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501d07c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b02d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "onehot_vectors = np.zeros(\n",
    "    (len(tokens), vocab_size), int)  # <1>\n",
    "for i, tok in enumerate(tokens):\n",
    "    if tok not in vocab:\n",
    "        continue\n",
    "    onehot_vectors[i, vocab.index(tok)] = 1  # <2>\n",
    "df_onehot = pd.DataFrame(onehot_vectors, columns=vocab)\n",
    "df_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3031b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot.iloc[:,:8].replace(0, '')  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44edb952",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac75f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = sorted(set(re.findall(pattern, text)))\n",
    "bow[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb84cb7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e130781",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[9:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28a5ce",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859460cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow[19:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fb26b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b29bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "sa.lexicon  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cf740",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb847041",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tok, score) for tok, score in sa.lexicon.items()\n",
    "  if \" \" in tok]  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189bd54",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.polarity_scores(text=\\\n",
    "  \"Python is very readable and it's great for NLP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde23949",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb735f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.polarity_scores(text=\\\n",
    "  \"Python is not a bad choice for most applications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f9953",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Absolutely perfect! Love it! :-) :-) :-)\",\n",
    "          \"Horrible! Completely useless. :(\",\n",
    "          \"It was OK. Some good and some bad things.\"]\n",
    "for doc in corpus:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    print('{:+}: {}'.format(scores['compound'], doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad29a14",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('https://proai.org/movie-reviews.csv.gz',\n",
    "    index_col=0)\n",
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f27ffa",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf996ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c276c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10309364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.width = 75  # <1>\n",
    "from nltk.tokenize import casual_tokenize  # <2>\n",
    "bows = []\n",
    "from collections import Counter  # <3>\n",
    "for text in movies.text:\n",
    "    bows.append(Counter(casual_tokenize(text)))\n",
    "df_movies = pd.DataFrame.from_records(bows)  # <4>\n",
    "df_movies = df_movies.fillna(0).astype(int)  # <5>\n",
    "df_movies.shape  # <6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa7b34",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8effe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706cff1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()[list(bows[0].keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04768edf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc156827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(df_movies, movies.sentiment > 0)  # <1>\n",
    "movies['pred_senti'] = (\n",
    "  nb.predict_proba(df_movies))[:, 1] * 8 - 4  # <2>\n",
    "movies['error'] = movies.pred_senti - movies.sentiment\n",
    "mae = movies['error'].abs().mean().round(1)  # <3>\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d71bf3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['senti_ispos'] = (movies['sentiment'] > 0).astype(int)\n",
    "movies['pred_ispos'] = (movies['pred_senti'] > 0).astype(int)\n",
    "columns = [c for c in movies.columns if 'senti' in c or 'pred' in c]\n",
    "movies[columns].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b4a16",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movies.pred_ispos ==\n",
    "  movies.senti_ispos).sum() / len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e0f3f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13333e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('https://proai.org/product-reviews.csv.gz')\n",
    "products.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fc317",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c96b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96551b3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = []\n",
    "for text in products['text']:\n",
    "    bows.append(Counter(casual_tokenize(text)))\n",
    "df_products = pd.DataFrame.from_records(bows)\n",
    "df_products = df_products.fillna(0).astype(int)\n",
    "df_products.shape # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab7aa7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05800f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_bows = pd.concat([df_movies, df_products])\n",
    "df_all_bows.columns  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4d037",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc824fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(df_movies.columns)  # <1>\n",
    "df_products = df_all_bows.iloc[len(movies):]  # <2>\n",
    "df_products = df_products[vocab]  # <3>\n",
    "df_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528edf4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49148442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.shape  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a5e68",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "products['senti_ispos'] = (products['sentiment'] > 0).astype(int)\n",
    "products['pred_ispos'] = nb.predict(df_products).astype(int)\n",
    "correct = (products['pred_ispos']\n",
    "        == products['senti_ispos'])  # <1>\n",
    "correct.sum() / len(products)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
