{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db7ee94",
   "metadata": {},
   "source": [
    "#### [CH03_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH03_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f9d2f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")  # <1>\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = ('It has also arisen in criminal justice, healthcare, and '\n",
    "    'hiring, compounding existing racial, economic, and gender biases'\n",
    "    )\n",
    "doc = nlp(sentence)\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae7f58",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c6521",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "most_common = dict(bag_of_words.most_common())  # <1>\n",
    "counts = pd.Series(most_common)  # <2>\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee0354",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ee322",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da238bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb40d3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef90a4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d60e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts / counts.sum()  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181bbd4d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['justice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb074960",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f918ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['justice'] / counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2900d1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81262fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Algorithmic bias has been cited in cases ranging from \" \\\n",
    "    \"election outcomes to the spread of online hate speech.\"\n",
    "tokens = [tok.text for tok in nlp(sentence)]\n",
    "counts = Counter(tokens)\n",
    "dict(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e944f55",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da837bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = ('https://gitlab.com/tangibleai/nlpia2/'\n",
    "       '-/raw/main/src/nlpia2/ch03/bias_intro.txt')\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02ab37",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c92c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_intro_bytes = response.content  # <1>\n",
    "bias_intro = response.text  # <2>\n",
    "assert bias_intro_bytes.decode() == bias_intro    # <3>\n",
    "bias_intro[:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db45d5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tok.text for tok in nlp(bias_intro)]\n",
    "counts = Counter(tokens)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20a4de",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc82772",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3376e",
   "metadata": {},
   "source": [
    "#### .Short documents about bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(s) for s in bias_intro.split('\\n')\n",
    "        if s.strip()]  # <1>\n",
    "counts = []\n",
    "for doc in docs:\n",
    "    counts.append(Counter([\n",
    "        t.text.lower() for t in doc]))  # <2>\n",
    "df = pd.DataFrame(counts)\n",
    "df = df.fillna(0).astype(int)  # <3>\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335f50f",
   "metadata": {},
   "source": [
    "#### .Short documents about bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81088e72",
   "metadata": {},
   "source": [
    "#### .Short documents about bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769872cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfda633",
   "metadata": {},
   "source": [
    "#### .Short documents about bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10]  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90811fac",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e186c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc_tokens = []\n",
    "for tokens in docs_tokens:\n",
    "    all_doc_tokens.extend(tokens)\n",
    "len(all_doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d94f4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(all_doc_tokens)  # <1>\n",
    "vocab = sorted(vocab)  # <2>\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47abee",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_doc_tokens) / len(vocab)  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818e503",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3577fa",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors = []\n",
    "for tokens in docs_tokens:\n",
    "    count_vectors.append(Counter(tokens))\n",
    "tf = pd.DataFrame(count_vectors)  # <1>\n",
    "tf = tf.T.sort_index().T\n",
    "tf = tf.fillna(0).astype(int)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9aa420",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f417519",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2b2c4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "np.set_printoptions(edgeitems=8)  # <1>\n",
    "corpus = [doc.text for doc in docs]\n",
    "vectorizer = CountVectorizer()  # <2>\n",
    "vectorizer = vectorizer.fit(corpus)  # <3>\n",
    "count_vectors = vectorizer.transform(corpus)  # <4>\n",
    "count_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b8297",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors.toarray()  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1b348",
   "metadata": {},
   "source": [
    "#### .Increasing the vectorized math in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e66e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.arange(5)  # <1>\n",
    "v2 = pd.Series(reversed(range(5)))\n",
    "slow_answer = sum([4.2 * (x1 * x2) for x1, x2 in zip(v1, v2)])\n",
    "slow_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c07b87",
   "metadata": {},
   "source": [
    "#### .Increasing the vectorized math in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_answer = sum(4.2 * v1 * v2)  # <2>\n",
    "faster_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4338c",
   "metadata": {},
   "source": [
    "#### .Increasing the vectorized math in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c862a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastest_answer = 4.2 * v1.dot(v2)  # <3>\n",
    "fastest_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526f413",
   "metadata": {},
   "source": [
    "#### .Increasing the vectorized math in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone git@gitlab.com/tangibleai/community/knowt\n",
    "!cd knowt\n",
    "mmvecs = np.memmap(\n",
    "    '.knowt-data/hpr_vectors.memmap',\n",
    "    shape=(41_531, 384),  # <1>\n",
    "    dtype=np.float32,\n",
    "    mode='r')\n",
    "vecs = np.array(mmvecs.T.copy().tolist())\n",
    "variables = dict(vecs=vecs, v=v)\n",
    "dt_vectorized = timeit('v.dot(vecs)', globals=variables, number=20)\n",
    "dt_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123539c9",
   "metadata": {},
   "source": [
    "#### .A looping search of HPR episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loops():\n",
    "    answers = np.zeros(shape[0])\n",
    "    for i, vec in enumerate(vecs):\n",
    "        answers[i] = sum((x1 * x2 for (x1, x2) in zip(v[0], vec)))\n",
    "    return answers\n",
    "variables = dict(np=np, loops=loops, vecs=vecs.T, v=v)\n",
    "dt_loop = timeit('loops()', globals=variables, number=20)\n",
    "dt_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d65d6",
   "metadata": {},
   "source": [
    "#### .A looping search of HPR episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_loop / dt_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c236f",
   "metadata": {},
   "source": [
    "#### .A looping search of HPR episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"muted\")  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9a4c2",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2092f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([2, 3, 4])\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed542d",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(v1 * v2).sum()  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a6efa",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3276867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x1 * x2 for x1, x2 in zip(v1, v2)])  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556efa79",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(B) == (np.linalg.norm(A) * np.linalg.norm(B)) * \\\n",
    "    np.cos(angle_between_A_and_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6c809",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8738df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_between_A_and_B = np.cos(angle_between_A_and_B) \\\n",
    "   = A.dot(B) / (np.linalg.norm(A) * np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f2a72",
   "metadata": {},
   "source": [
    "#### .Example dot product calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9b5869",
   "metadata": {},
   "source": [
    "#### .Calculating cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cba9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tf = tf.fillna(0)  # <1>\n",
    "vec1 = tf.values[:1,:]  # <2>\n",
    "vec2 = tf.values[1:2,:]\n",
    "cosine_similarity(vec1, vec2)  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a950a",
   "metadata": {},
   "source": [
    "#### .Calculating cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fd634",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim(vec1[0], vec2[0])  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902e195",
   "metadata": {},
   "source": [
    "#### .Calculating cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "question = \"What is algorithmic bias?\"\n",
    "ngram_docs = copy.copy(docs)\n",
    "ngram_docs.append(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85550d",
   "metadata": {},
   "source": [
    "#### .Calculating cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28154f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec = vectorizer.transform([new_sentence])\n",
    "question_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8915f2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec.to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b3bd3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in\n",
    "    vectorizer.vocabulary_.items())))[1]\n",
    "pd.Series(question_vec.to_array()[0], index=vocab).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea34879",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(count_vectors, question_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b145e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62786d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c9583",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04feac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "ngram_vectors = ngram_vectorizer.fit_transform(corpus)\n",
    "ngram_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fc509",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in\n",
    "    ngram_vectorizer.vocabulary_.items())))[1]\n",
    "pd.DataFrame(ngram_vectors.toarray(),\n",
    "    columns=vocab)['algorithmic bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1099f1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from this import s as secret\n",
    "print(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7dc709",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cabd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nlpia2_wikipedia         # <1>\n",
    "import wikipedia as wiki\n",
    "page = wiki.page('machine learning')  # <2>\n",
    "mlcounts = count_chars(page.content)\n",
    "mlcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167b837",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "secretcounts /= secretcounts.sum()  # <1>\n",
    "secretcounts.sort_index()['a':'z'].plot(kind='bar', grid='on')\n",
    "plt.title('Secret Message')\n",
    "plt.subplot(2,1,2)\n",
    "mlcounts /= mlcounts.sum()  # <2>\n",
    "mlcounts.sort_index()['a':'z'].plot(kind='bar', grid='on')\n",
    "plt.title('ML Article')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f999c04",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_distance = ord('R') - ord('E')\n",
    "peak_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07c8ca",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord('v') - peak_distance)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc061b0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord('n') - peak_distance)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcbc877",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord('W') - peak_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a95fe1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cf761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "print(codecs.decode(secret, 'rot-13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cece47",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46308918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('brown')  # <1>\n",
    "from nltk.corpus import brown\n",
    "brown.words()[:10]  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bfc63",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.tagged_words()[:5]  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cab5c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50515753",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db8b3b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "puncs = set((',', '.', '--', '-', '!', '?',\n",
    "    ':', ';', '``', \"''\", '(', ')', '[', ']'))\n",
    "word_list = (x.lower() for x in brown.words() if x not in puncs)\n",
    "token_counts = Counter(word_list)\n",
    "token_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cb168",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb555c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n",
    "            '-/raw/master/src/nlpia/data')\n",
    "url = DATA_DIR + '/bias_discrimination.txt'\n",
    "bias_discrimination = requests.get(url).content.decode()\n",
    "intro_tokens = [t.text for t in nlp(bias_intro.lower())]\n",
    "disc_tokens = [t.text for t in nlp(bias_discrimination.lower())]\n",
    "intro_total = len(intro_tokens)\n",
    "intro_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d3386",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_total = len(disc_tokens)\n",
    "disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafefd4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf = {}\n",
    "disc_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['bias'] = intro_counts['bias'] / intro_total\n",
    "disc_counts = Counter(disc_tokens)\n",
    "disc_tf['bias'] = disc_counts['bias'] / disc_total\n",
    "'Term Frequency of \"bias\" in intro is:{:.4f}'.format(intro_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bbdd74",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Term Frequency of \"bias\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e41d7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['and'] = intro_counts['and'] / intro_total\n",
    "disc_tf['and'] = disc_counts['and'] / disc_total\n",
    "print('Term Frequency of \"and\" in intro is: {:.4f}'\\\n",
    "    .format(intro_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd2ecf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa45d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Term Frequency of \"and\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910c4d0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b81d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_and = 0\n",
    "for doc in [intro_tokens, disc_tokens]:\n",
    "    if 'and' in doc:\n",
    "        num_docs_containing_and += 1  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9bdcb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['black'] = intro_counts['black'] / intro_total\n",
    "disc_tf['black'] = disc_counts['black'] / disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6781060",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6083a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 2\n",
    "intro_idf = {}\n",
    "disc_idf = {}\n",
    "intro_idf['and'] = num_docs / num_docs_containing_and\n",
    "disc_idf['and'] = num_docs / num_docs_containing_and\n",
    "intro_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "disc_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "intro_idf['black'] = num_docs / num_docs_containing_black\n",
    "disc_idf['black'] = num_docs / num_docs_containing_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24a0ee",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e361f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tfidf = {}\n",
    "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
    "intro_tfidf['bias'] = intro_tf['bias'] * intro_idf['bias']\n",
    "intro_tfidf['black'] = intro_tf['black'] * intro_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219f0a6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_tfidf = {}\n",
    "disc_tfidf['and'] = disc_tf['and'] * disc_idf['and']\n",
    "disc_tfidf['bias'] = disc_tf['bias'] * disc_idf['bias']\n",
    "disc_tfidf['black'] = disc_tf['black'] * disc_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1481d",
   "metadata": {},
   "source": [
    "#### .Downloading Hacker Public Radio show notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f92c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "url = 'https://gitlab.com/tangibleai/community/knowt/-/raw/main/'\n",
    "url += '.knowt-data/corpus_hpr/sentences.csv?inline=false'\n",
    "df = pd.read_csv(url)\n",
    "docs = df['sentence']\n",
    "vectorizer = TfidfVectorizer(min_df=1)  # <1>\n",
    "vectorizer = vectorizer.fit(docs)       # <2>\n",
    "vectors = vectorizer.transform(docs)    # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334af71",
   "metadata": {},
   "source": [
    "#### .Downloading Hacker Public Radio show notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = vectorizer.transform(\n",
    "    ['where is the lost audio'])  # <1>\n",
    "query_vec  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab895909",
   "metadata": {},
   "source": [
    "#### .Downloading Hacker Public Radio show notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076edeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotproducts = query_vec.dot(vectors.T)  # <3>\n",
    "dotproducts.argmax()\n",
    "idx = dotproducts.argmax()\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc8420",
   "metadata": {},
   "source": [
    "#### .Downloading Hacker Public Radio show notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387cec1",
   "metadata": {},
   "source": [
    "#### .Downloading Hacker Public Radio show notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efae5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[i]['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca04c87",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_FAQ_URL = ('https://gitlab.com/tangibleai/nlpia2/-/raw/main/'\n",
    "    'src/nlpia2/data/faqbot.csv')\n",
    "df = pd.read_csv(DS_FAQ_URL, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d0916",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['question'])\n",
    "tfidfvectors_sparse = vectorizer.transform(df['question'])  # <1>\n",
    "tfidfvectors = tfidfvectors_sparse.todense()  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ddafb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "   question_vector = vectorizer.transform([question]).todense()\n",
    "   idx = question_vector.dot(tfidfvectors.T).argmax() # <1>\n",
    "\n",
    "   print(\n",
    "       f\"Your question:\\n  {question}\\n\\n\"\n",
    "       f\"Most similar FAQ question:\\n  {df['question'][idx]}\\n\\n\"\n",
    "       f\"Answer to that FAQ question:\\n  {df['answer'][idx]}\\n\\n\"\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22399ab1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"What's overfitting a model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384dfa9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask('How do I decrease overfitting for Logistic Regression?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28ec64",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'LogisticRegression'\n",
    "question_vector = vectorizer.transform([question])\n",
    "dotproducts = question_vector.dot(tfidfvectors_sparse.T)\n",
    "dotproducts = dotproducts.toarray()[0]  # <1>\n",
    "idx = dotproducts.argsort()[-3:]  # <2>\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4af9e6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotproducts[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc83826",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer'][idx]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
