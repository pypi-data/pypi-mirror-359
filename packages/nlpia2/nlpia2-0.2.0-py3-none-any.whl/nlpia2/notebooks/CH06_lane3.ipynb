{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58b01b8",
   "metadata": {},
   "source": [
    "#### [CH06_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH06_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13736f86",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nessvec.indexers import Index  # <1>\n",
    "index = Index(num_vecs=100_000)  # <2>\n",
    "index.get_nearest(\"Engineer\").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94859e8c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfe306",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.get_nearest(\"Developer\").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d423eac",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d76e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "chief = (index.data[index.vocab[\"Chief\"]]\n",
    "    + index.data[index.vocab[\"Engineer\"]])\n",
    "index.get_nearest(chief)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e36bca",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_vector = wv['woman'] + wv['Europe'] + wv['physics'] +\n",
    "    wv['scientist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cf5d0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37609b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_vector = wv['woman'] + wv['Europe'] + wv['physics'] +\\\n",
    "    wv['scientist'] - wv['male'] - 2 * wv['man']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec73ab",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_vector = wv['Louis_Pasteur'] - wv['germs'] + wv['physics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db167f03",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv['Marie_Curie'] - wv['science'] + wv['music']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c908c",
   "metadata": {},
   "source": [
    "#### .Compute nessvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6969c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nessvec.examples.ch06.nessvectors import *  # <1>\n",
    "nessvector('Marie_Curie').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d908684",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "dsets = torchtext.datasets.WikiText2()\n",
    "num_texts = 10000\n",
    "filepath = DATA_DIR / f'WikiText2-{num_texts}.txt'\n",
    "with open(filepath, 'wt') as fout:\n",
    "    fout.writelines(list(dsets[0])[:num_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121682f5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8111cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 3 ~/nessvec-data/WikiText2-10000.txt\n",
    "import datasets\n",
    "dset = datasets.load_dataset('text', data_files=str(filepath))\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17cacc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.map(tokenize_row)\n",
    "dset\n",
    "vocab = list(set(\n",
    "    [tok for row in dset['train']['tokens'] for tok in row]))\n",
    "vocab[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020a3c4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe379d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tok = dict(enumerate(vocab))\n",
    "list(id2tok.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b89799",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2id = {tok: i for (i, tok) in id2tok.items()}\n",
    "list(tok2id.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd43332",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowizer(row, wsize=WINDOW_WIDTH):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f5b79",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d981470",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dset.map(windowizer)\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8a777",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ca102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_grams(tokens, window_width=WINDOW_WIDTH):\n",
    "   pairs = []\n",
    "   for i, wd in enumerate(tokens):\n",
    "       target = tok2id[wd]\n",
    "       window = [\n",
    "           i + j for j in\n",
    "           range(-window_width, window_width + 1, 1)\n",
    "           if (i + j >= 0)\n",
    "           & (i + j < len(tokens))\n",
    "           & (j != 0)\n",
    "       ]\n",
    "from torch.utils.data import Dataset\n",
    "class Word2VecDataset(Dataset):\n",
    "   def __init__(self, dataset, vocab_size, wsize=WINDOW_WIDTH):\n",
    "       self.dataset = dataset\n",
    "       self.vocab_size = vocab_size\n",
    "       self.data = [i for s in dataset['moving_window'] for i in s]\n",
    "\n",
    "   def __len__(self):\n",
    "       return len(self.data)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "       return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5b744",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39673597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec()\n",
    "model\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae3374",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # noqa\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1e23f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\\\n",
    "    '/path/to/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nlpia2.loaders import get_data\n",
    "word_vectors = get_data('w2v', limit=200000)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6116957",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['cooking', 'potatoes'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c4c2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['germany', 'france'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd2a21",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf890bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.doesnt_match(\"potatoes milk cake computer\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f2888",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738fd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['king', 'woman'],\n",
    "    negative=['man'], topn=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9a4b6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.similarity('princess', 'queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f09013",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e703206",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors['phone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a559f87",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf223f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a0b9e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63e579",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300  # <1>\n",
    "min_word_count = 3  # <2>\n",
    "num_workers = 2  # <3>\n",
    "window_size = 6  # <4>\n",
    "subsampling = 1e-3  # <5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fb80c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    token_list,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=window_size,\n",
    "    sample=subsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94ab11",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e70058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9d832",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"my_domain_specific_word2vec_model\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f53bef",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model_name = \"my_domain_specific_word2vec_model\"\n",
    "model = Word2Vec.load(model_name)\n",
    "model.most_similar('radiology')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c5e0f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"This is an example sentence.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "   print(token.text, token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc3235",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nessvec.files import load_fasttext\n",
    "df = load_fasttext()  # <1>\n",
    "df.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebcf48",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['prosocial']  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d254a",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vocab = pd.Series(wv.vocab)\n",
    "vocab.iloc[1000000:100006]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02dd79",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv['Illini']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da471496",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c8228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.linalg.norm(wv['Illinois'] - wv['Illini'])  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b93ec",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = np.dot(wv['Illinois'], wv['Illini']) / (\n",
    "    np.linalg.norm(wv['Illinois']) *\\\n",
    "    np.linalg.norm(wv['Illini']))  # <2>\n",
    "cos_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3f92a",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a637404",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - cos_similarity # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02046d32",
   "metadata": {},
   "source": [
    "#### .Examining Word2Vec vocabulary frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.data.loaders import get_data\n",
    "cities = get_data('cities')\n",
    "cities.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326b96e",
   "metadata": {},
   "source": [
    "#### .Some US state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = cities[(cities.country_code == 'US') &\\\n",
    "    (cities.admin1_code.notnull())].czopy()\n",
    "states = pd.read_csv(\\\n",
    "    'http://www.fonz.net/blog/wp-content/uploads/2008/04/states.csv')\n",
    "states = dict(zip(states.Abbreviation, states.State))\n",
    "us['city'] = us.name.copy()\n",
    "us['st'] = us.admin1_code.copy()\n",
    "us['state'] = us.st.map(states)\n",
    "us[us.columns[-3:]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1f132",
   "metadata": {},
   "source": [
    "#### .Some US state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.np.concatenate([us.city, us.st, us.state])\n",
    "vocab = np.array([word for word in vocab if word in wv.wv])\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5baab4",
   "metadata": {},
   "source": [
    "#### .Some US state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_plus_state = []\n",
    "for c, state, st in zip(us.city, us.state, us.st):\n",
    "    if c not in vocab:\n",
    "        continue\n",
    "    row = []\n",
    "    if state in vocab:\n",
    "        row.extend(wv[c] + wv[state])\n",
    "    else:\n",
    "        row.extend(wv[c] + wv[st])\n",
    "    city_plus_state.append(row)\n",
    "us_300D = pd.DataFrame(city_plus_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d630c1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model.distance('man', 'nurse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370295b2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb87df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model.distance('woman', 'nurse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7befd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)  # <1>\n",
    "us_300D = get_data('cities_us_wordvectors')\n",
    "us_2D = pca.fit_transform(us_300D.iloc[:, :300])  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d6be49",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8977d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "from nlpia2.plots import offline_plotly_scatter_bubble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb93bdb",
   "metadata": {},
   "source": [
    "#### .Writing the ADOC string to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path.cwd() / name\n",
    "with path.open('w') as fout:\n",
    "    fout.write(adoc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144139c7",
   "metadata": {},
   "source": [
    "#### .Writing the ADOC string to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea40538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.run(args=[   # <1>\n",
    "    'asciidoc3', '-a', '-n', '-a', 'icons', path.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41576e1",
   "metadata": {},
   "source": [
    "#### .Writing the ADOC string to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(chapt6_html) and os.path.getsize(chapt6_html) > 0:\n",
    "    chapter6_html = open(chapt6_html, 'r').read()\n",
    "    bsoup = BeautifulSoup(chapter6_html, 'html.parser')\n",
    "    text = bsoup.get_text()  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d13732",
   "metadata": {},
   "source": [
    "#### .Writing the ADOC string to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60082dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "config = {'punct_chars': None}\n",
    "nlp.add_pipe('sentencizer', config=config)\n",
    "doc = nlp(text)\n",
    "sentences = []\n",
    "noun_phrases = []\n",
    "for sent in doc.sents:\n",
    "    sent_noun_chunks = list(sent.noun_chunks)\n",
    "    if sent_noun_chunks:\n",
    "        sentences.append(sent)\n",
    "        noun_phrases.append(max(sent_noun_chunks))\n",
    "sent_vecs = []\n",
    "for sent in sentences:\n",
    "   sent_vecs.append(sent.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebed8fa",
   "metadata": {},
   "source": [
    "#### .Writing the ADOC string to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vector = np.array([1, 2, 3, 4])  # <1>\n",
    "np.sqrt(sum(vector**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0861ba",
   "metadata": {},
   "source": [
    "#### .Normalizing the sentence vector embeddings with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9953e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i, sent_vec in enumerate(sent_vecs):\n",
    "    sent_vecs[i] = sent_vec / np.linalg.norm(sent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437aa11",
   "metadata": {},
   "source": [
    "#### .Normalizing the sentence vector embeddings with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8548e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_sent_vecs_norm = np.array(sent_vecs)\n",
    "similarity_matrix = np_array_sent_vecs_norm.dot(\n",
    "    np_array_sent_vecs_norm.T)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e091b",
   "metadata": {},
   "source": [
    "#### .Normalizing the sentence vector embeddings with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "similarity_matrix = np.triu(similarity_matrix, k=1)  # <1>\n",
    "iterator = np.nditer(similarity_matrix,\n",
    "    flags=['multi_index'], order='C')\n",
    "node_labels = dict()\n",
    "G = nx.Graph()\n",
    "pattern = re.compile(\n",
    "   r'[\\w\\s]*[\\'\\\"]?[\\w\\s]+\\-?[\\w\\s]*[\\'\\\"]?[\\w\\s]*'\n",
    "   )  # <2>\n",
    "for edge in iterator:\n",
    "    key = 0\n",
    "    value = ''\n",
    "    if edge > 0.95:  # <3>\n",
    "        key = iterator.multi_index[0]\n",
    "        value = str(noun_phrases[iterator.multi_index[0]])\n",
    "        if (pattern.fullmatch(value)\n",
    "            and (value.lower().rstrip() != 'figure')):\n",
    "                node_labels[key] = value\n",
    "        G.add_node(iterator.multi_index[0])\n",
    "        G.add_edge(iterator.multi_index[0],\n",
    "            iterator.multi_index[1], weight=edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe71ea8",
   "metadata": {},
   "source": [
    "#### .Plotting an undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d060edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1, 1, 1)  # <1>\n",
    "pos = nx.spring_layout(G, k=0.15, seed=42)  # <2>\n",
    "nx.draw_networkx(G,\n",
    "   pos=pos,  # <3>\n",
    "   with_labels=True,\n",
    "   labels=node_labels,\n",
    "   font_weight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
