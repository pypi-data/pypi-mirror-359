{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e4e641",
   "metadata": {},
   "source": [
    "#### [CH08_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH08_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cf3e4",
   "metadata": {},
   "source": [
    "#### .Recurrence in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9921e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "            vocab_size, hidden_size, output_size):  # <1>\n",
    "        super().__init__()\n",
    "        self.W_c2h = nn.Linear(\n",
    "            vocab_size + hidden_size, hidden_size)  # <2>\n",
    "        self.W_c2y = nn.Linear(vocab_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):  # <3>\n",
    "        combined = torch.cat((x, hidden), axis=1)  # <4>\n",
    "        hidden = self.W_c2h(combined)  # <5>\n",
    "        y = self.W_c2y(combined)  # <6>\n",
    "        y = self.softmax(y)\n",
    "        return y, hidden  # <7>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54e8a3",
   "metadata": {},
   "source": [
    "#### .SpaCy tagging tokens with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nlpia2.spacy_language_model import nlp\n",
    "tagged_tokens = list(nlp('Hello world. Goodbye now!'))\n",
    "interesting_tags = 'text dep_ head lang_ lemma_ pos_ sentiment'\n",
    "interesting_tags = (interesting_tags +  'shape_ tag_').split()\n",
    "pd.DataFrame([\n",
    "        [getattr(t, a) for a in interesting_tags]\n",
    "        for t in tagged_tokens],\n",
    "    columns=interesting_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f056df",
   "metadata": {},
   "source": [
    "#### .SpaCy tagging tokens with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2781c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia2.string_normalizers import Asciifier\n",
    "asciify = Asciifier()\n",
    "asciify(\"O’Néàl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1bd95",
   "metadata": {},
   "source": [
    "#### .SpaCy tagging tokens with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9537f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "asciify(\"Çetin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd5662",
   "metadata": {},
   "source": [
    "#### .Loadign the surname data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489440aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'tangibleai/nlpia2'  # <1>\n",
    "filepath = 'src/nlpia2/data/surname-nationality.csv.gz'\n",
    "url = f\"https://gitlab.com/{repo}/-/raw/main/{filepath}\"\n",
    "df = pd.read_csv(url)  # <2>\n",
    "df[['surname', 'nationality']].sort_values('surname').head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815dabc0",
   "metadata": {},
   "source": [
    "#### .Loadign the surname data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d98e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nationality'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f2254",
   "metadata": {},
   "source": [
    "#### .Loadign the surname data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['nationality'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb494781",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_unique = {}\n",
    "for i, g in df.groupby('nationality'):\n",
    "    fraction_unique[i] = g['surname'].nunique() / len(g)\n",
    "pd.Series(fraction_unique).sort_values().head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6bb5e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic = [x.strip() for x in open('.nlpia2-data/names/Arabic.txt')]\n",
    "arabic = pd.Series(sorted(arabic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccaa58c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('surname')\n",
    "overlap = {}\n",
    "for i, g in df.groupby('surname'):\n",
    "    n = g['nationality'].nunique()\n",
    "    if n > 1:\n",
    "        overlap[i] = {'nunique': n,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ea2ff",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap.sort_values('nunique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4bd0",
   "metadata": {},
   "source": [
    "#### .The heart of an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96029573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "def __init__(self, n_hidden=128, categories, char2i):  # <1>\n",
    "    super().__init__()\n",
    "    self.categories = categories\n",
    "    self.n_categories = len(self.categories)  # <2>\n",
    "    print(f'RNN.categories: {self.categories}')\n",
    "    print(f'RNN.n_categories: {self.n_categories}')\n",
    "def forward(self, x, hidden):  # <3>\n",
    "    combined = torch.cat((x, hidden), 1)\n",
    "    hidden = self.W_c2h(combined)\n",
    "    y = self.W_c2y(combined)\n",
    "    y = self.softmax(y)\n",
    "    return y, hidden  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df305a",
   "metadata": {},
   "source": [
    "#### .The heart of an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21390dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sample(model, category_tensor, char_seq_tens,\n",
    "                criterion=nn.NLLLoss(), lr=.005):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daf485",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b86de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classify_name_nationality.py  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf205a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_category(\"Khalid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417208ea",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = topk_predictions(model, 'Khalid', topk=4)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d78fcf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = topk_predictions(model, 'Khalid', topk=4)\n",
    "predictions['likelihood'] = np.exp(predictions['log_loss'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fd165",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hidden(self, text=\"Khalid\"):\n",
    "   text_tensor = self.encode_one_hot_seq(text)\n",
    "   with torch.no_grad():  # <1>\n",
    "       hidden = self.hidden_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e81378",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(self, text=\"Khalid\"):\n",
    "   text_tensor = self.encode_one_hot_seq(text)\n",
    "   with torch.no_grad():\n",
    "       hidden = self.hidden_init\n",
    "       for i in range(text_tensor.shape[0]):\n",
    "           y, hidden = self(text_tensor[i], hidden)\n",
    "   return y  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccee3a0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(self, text):\n",
    "   tensor = self.encode_one_hot_seq(text)\n",
    "   y = self.predict_proba(tensor)  # <1>\n",
    "   pred_i = y.topk(1)[1][0].item()  # <2>\n",
    "   return self.categories[pred_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b68f6bb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7340d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Khalid'\n",
    "pred_categories = []\n",
    "pred_hiddens = []\n",
    "for i in range(1, len(text) + 1):\n",
    "   pred_hiddens.append(model.predict_hidden(text[:i]))  # <1>\n",
    "   pred_categories.append(model.predict_category(text[:i]))\n",
    "pd.Series(pred_categories, input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99296564",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dec0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = [h[0].tolist() for h in hiddens]\n",
    "df_hidden = pd.DataFrame(hidden_lists, index=list(text))\n",
    "df_hidden = df_hidden.T.round(2)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c929f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = pd.Series(range(len(text)), index=df_hidden.index)\n",
    "pd.DataFrame(position).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e8dd3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hidden_raw.corrwith(position).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fcf12d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96406564",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('data/wikitext-2/train.txt').readlines()\n",
    "for line in lines[:4]:\n",
    "    print(line.rstrip()[:70])\n",
    "from nlpia2.ch08.data import Corpus\n",
    "corpus = Corpus('data/wikitext-2')\n",
    "corpus.train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c1f84",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = corpus.dictionary\n",
    "[vocab.idx2word[i] for i in corpus.train[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14159b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_slow(x, batch_size=8, num_batches=5):\n",
    "   batches = []\n",
    "   for i in range(int(len(x)/batch_size)):\n",
    "       if i > num_batches:\n",
    "           break\n",
    "       batches.append(x[i*batch_size:i*batch_size + batch_size])\n",
    "   return batches\n",
    "batches = batchify_slow(corpus.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c81d1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991cdd9a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd370ff2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sigmoid(W_i2r.mm(x) + b_i2r +    W_h2r.mm(h) + b_h2r)  # <1>\n",
    "z = sigmoid(W_i2z.mm(x) + b_i2z +    W_h2z.mm(h) + b_h2z)  # <2>\n",
    "n =    tanh(W_i2n.mm(x) + b_i2n + r∗(W_h2n.mm(h) + b_h2n))  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a59974",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model, learned=True):\n",
    "    return sum(\n",
    "        p.numel() for p in model.parameters()  # <1>\n",
    "        if not learned or p.requires_grad  # <2>\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc8fe1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91402572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines  # <1>\n",
    "with jsonlines.open('experiments.jsonl') as fin:\n",
    "    lines = list(fin)\n",
    "df = pd.DataFrame(lines)\n",
    "df.to_csv('experiments.csv')\n",
    "cols = 'learned_parameters rnn_type epochs lr num_layers'\n",
    "cols += ' dropout epoch_time test_loss'\n",
    "cols = cols.split()\n",
    "df[cols].round(2).sort_values('test_loss', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274670a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d20308",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sigmoid(W_i2r.mm(x) + b_i2r +    W_h2r.mm(h) + b_h2r)\n",
    "z = sigmoid(W_i2z.mm(x) + b_i2z +    W_h2z.mm(h) + b_h2z)\n",
    "n =    tanh(W_i2n.mm(x) + b_i2n + r∗(W_h2n.mm(h) + b_h2n))\n",
    "\n",
    "f = sigmoid(W_i2f.mm(x) + b_i2f + W_h2f.mm(h) + b_h2f)  # <1>\n",
    "i = sigmoid(W_i2i.mm(x) + b_i2i + W_h2i.mm(h) + b_h2i)  # <2>\n",
    "g = tanh(W_i2g.mm(x) + b_i2g + W_h2y.mm(h) + b_h2g)  # <3>\n",
    "o = sigmoid(W_i2o.mm(x) + b_i2o + W_h2o.mm(h) + b_h2o)  # <4>\n",
    "c = f*c + i*g  # <5>\n",
    "h = o*tanh(c)\n",
    "----\n",
    "<1> The LSTM forgetting gate (GRU reset gate)\n",
    "<2> The LSTM input relevance gate (GRU update gate)\n",
    "<3> The LSTM cell gate—notice the redundant biases b_i2i and b_h2i\n",
    "<4> The LSTM output gate\n",
    "<5> The cell state\n",
    "\n",
    "=== Giving your RNN a tune-up\n",
    "\n",
    "As you learned in chapter 7, hyperparameter tuning becomes more and more important as your neural networks get more and more complicated.\n",
    "Your intuitions about layers, network capacity, and training time will get fuzzier and fuzzier as the models get complicated.\n",
    "RNNs are particularly intuitive.\n",
    "To jumpstart your intuition, we’ve trained dozens of different basic RNNs with different combinations of hyperparameters, such as the number of layers and number of hidden units in each layer.\n",
    "You can explore all the hyperparameters you are curious about, using the code in `nlpia2/ch08`footnote:[See the hypertune.py script in the ch08/rnn_word module within the `nlpia2` Python package: https://gitlab.com/tangibleai/nlpia2/-/blob/main/src/nlpia2/ch08/rnn_word/hypertune.py.]:\n",
    "\n",
    "[source,python]\n",
    "----\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('experiments.jsonl') as fin:\n",
    "    lines = list(fin)\n",
    "df = pd.DataFrame(lines)\n",
    "df.to_csv('experiments.csv')\n",
    "cols = 'rnn_type epochs lr num_layers dropout epoch_time test_loss'\n",
    "cols = cols.split()\n",
    "df[cols].round(2).sort_values('test_loss').head(10)\n",
    "----\n",
    "\n",
    "[source,text]\n",
    "----\n",
    "    epochs   lr  num_layers  dropout  epoch_time  test_loss\n",
    "37      12  2.0           2      0.2       35.43       5.23\n",
    "28      12  2.0           1      0.0       22.66       5.23\n",
    "49      32  0.5           2      0.0       32.35       5.22\n",
    "57      32  0.5           2      0.2       35.50       5.22\n",
    "38      12  2.0           3      0.2       46.14       5.21\n",
    "50      32  0.5           3      0.0       37.36       5.20\n",
    "52      32  2.0           1      0.0       22.90       5.10\n",
    "55      32  2.0           5      0.0       56.23       5.09\n",
    "53      32  2.0           2      0.0       32.49       5.06\n",
    "54      32  2.0           3      0.0       38.78       5.04\n",
    "----\n",
    "\n",
    "It’s a really exciting thing to explore the hyperspace of options like this and discover surprising tricks for building accurate models.\n",
    "Surprisingly, for this RNN language model trained on a small subset of Wikipedia, you can get great results without maximizing the size and capacity of the model.\n",
    "You can achieve better accuracy with a three-layer RNN than with a five-layer RNN.\n",
    "You just need to start with an aggressive learning rate and keep the dropout to a minimum—the fewer layers you have the faster the model will train.\n",
    "\n",
    "[TIP]\n",
    "====\n",
    "Experiment often, and always document what things you tried and how well the model worked.\n",
    "This kind of hands-on work provides the quickest path toward an intuition that speeds up your model building and learning.\n",
    "Your lifelong goal is to train your mental model to predict which hyperparameter values will produce the best results in any given situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411c67b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia2.ch08.rnn_word.data import Corpus\n",
    "corpus = Corpus('data/wikitext-2')\n",
    "passage = corpus.train.numpy()[-89:-35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc64ebf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac13b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([vocab.idx2word[i] for i in passage])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a05da9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eos = sum([vocab.idx2word[i] == '<eos>' for i in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92987884",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba1c1a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unk = sum([vocab.idx2word[i] == '<unk>' for i in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0527997",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f46761",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_normal = sum([\n",
    "    vocab.idx2word[i] not in ('<unk>', '<eos>')\n",
    "    for i in corpus.train.numpy()])\n",
    "num_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df525576",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unk / (num_normal + num_eos + num_unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289046a4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from preprocessing import Corpus\n",
    "from generate import generate_words\n",
    "from model import RNNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82c2fd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(w for w in words))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
