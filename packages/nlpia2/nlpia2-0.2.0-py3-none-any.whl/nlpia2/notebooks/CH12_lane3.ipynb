{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c05a30",
   "metadata": {},
   "source": [
    "#### [CH12_lane3](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/CH12_lane3.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388ca42",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad Snisar, Ruslan Borisov build ConvoHub w/ spaCy.\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269afbd3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar, ruslan borisov build convoHub w/ spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc148bb3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar ruslan borisov convoHub spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6001f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_proper_nouns(\n",
    "        context, key=\"user_text\",  # <1>\n",
    "        pos=\"PROPN\", ent_type=None):  # <2>\n",
    "    doc = nlp(context.get(key, ''))  # <3>\n",
    "    names = []\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        tok = doc[i]\n",
    "        ent = []\n",
    "        if ((pos is None or tok.pos_ == pos)\n",
    "                and (ent_type is None or tok.ent_type_ != ent_type)):\n",
    "            for k, t in enumerate(doc[i:]):\n",
    "                if not ((pos is None or t.pos_ == pos)\n",
    "                    and (ent_type is None or t.ent_type_\n",
    "                        != ent_type)):\n",
    "                    break\n",
    "                ent.append(t.text)\n",
    "            names.append(\" \".join(ent))\n",
    "        i += len(ent) + 1\n",
    "    return {'proper_nouns': names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec100f6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2599aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ruslan Borisov and Vlad Snisar rebuilt ConvoHub.'\n",
    "context_diff = extract_proper_nouns(context=dict(user_text=text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b595559",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a30a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mathtext\n",
    "from mathtext.predict_intent import predict_intents_list\n",
    "predict_intents_list('you are mean forty 2')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863ea6b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_intents_list('you are jerk infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919c95a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deac42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_data(start, stop, step, question_num=None):\n",
    "    \"\"\" Generate list of possible questions with their contexts \"\"\"\n",
    "    seq = seq2str(start, stop, step)\n",
    "    templates = [\n",
    "        f\"Let's practice counting {seq2str(start, stop, step)}... \" \\\n",
    "        + f\"What is the next number in the sequence after {stop}?\",\n",
    "        f\"What number comes {step} after {stop}?\\n{seq}\",\n",
    "        f\"We're counting by {step}s. \" \\\n",
    "        + f\"What number is 1 after {stop}?\\n{seq}\",\n",
    "        f\"What is {step} number up from {stop}?\\n{seq}\",\n",
    "        f\"If we count up {step} from {stop}, \" \\\n",
    "        + f\"what number is next?\\n{seq}\",\n",
    "    ]\n",
    "    questions = []\n",
    "    for quest in templates:\n",
    "        questions.append({\n",
    "             \"question\": quest,\n",
    "             \"answer\": stop + step,\n",
    "             \"start\": start,\n",
    "             \"stop\": stop,\n",
    "             \"step\": step,\n",
    "             })\n",
    "    return questions[question_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239137f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = '<your_API_key_here>'\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:\" +\n",
    "    \"df7690\",  # <1>\n",
    "    input={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 100,\n",
    "        \"top_p\": 1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f611e4d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor \n",
    "    chatbot Rori and a user who might be a student \n",
    "    in Africa or a parent. \n",
    "\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"message\"],  # <1>\n",
    "    template=template)       \n",
    "chain = LLMChain(\n",
    "    llm=llm, verbose=True, prompt=prompt  # <2>\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4ad04",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6255cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"Hi Bot! My name is Maria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c790b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a4aec",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor chatbot\n",
    "    Rori and a user who might be a student in Africa or a parent. \n",
    "    The chatbot introduces itself and asks if it's talking to a\n",
    "    student or to a parent. \n",
    "    If the user is a parent, Rori asks the parent for \n",
    "    permission for the child to use Rori over Whatsapp. \n",
    "    If the user is a student, Rori asks the student to\n",
    "     call their parents. \n",
    "    If the parent agrees, Rori thanks them and asks to give the phone to the student. \n",
    "    Provide the tutor's next response based on the conversation history.\n",
    "\n",
    "    {chat_history}\n",
    "    Parent: {message}\n",
    "    Tutor:\"\"\"\n",
    "onboarding_prompt = PromptTemplate(\n",
    "    input_variables = [\"chat_history\", \"message\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e2ccb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bd37b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43313c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory\n",
    "    )\n",
    "onboarding_chain.prompt = onboarding_prompt\n",
    "onboarding_chain.predict(message=\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc016a7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain.predict(message=\"I'm a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908561e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathConversation():\n",
    "    def __init__(self, llm, prompt_string):\n",
    "        self.llm = llm\n",
    "        self.memory = \\\n",
    "            ConversationBufferMemory(\n",
    "                memory_key='history',\n",
    "                ai_prefix='tutor',\n",
    "                human_prefix=\"user\")\n",
    "        self.convo_chain = ConversationChain(\n",
    "            llm=llm, memory=self.memory)\n",
    "        self.convo_chain.prompt = PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\"],\n",
    "            template=prompt_string)\n",
    "\n",
    "    def answer(self, user_input):\n",
    "        return self.convo_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017c84c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa20e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo = MathConversation(llm, onboarding_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e993a62",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0862f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"I am a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e74897",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae372f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"Yes, I agree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10491e63",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_quiz_pt = \"\"\"\n",
    "You are a math teacher that's teaching math to a third-grade\n",
    "student. Prompt the student to complete number sequences\n",
    "from the following list and compare their answer with the\n",
    "last number in the sequence:\n",
    "  - 9,10,11,12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd135f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e490e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo.answer(\"12\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
