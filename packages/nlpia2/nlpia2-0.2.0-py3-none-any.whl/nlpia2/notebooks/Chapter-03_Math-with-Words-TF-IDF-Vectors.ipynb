{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed98e79",
   "metadata": {},
   "source": [
    "#### [`Chapter-03_Math-with-Words-TF-IDF-Vectors`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-03_Math-with-Words-TF-IDF-Vectors.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2dbd6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbb9bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'has',\n",
       " 'also',\n",
       " 'arisen',\n",
       " 'in',\n",
       " 'criminal',\n",
       " 'justice',\n",
       " ',',\n",
       " 'healthcare',\n",
       " ',',\n",
       " 'and',\n",
       " 'hiring',\n",
       " ',',\n",
       " 'compounding',\n",
       " 'existing',\n",
       " 'racial',\n",
       " ',',\n",
       " 'economic',\n",
       " ',',\n",
       " 'and',\n",
       " 'gender',\n",
       " 'biases',\n",
       " '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = ('It has also arisen in criminal justice, healthcare, and '\n",
    "    'hiring, compounding existing racial, economic, and gender biases.')\n",
    "doc = nlp(sentence)\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f102dd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be54ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({',': 5,\n",
       "         'and': 2,\n",
       "         'It': 1,\n",
       "         'has': 1,\n",
       "         'also': 1,\n",
       "         'arisen': 1,\n",
       "         'in': 1,\n",
       "         'criminal': 1,\n",
       "         'justice': 1,\n",
       "         'healthcare': 1,\n",
       "         'hiring': 1,\n",
       "         'compounding': 1,\n",
       "         'existing': 1,\n",
       "         'racial': 1,\n",
       "         'economic': 1,\n",
       "         'gender': 1,\n",
       "         'biases': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a14e2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6b05fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",              5\n",
       "and            2\n",
       "It             1\n",
       "has            1\n",
       "also           1\n",
       "arisen         1\n",
       "in             1\n",
       "criminal       1\n",
       "justice        1\n",
       "healthcare     1\n",
       "hiring         1\n",
       "compounding    1\n",
       "existing       1\n",
       "racial         1\n",
       "economic       1\n",
       "gender         1\n",
       "biases         1\n",
       ".              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "most_common = dict(bag_of_words.most_common())  # <1>\n",
    "counts = pd.Series(most_common)  # <2>\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e82f8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a16c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bde51",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d045669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdc95b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fc56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd5ee6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11e1515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",              0.217391\n",
       "and            0.086957\n",
       "It             0.043478\n",
       "has            0.043478\n",
       "also           0.043478\n",
       "arisen         0.043478\n",
       "in             0.043478\n",
       "criminal       0.043478\n",
       "justice        0.043478\n",
       "healthcare     0.043478\n",
       "hiring         0.043478\n",
       "compounding    0.043478\n",
       "existing       0.043478\n",
       "racial         0.043478\n",
       "economic       0.043478\n",
       "gender         0.043478\n",
       "biases         0.043478\n",
       ".              0.043478\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts / counts.sum()  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f1211",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310381be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['justice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e51ec",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "190c1ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['justice'] / counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc6bbd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512845b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algorithmic': 1,\n",
       " 'bias': 1,\n",
       " 'has': 1,\n",
       " 'been': 1,\n",
       " 'cited': 1,\n",
       " 'in': 1,\n",
       " 'cases': 1,\n",
       " 'ranging': 1,\n",
       " 'from': 1,\n",
       " 'election': 1,\n",
       " 'outcomes': 1,\n",
       " 'to': 1,\n",
       " 'the': 1,\n",
       " 'spread': 1,\n",
       " 'of': 1,\n",
       " 'online': 1,\n",
       " 'hate': 1,\n",
       " 'speech': 1,\n",
       " '.': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Algorithmic bias has been cited in cases ranging from \" \\\n",
    "    \"election outcomes to the spread of online hate speech.\"\n",
    "tokens = [tok.text for tok in nlp(sentence)]\n",
    "counts = Counter(tokens)\n",
    "dict(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ee9a1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f32523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithmic bias describes systematic and repeatable errors in a compu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpia2 import wikipedia as wiki\n",
    "page = wiki.page('Algorithmic Bias')  # <1>\n",
    "page.content[:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95842bd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1a78ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = ('https://gitlab.com/tangibleai/nlpia2/'\n",
    "       '-/raw/main/src/nlpia2/ch03/bias_intro.txt')\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a179ae",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb52da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithmic bias describes systematic and repeatable errors in a compu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_intro_bytes = response.content  # <1>\n",
    "bias_intro = response.text  # <2>\n",
    "assert bias_intro_bytes.decode() == bias_intro    # <3>\n",
    "bias_intro[:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c6d78",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dfeedd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({',': 35,\n",
       "         'of': 16,\n",
       "         '.': 16,\n",
       "         'to': 15,\n",
       "         'and': 14,\n",
       "         '\\n': 14,\n",
       "         'the': 13,\n",
       "         'or': 11,\n",
       "         'in': 10,\n",
       "         'can': 7,\n",
       "         'algorithms': 7,\n",
       "         'bias': 6,\n",
       "         'is': 6,\n",
       "         'a': 5,\n",
       "         'as': 5,\n",
       "         'not': 4,\n",
       "         '\"': 4,\n",
       "         'has': 4,\n",
       "         'their': 4,\n",
       "         'Algorithmic': 3,\n",
       "         'that': 3,\n",
       "         'outcomes': 3,\n",
       "         'many': 3,\n",
       "         'but': 3,\n",
       "         'design': 3,\n",
       "         'algorithm': 3,\n",
       "         'unanticipated': 3,\n",
       "         'data': 3,\n",
       "         'social': 3,\n",
       "         'from': 3,\n",
       "         'algorithmic': 3,\n",
       "         'been': 3,\n",
       "         'are': 3,\n",
       "         'cases': 3,\n",
       "         'systematic': 2,\n",
       "         'unfair': 2,\n",
       "         'such': 2,\n",
       "         'users': 2,\n",
       "         'Bias': 2,\n",
       "         'due': 2,\n",
       "         'including': 2,\n",
       "         'limited': 2,\n",
       "         'used': 2,\n",
       "         'platforms': 2,\n",
       "         'have': 2,\n",
       "         'ranging': 2,\n",
       "         'biases': 2,\n",
       "         'gender': 2,\n",
       "         'The': 2,\n",
       "         'concerned': 2,\n",
       "         'with': 2,\n",
       "         \"'s\": 2,\n",
       "         'become': 2,\n",
       "         '\\n\\n': 2,\n",
       "         'ways': 2,\n",
       "         'which': 2,\n",
       "         'output': 2,\n",
       "         'considered': 2,\n",
       "         'be': 2,\n",
       "         'human': 2,\n",
       "         'for': 2,\n",
       "         '-': 2,\n",
       "         'existing': 2,\n",
       "         ';': 2,\n",
       "         'by': 2,\n",
       "         'understanding': 2,\n",
       "         'even': 2,\n",
       "         'single': 2,\n",
       "         'describes': 1,\n",
       "         'repeatable': 1,\n",
       "         'errors': 1,\n",
       "         'computer': 1,\n",
       "         'system': 1,\n",
       "         'create': 1,\n",
       "         'privileging': 1,\n",
       "         'one': 1,\n",
       "         'arbitrary': 1,\n",
       "         'group': 1,\n",
       "         'over': 1,\n",
       "         'others': 1,\n",
       "         'emerge': 1,\n",
       "         'factors': 1,\n",
       "         'unintended': 1,\n",
       "         'use': 1,\n",
       "         'decisions': 1,\n",
       "         'relating': 1,\n",
       "         'way': 1,\n",
       "         'coded': 1,\n",
       "         'collected': 1,\n",
       "         'selected': 1,\n",
       "         'train': 1,\n",
       "         'found': 1,\n",
       "         'across': 1,\n",
       "         'search': 1,\n",
       "         'engine': 1,\n",
       "         'results': 1,\n",
       "         'media': 1,\n",
       "         'impacts': 1,\n",
       "         'inadvertent': 1,\n",
       "         'privacy': 1,\n",
       "         'violations': 1,\n",
       "         'reinforcing': 1,\n",
       "         'race': 1,\n",
       "         'sexuality': 1,\n",
       "         'ethnicity': 1,\n",
       "         'study': 1,\n",
       "         'most': 1,\n",
       "         'reflect': 1,\n",
       "         'discrimination': 1,\n",
       "         'This': 1,\n",
       "         'only': 1,\n",
       "         'recently': 1,\n",
       "         'addressed': 1,\n",
       "         'legal': 1,\n",
       "         'frameworks': 1,\n",
       "         '2018': 1,\n",
       "         'European': 1,\n",
       "         'Union': 1,\n",
       "         'General': 1,\n",
       "         'Data': 1,\n",
       "         'Protection': 1,\n",
       "         'Regulation': 1,\n",
       "         'More': 1,\n",
       "         'comprehensive': 1,\n",
       "         'regulation': 1,\n",
       "         'needed': 1,\n",
       "         'emerging': 1,\n",
       "         'technologies': 1,\n",
       "         'increasingly': 1,\n",
       "         'advanced': 1,\n",
       "         'opaque': 1,\n",
       "         'As': 1,\n",
       "         'expand': 1,\n",
       "         'ability': 1,\n",
       "         'organize': 1,\n",
       "         'society': 1,\n",
       "         'politics': 1,\n",
       "         'institutions': 1,\n",
       "         'behavior': 1,\n",
       "         'sociologists': 1,\n",
       "         'manipulation': 1,\n",
       "         'impact': 1,\n",
       "         'physical': 1,\n",
       "         'world': 1,\n",
       "         'Because': 1,\n",
       "         'often': 1,\n",
       "         'neutral': 1,\n",
       "         'unbiased': 1,\n",
       "         'they': 1,\n",
       "         'inaccurately': 1,\n",
       "         'project': 1,\n",
       "         'greater': 1,\n",
       "         'authority': 1,\n",
       "         'than': 1,\n",
       "         'expertise': 1,\n",
       "         'some': 1,\n",
       "         'reliance': 1,\n",
       "         'on': 1,\n",
       "         'displace': 1,\n",
       "         'responsibility': 1,\n",
       "         'enter': 1,\n",
       "         'into': 1,\n",
       "         'systems': 1,\n",
       "         'result': 1,\n",
       "         'pre': 1,\n",
       "         'cultural': 1,\n",
       "         'institutional': 1,\n",
       "         'expectations': 1,\n",
       "         'because': 1,\n",
       "         'technical': 1,\n",
       "         'limitations': 1,\n",
       "         'being': 1,\n",
       "         'contexts': 1,\n",
       "         'audiences': 1,\n",
       "         'who': 1,\n",
       "         'software': 1,\n",
       "         'initial': 1,\n",
       "         'cited': 1,\n",
       "         'election': 1,\n",
       "         'spread': 1,\n",
       "         'online': 1,\n",
       "         'hate': 1,\n",
       "         'speech': 1,\n",
       "         'It': 1,\n",
       "         'also': 1,\n",
       "         'arisen': 1,\n",
       "         'criminal': 1,\n",
       "         'justice': 1,\n",
       "         'healthcare': 1,\n",
       "         'hiring': 1,\n",
       "         'compounding': 1,\n",
       "         'racial': 1,\n",
       "         'economic': 1,\n",
       "         'relative': 1,\n",
       "         'inability': 1,\n",
       "         'facial': 1,\n",
       "         'recognition': 1,\n",
       "         'technology': 1,\n",
       "         'accurately': 1,\n",
       "         'identify': 1,\n",
       "         'darker': 1,\n",
       "         'skinned': 1,\n",
       "         'faces': 1,\n",
       "         'linked': 1,\n",
       "         'multiple': 1,\n",
       "         'wrongful': 1,\n",
       "         'arrests': 1,\n",
       "         'men': 1,\n",
       "         'color': 1,\n",
       "         'an': 1,\n",
       "         'issue': 1,\n",
       "         'stemming': 1,\n",
       "         'imbalanced': 1,\n",
       "         'datasets': 1,\n",
       "         'Problems': 1,\n",
       "         'researching': 1,\n",
       "         'discovering': 1,\n",
       "         'persist': 1,\n",
       "         'proprietary': 1,\n",
       "         'nature': 1,\n",
       "         'typically': 1,\n",
       "         'treated': 1,\n",
       "         'trade': 1,\n",
       "         'secrets': 1,\n",
       "         'Even': 1,\n",
       "         'when': 1,\n",
       "         'full': 1,\n",
       "         'transparency': 1,\n",
       "         'provided': 1,\n",
       "         'complexity': 1,\n",
       "         'certain': 1,\n",
       "         'poses': 1,\n",
       "         'barrier': 1,\n",
       "         'functioning': 1,\n",
       "         'Furthermore': 1,\n",
       "         'may': 1,\n",
       "         'change': 1,\n",
       "         'respond': 1,\n",
       "         'input': 1,\n",
       "         'anticipated': 1,\n",
       "         'easily': 1,\n",
       "         'reproduced': 1,\n",
       "         'analysis': 1,\n",
       "         'In': 1,\n",
       "         'within': 1,\n",
       "         'website': 1,\n",
       "         'application': 1,\n",
       "         'there': 1,\n",
       "         'no': 1,\n",
       "         'examine': 1,\n",
       "         'network': 1,\n",
       "         'interrelated': 1,\n",
       "         'programs': 1,\n",
       "         'inputs': 1,\n",
       "         'between': 1,\n",
       "         'same': 1,\n",
       "         'service': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [tok.text for tok in nlp(bias_intro)]\n",
    "counts = Counter(tokens)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d94a7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1fbfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 35), ('of', 16), ('.', 16), ('to', 15), ('and', 14)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a73db6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a49944e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inputs', 1), ('between', 1), ('same', 1), ('service', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common()[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60c192",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61e3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [nlp(s) for s in bias_intro.split('\\n')\n",
    "        if s.strip()]  # <1>\n",
    "counts = []\n",
    "for doc in docs:\n",
    "    counts.append(Counter([\n",
    "        t.text.lower() for t in doc]))  # <2>\n",
    "df = pd.DataFrame(counts)\n",
    "df = df.fillna(0).astype(int)  # <3>\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b36e6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d55bb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithmic</th>\n",
       "      <th>bias</th>\n",
       "      <th>describes</th>\n",
       "      <th>systematic</th>\n",
       "      <th>and</th>\n",
       "      <th>repeatable</th>\n",
       "      <th>errors</th>\n",
       "      <th>in</th>\n",
       "      <th>a</th>\n",
       "      <th>computer</th>\n",
       "      <th>...</th>\n",
       "      <th>there</th>\n",
       "      <th>no</th>\n",
       "      <th>examine</th>\n",
       "      <th>network</th>\n",
       "      <th>interrelated</th>\n",
       "      <th>programs</th>\n",
       "      <th>inputs</th>\n",
       "      <th>between</th>\n",
       "      <th>same</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithmic  bias  describes  systematic  and  repeatable  errors  in  a  \\\n",
       "0            1     1          1           1    1           1       1   1  1   \n",
       "1            0     1          0           0    0           0       0   0  0   \n",
       "2            1     1          0           0    3           0       0   0  0   \n",
       "3            1     1          0           1    1           0       0   0  0   \n",
       "4            0     1          0           0    0           0       0   1  0   \n",
       "\n",
       "   computer  ...  there  no  examine  network  interrelated  programs  inputs  \\\n",
       "0         1  ...      0   0        0        0             0         0       0   \n",
       "1         0  ...      0   0        0        0             0         0       0   \n",
       "2         0  ...      0   0        0        0             0         0       0   \n",
       "3         0  ...      0   0        0        0             0         0       0   \n",
       "4         0  ...      0   0        0        0             0         0       0   \n",
       "\n",
       "   between  same  service  \n",
       "0        0     0        0  \n",
       "1        0     0        0  \n",
       "2        0     0        0  \n",
       "3        0     0        0  \n",
       "4        0     0        0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501537a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120d6bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithmic    0\n",
       "bias           0\n",
       "describes      0\n",
       "systematic     0\n",
       "and            2\n",
       "              ..\n",
       "programs       0\n",
       "inputs         0\n",
       "between        0\n",
       "same           0\n",
       "service        0\n",
       "Name: 10, Length: 246, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10]  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dd1d3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8c2e868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokens = []\n",
    "for doc in docs:\n",
    "    docs_tokens.append([\n",
    "        tok.text.lower() for tok in nlp(doc.text)])  # <1>\n",
    "len(docs_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23b426",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db9ebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_tokens = []\n",
    "for tokens in docs_tokens:\n",
    "    all_doc_tokens.extend(tokens)\n",
    "len(all_doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306154a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37d20cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(all_doc_tokens)  # <1>\n",
    "vocab = sorted(vocab)  # <2>\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66002869",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61c0bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"</th>\n",
       "      <th>'s</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>.</th>\n",
       "      <th>2018</th>\n",
       "      <th>;</th>\n",
       "      <th>a</th>\n",
       "      <th>ability</th>\n",
       "      <th>accurately</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>ways</th>\n",
       "      <th>website</th>\n",
       "      <th>when</th>\n",
       "      <th>which</th>\n",
       "      <th>who</th>\n",
       "      <th>with</th>\n",
       "      <th>within</th>\n",
       "      <th>world</th>\n",
       "      <th>wrongful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    \"  's  ,  -  .  2018  ;  a  ability  accurately  ...  way  ways  website  \\\n",
       "0   0   0  1  0  1     0  0  1        0           0  ...    0     0        0   \n",
       "1   0   0  3  0  1     0  0  0        0           0  ...    1     0        0   \n",
       "2   0   0  5  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "3   2   0  0  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "4   0   1  1  0  1     1  0  0        0           0  ...    0     0        0   \n",
       "5   0   0  0  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "6   0   0  4  0  1     0  0  0        1           0  ...    0     1        0   \n",
       "7   0   0  3  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "8   0   1  2  1  1     0  2  1        0           0  ...    0     0        0   \n",
       "9   0   0  0  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "10  0   0  5  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "11  0   0  1  1  1     0  0  0        0           1  ...    0     0        0   \n",
       "12  0   0  3  0  1     0  0  0        0           0  ...    0     0        0   \n",
       "13  0   0  1  0  1     0  0  1        0           0  ...    0     0        0   \n",
       "14  0   0  2  0  1     0  0  0        0           0  ...    0     1        0   \n",
       "15  2   0  4  0  1     0  0  2        0           0  ...    0     0        1   \n",
       "\n",
       "    when  which  who  with  within  world  wrongful  \n",
       "0      0      0    0     0       0      0         0  \n",
       "1      0      0    0     0       0      0         0  \n",
       "2      0      0    0     0       0      0         0  \n",
       "3      0      0    0     1       0      0         0  \n",
       "4      0      0    0     0       0      0         0  \n",
       "5      0      0    0     0       0      0         0  \n",
       "6      0      1    0     1       0      1         0  \n",
       "7      0      0    0     0       0      0         0  \n",
       "8      0      0    1     0       0      0         0  \n",
       "9      0      0    0     0       0      0         0  \n",
       "10     0      0    0     0       0      0         0  \n",
       "11     0      0    0     0       0      0         1  \n",
       "12     0      1    0     0       0      0         0  \n",
       "13     1      0    0     0       0      0         0  \n",
       "14     0      0    0     0       0      0         0  \n",
       "15     0      0    0     0       1      0         0  \n",
       "\n",
       "[16 rows x 246 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors = []\n",
    "for tokens in docs_tokens:\n",
    "    count_vectors.append(Counter(tokens))\n",
    "tf = pd.DataFrame(count_vectors)  # <1>\n",
    "tf = tf.T.sort_index().T\n",
    "tf = tf.fillna(0).astype(int)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232dcd10",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9212eb9-8305-41d2-9857-62cf7b0d8a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (0, 0), (1, 1), (1, 1), (0, 0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df['algorithmic'], tf['algorithmic']))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de7304e1-38f4-49b2-b91b-ff714a458897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(df['algorithmic'] == tf['algorithmic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09290472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "v1 = np.array(list(range(5)))\n",
    "v2 = pd.Series(reversed(range(5)))\n",
    "slow_answer = sum([4.2 * (x1 * x2) for x1, x2 in zip(v1, v2)])\n",
    "slow_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ea218",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cd87c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_answer = sum(4.2 * v1 * v2)  # <1>\n",
    "faster_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a149c46",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2148b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastest_answer = 4.2 * v1.dot(v2)  # <2>\n",
    "fastest_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a181790",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cbbdb99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241m.\u001b[39mdot(B) \u001b[38;5;241m==\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(A) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(B)) \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m      2\u001b[0m     np\u001b[38;5;241m.\u001b[39mcos(angle_between_A_and_B)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "A.dot(B) == (np.linalg.norm(A) * np.linalg.norm(B)) * \\\n",
    "    np.cos(angle_between_A_and_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13faa7ce",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d787599c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1830320268.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cos_similarity_between_A_and_B = np.cos(angle_between_A_and_B) \\\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "cos_similarity_between_A_and_B = np.cos(angle_between_A_and_B) \\\n",
    "   = A.dot(B) / (np.linalg.norm(A) * np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d397402",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc162e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = list(vec1.values())  # <1>\n",
    "    vec2 = list(vec2.values())\n",
    "\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "\n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904514c",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64fd8e9b-83de-4fb6-a61e-280b00243e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan,  3., nan,  1., nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         2., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan,\n",
       "         1., nan,  1., nan, nan, nan, nan,  1.,  1., nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan,  1., nan,  1., nan,  1.,\n",
       "        nan, nan, nan,  1., nan, nan, nan,  1., nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan,  1., nan, nan, nan, nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         1.,  1., nan, nan, nan, nan, nan, nan,  4., nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan,  5., nan, nan, nan, nan,  4.,\n",
       "        nan,  1., nan, nan, nan,  1., nan, nan, nan,  1., nan,  1.,  1.,\n",
       "        nan, nan,  1., nan, nan, nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectors[1].values())\n",
    "tf.values[1:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5c4575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11785113019775792"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vec1 = tf.values[:1,:]  # <1>\n",
    "vec2 = tf.values[1:2,:]\n",
    "cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550444b1",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c31f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "question = \"What is algorithmic bias?\"\n",
    "ngram_docs = copy.copy(docs)\n",
    "ngram_docs.append(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f1be9",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39dd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec = vectorizer.transform([new_sentence])\n",
    "question_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dedf12",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec.to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be1df8",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a11c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in\n",
    "    vectorizer.vocabulary_.items())))[1]\n",
    "pd.Series(question_vec.to_array()[0], index=vocab).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaac0bf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(count_vectors, question_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aad812",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97865289",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784c36e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "ngram_vectors = ngram_vectorizer.fit_transform(corpus)\n",
    "ngram_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d84b37",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in\n",
    "    ngram_vectorizer.vocabulary_.items())))[1]\n",
    "pd.DataFrame(ngram_vectors.toarray(),\n",
    "    columns=vocab)['algorithmic bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00cdfc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e760485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from this import s\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08304939",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1,1), analyzer='char')  # <1>\n",
    "s_char_frequencies = char_vectorizer.fit_transform(s)\n",
    "generate_histogram(\n",
    "    s_char_frequencies, s_char_vectorizer)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981d807",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49589946",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n",
    "            '-/raw/master/src/nlpia/data')\n",
    "url = DATA_DIR + '/machine_learning_full_article.txt'\n",
    "ml_text = requests.get(url).content.decode()\n",
    "ml_char_frequencies = char_vectorizer.fit_transform(ml_text)\n",
    "generate_histogram(s_char_frequencies, s_char_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c722b48",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord('W') - peak_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6728332",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afca1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "print(codecs.decode(s, 'rot-13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07266698",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown')  # <1>\n",
    "from nltk.corpus import brown\n",
    "brown.words()[:10]  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8f270",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff831fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.tagged_words()[:5]  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975e61d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cead20a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "puncs = set((',', '.', '--', '-', '!', '?',\n",
    "    ':', ';', '``', \"''\", '(', ')', '[', ']'))\n",
    "word_list = (x.lower() for x in brown.words() if x not in puncs)\n",
    "token_counts = Counter(word_list)\n",
    "token_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6483cf8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4262e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n",
    "            '-/raw/master/src/nlpia/data')\n",
    "url = DATA_DIR + '/bias_discrimination.txt'\n",
    "bias_discrimination = requests.get(url).content.decode()\n",
    "intro_tokens = [token.text for token in nlp(bias_intro.lower())]\n",
    "disc_tokens = [token.text for token in nlp(bias_discrimination.lower())]\n",
    "intro_total = len(intro_tokens)\n",
    "intro_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580ac3c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_total = len (disc_tokens)\n",
    "disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc622bec",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf = {}\n",
    "disc_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['bias'] = intro_counts['bias'] / intro_total\n",
    "disc_counts = Counter(disc_tokens)\n",
    "disc_tf['bias'] = disc_counts['bias'] / disc_total\n",
    "'Term Frequency of \"bias\" in intro is:{:.4f}'.format(intro_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1689d9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292eea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Term Frequency of \"bias\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b4965",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8291c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['and'] = intro_counts['and'] / intro_total\n",
    "disc_tf['and'] = disc_counts['and'] / disc_total\n",
    "print('Term Frequency of \"and\" in intro is: {:.4f}'\\\n",
    "    .format(intro_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f74d6f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12528819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Term Frequency of \"and\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a58d59",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a307bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_and = 0\n",
    "for doc in [intro_tokens, disc_tokens]:\n",
    "    if 'and' in doc:\n",
    "        num_docs_containing_and += 1  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140001d9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['black'] = intro_counts['black'] / intro_total\n",
    "disc_tf['black'] = disc_counts['black'] / disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85716247",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 2\n",
    "intro_idf = {}\n",
    "disc_idf = {}\n",
    "intro_idf['and'] = num_docs / num_docs_containing_and\n",
    "disc_idf['and'] = num_docs / num_docs_containing_and\n",
    "intro_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "disc_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "intro_idf['black'] = num_docs / num_docs_containing_black\n",
    "disc_idf['black'] = num_docs / num_docs_containing_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc29150",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tfidf = {}\n",
    "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
    "intro_tfidf['bias'] = intro_tf['bias'] * intro_idf['bias']\n",
    "intro_tfidf['black'] = intro_tf['black'] * intro_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a18d17",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_tfidf = {}\n",
    "disc_tfidf['and'] = disc_tf['and'] * disc_idf['and']\n",
    "disc_tfidf['bias'] = disc_tf['bias'] * disc_idf['bias']\n",
    "disc_tfidf['black'] = disc_tf['black'] * disc_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7727a1b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tfidf_vectors = []\n",
    "for doc in docs:  # <1>\n",
    "    vec = copy.copy(zero_vector)  # <2>\n",
    "    tokens = [token.text for token in nlp(doc.lower())]\n",
    "    token_counts = Counter(tokens)\n",
    "\n",
    "    for token, count in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for d in docs:\n",
    "            if token in d:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(vocab)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf\n",
    "    doc_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812db7c7",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(zero_vector)  # <1>\n",
    "tokens = [token.text for token in nlp(query.lower())]\n",
    "token_counts = Counter(tokens)\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for _doc in docs:\n",
    "      if key in _doc.lower():\n",
    "        docs_containing_key += 1\n",
    "    if docs_containing_key == 0:  # <1>\n",
    "        continue\n",
    "    tf = value / len(tokens)\n",
    "    idf = len(docs) / docs_containing_key\n",
    "    query_vec[key] = tf * idf\n",
    "cosine_sim(query_vec, doc_tfidf_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d73f04",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim(query_vec, doc_tfidf_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9164313d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim(query_vec, doc_tfidf_vectors[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033fd5c",
   "metadata": {},
   "source": [
    "#### .Computing TF-IDF matrix using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = docs\n",
    "vectorizer = TfidfVectorizer(min_df=1) # <1>\n",
    "vectorizer = vectorizer.fit(corpus)  # <2>\n",
    "vectors = vectorizer.transform(corpus)  # <3>\n",
    "print(vectors.todense().round(2))  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9fa1d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958659a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_FAQ_URL = ('https://gitlab.com/tangibleai/qary/-/raw/main/'\n",
    "    'src/qary/data/faq/faq-python-data-science-cleaned.csv')\n",
    "qa_dataset = pd.read_csv(DS_FAQ_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d544b2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3de0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['question'])\n",
    "tfidfvectors_sparse = vectorizer.transform(df['question'])  # <1>\n",
    "tfidfvectors = tfidfvectors_sparse.todense()  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407204e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0970bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_reply(question):\n",
    "   question_vector = vectorizer.transform([question]).todense()\n",
    "   idx = question_vector.dot(tfidfvectors.T).argmax() # <1>\n",
    "\n",
    "   print(\n",
    "       f\"Your question:\\n  {question}\\n\\n\"\n",
    "       f\"Most similar FAQ question:\\n  {df['question'][idx]}\\n\\n\"\n",
    "       f\"Answer to that FAQ question:\\n  {df['answer'][idx]}\\n\\n\"\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9bb2b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_reply(\"What's overfitting a model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e2a69",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_reply('How do I decrease overfitting for Logistic Regression?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
