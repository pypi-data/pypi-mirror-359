{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0798231f",
   "metadata": {},
   "source": [
    "#### [`Chapter-03_Math-with-Words-TF-IDF-Vectors`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-03_Math-with-Words-TF-IDF-Vectors.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778ba7d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10b8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m209.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.25.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'has',\n",
       " 'also',\n",
       " 'arisen',\n",
       " 'in',\n",
       " 'criminal',\n",
       " 'justice',\n",
       " ',',\n",
       " 'healthcare',\n",
       " ',',\n",
       " 'and',\n",
       " 'hiring',\n",
       " ',',\n",
       " 'compounding',\n",
       " 'existing',\n",
       " 'racial',\n",
       " ',',\n",
       " 'economic',\n",
       " ',',\n",
       " 'and',\n",
       " 'gender',\n",
       " 'biases',\n",
       " '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = ('It has also arisen in criminal justice, healthcare, and '\n",
    "    'hiring, compounding existing racial, economic, and gender biases.')\n",
    "doc = nlp(sentence)\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fd946",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7021754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({',': 5,\n",
       "         'and': 2,\n",
       "         'It': 1,\n",
       "         'has': 1,\n",
       "         'also': 1,\n",
       "         'arisen': 1,\n",
       "         'in': 1,\n",
       "         'criminal': 1,\n",
       "         'justice': 1,\n",
       "         'healthcare': 1,\n",
       "         'hiring': 1,\n",
       "         'compounding': 1,\n",
       "         'existing': 1,\n",
       "         'racial': 1,\n",
       "         'economic': 1,\n",
       "         'gender': 1,\n",
       "         'biases': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005c1dc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49f4ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 5), ('and', 2), ('It', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.most_common(3)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb657c8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5290b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",              5\n",
       "and            2\n",
       "It             1\n",
       "has            1\n",
       "also           1\n",
       "arisen         1\n",
       "in             1\n",
       "criminal       1\n",
       "justice        1\n",
       "healthcare     1\n",
       "hiring         1\n",
       "compounding    1\n",
       "existing       1\n",
       "racial         1\n",
       "economic       1\n",
       "gender         1\n",
       "biases         1\n",
       ".              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "most_common = dict(bag_of_words.most_common())  # <1>\n",
    "counts = pd.Series(most_common)  # <2>\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a7e76",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372ca353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d79aa",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98eb2e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c003368",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597349fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0746ec8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdad72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",              0.217391\n",
       "and            0.086957\n",
       "It             0.043478\n",
       "has            0.043478\n",
       "also           0.043478\n",
       "arisen         0.043478\n",
       "in             0.043478\n",
       "criminal       0.043478\n",
       "justice        0.043478\n",
       "healthcare     0.043478\n",
       "hiring         0.043478\n",
       "compounding    0.043478\n",
       "existing       0.043478\n",
       "racial         0.043478\n",
       "economic       0.043478\n",
       "gender         0.043478\n",
       "biases         0.043478\n",
       ".              0.043478\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts / counts.sum()  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67427128",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106db4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['justice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c7e03",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b9e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts['justice'] / counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d8334",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38913b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algorithmic': 1,\n",
       " 'bias': 1,\n",
       " 'has': 1,\n",
       " 'been': 1,\n",
       " 'cited': 1,\n",
       " 'in': 1,\n",
       " 'cases': 1,\n",
       " 'ranging': 1,\n",
       " 'from': 1,\n",
       " 'election': 1,\n",
       " 'outcomes': 1,\n",
       " 'to': 1,\n",
       " 'the': 1,\n",
       " 'spread': 1,\n",
       " 'of': 1,\n",
       " 'online': 1,\n",
       " 'hate': 1,\n",
       " 'speech': 1,\n",
       " '.': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Algorithmic bias has been cited in cases ranging from \" \\\n",
    "    \"election outcomes to the spread of online hate speech.\"\n",
    "tokens = [tok.text for tok in nlp(sentence)]\n",
    "counts = Counter(tokens)\n",
    "dict(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a8217",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73535048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = ('https://gitlab.com/tangibleai/nlpia2/'\n",
    "       '-/raw/main/src/nlpia2/ch03/bias_intro.txt')\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae03cf",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d52737a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithmic bias describes systematic and repeatable errors in a compu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_intro_bytes = response.content  # <1>\n",
    "bias_intro = response.text  # <2>\n",
    "assert bias_intro_bytes.decode() == bias_intro    # <3>\n",
    "bias_intro[:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca913b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e4e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({',': 35,\n",
       "         'of': 16,\n",
       "         '.': 16,\n",
       "         'to': 15,\n",
       "         'and': 14,\n",
       "         '\\n': 14,\n",
       "         'the': 13,\n",
       "         'or': 11,\n",
       "         'in': 10,\n",
       "         'can': 7,\n",
       "         'algorithms': 7,\n",
       "         'bias': 6,\n",
       "         'is': 6,\n",
       "         'a': 5,\n",
       "         'as': 5,\n",
       "         'not': 4,\n",
       "         '\"': 4,\n",
       "         'has': 4,\n",
       "         'their': 4,\n",
       "         'Algorithmic': 3,\n",
       "         'that': 3,\n",
       "         'outcomes': 3,\n",
       "         'many': 3,\n",
       "         'but': 3,\n",
       "         'design': 3,\n",
       "         'algorithm': 3,\n",
       "         'unanticipated': 3,\n",
       "         'data': 3,\n",
       "         'social': 3,\n",
       "         'from': 3,\n",
       "         'algorithmic': 3,\n",
       "         'been': 3,\n",
       "         'are': 3,\n",
       "         'cases': 3,\n",
       "         'systematic': 2,\n",
       "         'unfair': 2,\n",
       "         'such': 2,\n",
       "         'users': 2,\n",
       "         'Bias': 2,\n",
       "         'due': 2,\n",
       "         'including': 2,\n",
       "         'limited': 2,\n",
       "         'used': 2,\n",
       "         'platforms': 2,\n",
       "         'have': 2,\n",
       "         'ranging': 2,\n",
       "         'biases': 2,\n",
       "         'gender': 2,\n",
       "         'The': 2,\n",
       "         'concerned': 2,\n",
       "         'with': 2,\n",
       "         \"'s\": 2,\n",
       "         'become': 2,\n",
       "         '\\n\\n': 2,\n",
       "         'ways': 2,\n",
       "         'which': 2,\n",
       "         'output': 2,\n",
       "         'considered': 2,\n",
       "         'be': 2,\n",
       "         'human': 2,\n",
       "         'for': 2,\n",
       "         '-': 2,\n",
       "         'existing': 2,\n",
       "         ';': 2,\n",
       "         'by': 2,\n",
       "         'understanding': 2,\n",
       "         'even': 2,\n",
       "         'single': 2,\n",
       "         'describes': 1,\n",
       "         'repeatable': 1,\n",
       "         'errors': 1,\n",
       "         'computer': 1,\n",
       "         'system': 1,\n",
       "         'create': 1,\n",
       "         'privileging': 1,\n",
       "         'one': 1,\n",
       "         'arbitrary': 1,\n",
       "         'group': 1,\n",
       "         'over': 1,\n",
       "         'others': 1,\n",
       "         'emerge': 1,\n",
       "         'factors': 1,\n",
       "         'unintended': 1,\n",
       "         'use': 1,\n",
       "         'decisions': 1,\n",
       "         'relating': 1,\n",
       "         'way': 1,\n",
       "         'coded': 1,\n",
       "         'collected': 1,\n",
       "         'selected': 1,\n",
       "         'train': 1,\n",
       "         'found': 1,\n",
       "         'across': 1,\n",
       "         'search': 1,\n",
       "         'engine': 1,\n",
       "         'results': 1,\n",
       "         'media': 1,\n",
       "         'impacts': 1,\n",
       "         'inadvertent': 1,\n",
       "         'privacy': 1,\n",
       "         'violations': 1,\n",
       "         'reinforcing': 1,\n",
       "         'race': 1,\n",
       "         'sexuality': 1,\n",
       "         'ethnicity': 1,\n",
       "         'study': 1,\n",
       "         'most': 1,\n",
       "         'reflect': 1,\n",
       "         'discrimination': 1,\n",
       "         'This': 1,\n",
       "         'only': 1,\n",
       "         'recently': 1,\n",
       "         'addressed': 1,\n",
       "         'legal': 1,\n",
       "         'frameworks': 1,\n",
       "         '2018': 1,\n",
       "         'European': 1,\n",
       "         'Union': 1,\n",
       "         'General': 1,\n",
       "         'Data': 1,\n",
       "         'Protection': 1,\n",
       "         'Regulation': 1,\n",
       "         'More': 1,\n",
       "         'comprehensive': 1,\n",
       "         'regulation': 1,\n",
       "         'needed': 1,\n",
       "         'emerging': 1,\n",
       "         'technologies': 1,\n",
       "         'increasingly': 1,\n",
       "         'advanced': 1,\n",
       "         'opaque': 1,\n",
       "         'As': 1,\n",
       "         'expand': 1,\n",
       "         'ability': 1,\n",
       "         'organize': 1,\n",
       "         'society': 1,\n",
       "         'politics': 1,\n",
       "         'institutions': 1,\n",
       "         'behavior': 1,\n",
       "         'sociologists': 1,\n",
       "         'manipulation': 1,\n",
       "         'impact': 1,\n",
       "         'physical': 1,\n",
       "         'world': 1,\n",
       "         'Because': 1,\n",
       "         'often': 1,\n",
       "         'neutral': 1,\n",
       "         'unbiased': 1,\n",
       "         'they': 1,\n",
       "         'inaccurately': 1,\n",
       "         'project': 1,\n",
       "         'greater': 1,\n",
       "         'authority': 1,\n",
       "         'than': 1,\n",
       "         'expertise': 1,\n",
       "         'some': 1,\n",
       "         'reliance': 1,\n",
       "         'on': 1,\n",
       "         'displace': 1,\n",
       "         'responsibility': 1,\n",
       "         'enter': 1,\n",
       "         'into': 1,\n",
       "         'systems': 1,\n",
       "         'result': 1,\n",
       "         'pre': 1,\n",
       "         'cultural': 1,\n",
       "         'institutional': 1,\n",
       "         'expectations': 1,\n",
       "         'because': 1,\n",
       "         'technical': 1,\n",
       "         'limitations': 1,\n",
       "         'being': 1,\n",
       "         'contexts': 1,\n",
       "         'audiences': 1,\n",
       "         'who': 1,\n",
       "         'software': 1,\n",
       "         'initial': 1,\n",
       "         'cited': 1,\n",
       "         'election': 1,\n",
       "         'spread': 1,\n",
       "         'online': 1,\n",
       "         'hate': 1,\n",
       "         'speech': 1,\n",
       "         'It': 1,\n",
       "         'also': 1,\n",
       "         'arisen': 1,\n",
       "         'criminal': 1,\n",
       "         'justice': 1,\n",
       "         'healthcare': 1,\n",
       "         'hiring': 1,\n",
       "         'compounding': 1,\n",
       "         'racial': 1,\n",
       "         'economic': 1,\n",
       "         'relative': 1,\n",
       "         'inability': 1,\n",
       "         'facial': 1,\n",
       "         'recognition': 1,\n",
       "         'technology': 1,\n",
       "         'accurately': 1,\n",
       "         'identify': 1,\n",
       "         'darker': 1,\n",
       "         'skinned': 1,\n",
       "         'faces': 1,\n",
       "         'linked': 1,\n",
       "         'multiple': 1,\n",
       "         'wrongful': 1,\n",
       "         'arrests': 1,\n",
       "         'men': 1,\n",
       "         'color': 1,\n",
       "         'an': 1,\n",
       "         'issue': 1,\n",
       "         'stemming': 1,\n",
       "         'imbalanced': 1,\n",
       "         'datasets': 1,\n",
       "         'Problems': 1,\n",
       "         'researching': 1,\n",
       "         'discovering': 1,\n",
       "         'persist': 1,\n",
       "         'proprietary': 1,\n",
       "         'nature': 1,\n",
       "         'typically': 1,\n",
       "         'treated': 1,\n",
       "         'trade': 1,\n",
       "         'secrets': 1,\n",
       "         'Even': 1,\n",
       "         'when': 1,\n",
       "         'full': 1,\n",
       "         'transparency': 1,\n",
       "         'provided': 1,\n",
       "         'complexity': 1,\n",
       "         'certain': 1,\n",
       "         'poses': 1,\n",
       "         'barrier': 1,\n",
       "         'functioning': 1,\n",
       "         'Furthermore': 1,\n",
       "         'may': 1,\n",
       "         'change': 1,\n",
       "         'respond': 1,\n",
       "         'input': 1,\n",
       "         'anticipated': 1,\n",
       "         'easily': 1,\n",
       "         'reproduced': 1,\n",
       "         'analysis': 1,\n",
       "         'In': 1,\n",
       "         'within': 1,\n",
       "         'website': 1,\n",
       "         'application': 1,\n",
       "         'there': 1,\n",
       "         'no': 1,\n",
       "         'examine': 1,\n",
       "         'network': 1,\n",
       "         'interrelated': 1,\n",
       "         'programs': 1,\n",
       "         'inputs': 1,\n",
       "         'between': 1,\n",
       "         'same': 1,\n",
       "         'service': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [tok.text for tok in nlp(bias_intro)]\n",
    "counts = Counter(tokens)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23718d88",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "460b3c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 35), ('of', 16), ('.', 16), ('to', 15), ('and', 14)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d581e9f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db30b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inputs', 1), ('between', 1), ('same', 1), ('service', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common()[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba934b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40104f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [nlp(s) for s in bias_intro.split('\\n')\n",
    "        if s.strip()]  # <1>\n",
    "counts = []\n",
    "for doc in docs:\n",
    "    counts.append(Counter([\n",
    "        t.text.lower() for t in doc]))  # <2>\n",
    "df = pd.DataFrame(counts)\n",
    "df = df.fillna(0).astype(int)  # <3>\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b4287",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e72eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithmic</th>\n",
       "      <th>bias</th>\n",
       "      <th>describes</th>\n",
       "      <th>systematic</th>\n",
       "      <th>and</th>\n",
       "      <th>repeatable</th>\n",
       "      <th>errors</th>\n",
       "      <th>in</th>\n",
       "      <th>a</th>\n",
       "      <th>computer</th>\n",
       "      <th>...</th>\n",
       "      <th>there</th>\n",
       "      <th>no</th>\n",
       "      <th>examine</th>\n",
       "      <th>network</th>\n",
       "      <th>interrelated</th>\n",
       "      <th>programs</th>\n",
       "      <th>inputs</th>\n",
       "      <th>between</th>\n",
       "      <th>same</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithmic  bias  describes  systematic  and  repeatable  errors  in  a  \\\n",
       "0            1     1          1           1    1           1       1   1  1   \n",
       "1            0     1          0           0    0           0       0   0  0   \n",
       "2            1     1          0           0    3           0       0   0  0   \n",
       "3            1     1          0           1    1           0       0   0  0   \n",
       "4            0     1          0           0    0           0       0   1  0   \n",
       "\n",
       "   computer  ...  there  no  examine  network  interrelated  programs  inputs  \\\n",
       "0         1  ...      0   0        0        0             0         0       0   \n",
       "1         0  ...      0   0        0        0             0         0       0   \n",
       "2         0  ...      0   0        0        0             0         0       0   \n",
       "3         0  ...      0   0        0        0             0         0       0   \n",
       "4         0  ...      0   0        0        0             0         0       0   \n",
       "\n",
       "   between  same  service  \n",
       "0        0     0        0  \n",
       "1        0     0        0  \n",
       "2        0     0        0  \n",
       "3        0     0        0  \n",
       "4        0     0        0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0ba86",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd35cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithmic    0\n",
       "bias           0\n",
       "describes      0\n",
       "systematic     0\n",
       "and            2\n",
       "              ..\n",
       "programs       0\n",
       "inputs         0\n",
       "between        0\n",
       "same           0\n",
       "service        0\n",
       "Name: 10, Length: 246, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10]  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da462d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4961e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokens = []\n",
    "for doc in docs:\n",
    "    docs_tokens.append([\n",
    "        tok.text.lower() for tok in nlp(doc.text)])  # <1>\n",
    "len(docs_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3d59",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57794878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_doc_tokens = []\n",
    "for tokens in docs_tokens:\n",
    "    all_doc_tokens.extend(tokens)\n",
    "len(all_doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64111ac",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13165608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(  # <1>\n",
    "    set(all_doc_tokens))  # <2>\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39846d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3178113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9593495934959348"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_doc_tokens) / len(vocab)  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705049d8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a489e368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " \"'s\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '2018',\n",
       " ';',\n",
       " 'a',\n",
       " 'ability',\n",
       " 'accurately',\n",
       " 'across',\n",
       " 'addressed',\n",
       " 'advanced',\n",
       " 'algorithm',\n",
       " 'algorithmic',\n",
       " 'algorithms',\n",
       " 'also',\n",
       " 'an',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'anticipated',\n",
       " 'application',\n",
       " 'arbitrary',\n",
       " 'are',\n",
       " 'arisen',\n",
       " 'arrests',\n",
       " 'as',\n",
       " 'audiences',\n",
       " 'authority',\n",
       " 'barrier',\n",
       " 'be',\n",
       " 'because',\n",
       " 'become',\n",
       " 'been',\n",
       " 'behavior',\n",
       " 'being',\n",
       " 'between',\n",
       " 'bias',\n",
       " 'biases',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'cases',\n",
       " 'certain',\n",
       " 'change',\n",
       " 'cited',\n",
       " 'coded',\n",
       " 'collected',\n",
       " 'color',\n",
       " 'complexity',\n",
       " 'compounding',\n",
       " 'comprehensive',\n",
       " 'computer',\n",
       " 'concerned',\n",
       " 'considered',\n",
       " 'contexts',\n",
       " 'create',\n",
       " 'criminal',\n",
       " 'cultural',\n",
       " 'darker',\n",
       " 'data',\n",
       " 'datasets',\n",
       " 'decisions',\n",
       " 'describes',\n",
       " 'design',\n",
       " 'discovering',\n",
       " 'discrimination',\n",
       " 'displace',\n",
       " 'due',\n",
       " 'easily',\n",
       " 'economic',\n",
       " 'election',\n",
       " 'emerge',\n",
       " 'emerging',\n",
       " 'engine',\n",
       " 'enter',\n",
       " 'errors',\n",
       " 'ethnicity',\n",
       " 'european',\n",
       " 'even',\n",
       " 'examine',\n",
       " 'existing',\n",
       " 'expand',\n",
       " 'expectations',\n",
       " 'expertise',\n",
       " 'faces',\n",
       " 'facial',\n",
       " 'factors',\n",
       " 'for',\n",
       " 'found',\n",
       " 'frameworks',\n",
       " 'from',\n",
       " 'full',\n",
       " 'functioning',\n",
       " 'furthermore',\n",
       " 'gender',\n",
       " 'general',\n",
       " 'greater',\n",
       " 'group',\n",
       " 'has',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'healthcare',\n",
       " 'hiring',\n",
       " 'human',\n",
       " 'identify',\n",
       " 'imbalanced',\n",
       " 'impact',\n",
       " 'impacts',\n",
       " 'in',\n",
       " 'inability',\n",
       " 'inaccurately',\n",
       " 'inadvertent',\n",
       " 'including',\n",
       " 'increasingly',\n",
       " 'initial',\n",
       " 'input',\n",
       " 'inputs',\n",
       " 'institutional',\n",
       " 'institutions',\n",
       " 'interrelated',\n",
       " 'into',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'justice',\n",
       " 'legal',\n",
       " 'limitations',\n",
       " 'limited',\n",
       " 'linked',\n",
       " 'manipulation',\n",
       " 'many',\n",
       " 'may',\n",
       " 'media',\n",
       " 'men',\n",
       " 'more',\n",
       " 'most',\n",
       " 'multiple',\n",
       " 'nature',\n",
       " 'needed',\n",
       " 'network',\n",
       " 'neutral',\n",
       " 'no',\n",
       " 'not',\n",
       " 'of',\n",
       " 'often',\n",
       " 'on',\n",
       " 'one',\n",
       " 'online',\n",
       " 'only',\n",
       " 'opaque',\n",
       " 'or',\n",
       " 'organize',\n",
       " 'others',\n",
       " 'outcomes',\n",
       " 'output',\n",
       " 'over',\n",
       " 'persist',\n",
       " 'physical',\n",
       " 'platforms',\n",
       " 'politics',\n",
       " 'poses',\n",
       " 'pre',\n",
       " 'privacy',\n",
       " 'privileging',\n",
       " 'problems',\n",
       " 'programs',\n",
       " 'project',\n",
       " 'proprietary',\n",
       " 'protection',\n",
       " 'provided',\n",
       " 'race',\n",
       " 'racial',\n",
       " 'ranging',\n",
       " 'recently',\n",
       " 'recognition',\n",
       " 'reflect',\n",
       " 'regulation',\n",
       " 'reinforcing',\n",
       " 'relating',\n",
       " 'relative',\n",
       " 'reliance',\n",
       " 'repeatable',\n",
       " 'reproduced',\n",
       " 'researching',\n",
       " 'respond',\n",
       " 'responsibility',\n",
       " 'result',\n",
       " 'results',\n",
       " 'same',\n",
       " 'search',\n",
       " 'secrets',\n",
       " 'selected',\n",
       " 'service',\n",
       " 'sexuality',\n",
       " 'single',\n",
       " 'skinned',\n",
       " 'social',\n",
       " 'society',\n",
       " 'sociologists',\n",
       " 'software',\n",
       " 'some',\n",
       " 'speech',\n",
       " 'spread',\n",
       " 'stemming',\n",
       " 'study',\n",
       " 'such',\n",
       " 'system',\n",
       " 'systematic',\n",
       " 'systems',\n",
       " 'technical',\n",
       " 'technologies',\n",
       " 'technology',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'there',\n",
       " 'they',\n",
       " 'this',\n",
       " 'to',\n",
       " 'trade',\n",
       " 'train',\n",
       " 'transparency',\n",
       " 'treated',\n",
       " 'typically',\n",
       " 'unanticipated',\n",
       " 'unbiased',\n",
       " 'understanding',\n",
       " 'unfair',\n",
       " 'unintended',\n",
       " 'union',\n",
       " 'use',\n",
       " 'used',\n",
       " 'users',\n",
       " 'violations',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'website',\n",
       " 'when',\n",
       " 'which',\n",
       " 'who',\n",
       " 'with',\n",
       " 'within',\n",
       " 'world',\n",
       " 'wrongful']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6141c9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0cea704",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9343cea",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85cf63de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [doc.text for doc in docs]\n",
    "vectorizer = CountVectorizer()\n",
    "count_vectors = vectorizer.fit_transform(corpus)  # <1>\n",
    "print(count_vectors.toarray()) # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d8bca",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d30004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "v1 = np.array(list(range(5)))\n",
    "v2 = pd.Series(reversed(range(5)))\n",
    "slow_answer = sum([4.2 * (x1 * x2) for x1, x2 in zip(v1, v2)])\n",
    "slow_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7e007",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "200686b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faster_answer = sum(4.2 * v1 * v2)  # <1>\n",
    "faster_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289315e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acd46fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastest_answer = 4.2 * v1.dot(v2)  # <2>\n",
    "fastest_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5175f9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b83f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.dot(v2) == (np.linalg.norm(v1) * np.linalg.norm(v2))  # * np.cos(angle_between_v1_and_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfb512f5-c892-47e7-b113-7a695ad10b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Algorithmic bias describes systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others.,\n",
       " Bias can emerge due to many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm.,\n",
       " Algorithmic bias is found across platforms, including but not limited to search engine results and social media platforms, and can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity.,\n",
       " The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination.,\n",
       " This bias has only recently been addressed in legal frameworks, such as the 2018 European Union's General Data Protection Regulation.,\n",
       " More comprehensive regulation is needed as emerging technologies become increasingly advanced and opaque.,\n",
       " As algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world.,\n",
       " Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise, and in some cases, reliance on algorithms can displace human responsibility for their outcomes.,\n",
       " Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.,\n",
       " Algorithmic bias has been cited in cases ranging from election outcomes to the spread of online hate speech.,\n",
       " It has also arisen in criminal justice, healthcare, and hiring, compounding existing racial, economic, and gender biases.,\n",
       " The relative inability of facial recognition technology to accurately identify darker-skinned faces has been linked to multiple wrongful arrests of men of color, an issue stemming from imbalanced datasets.,\n",
       " Problems in understanding, researching, and discovering algorithmic bias persist due to the proprietary nature of algorithms, which are typically treated as trade secrets.,\n",
       " Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning.,\n",
       " Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis.,\n",
       " In many cases, even within a single website or application, there is no single \"algorithm\" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63762e8d-51b1-4c5d-b2a8-7357447a57e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithmic': 7,\n",
       " 'bias': 30,\n",
       " 'describes': 57,\n",
       " 'systematic': 202,\n",
       " 'and': 12,\n",
       " 'repeatable': 176,\n",
       " 'errors': 70,\n",
       " 'in': 103,\n",
       " 'computer': 46,\n",
       " 'system': 201,\n",
       " 'that': 208,\n",
       " 'create': 50,\n",
       " 'unfair': 223,\n",
       " 'outcomes': 148,\n",
       " 'such': 200,\n",
       " 'as': 19,\n",
       " 'privileging': 158,\n",
       " 'one': 141,\n",
       " 'arbitrary': 15,\n",
       " 'group': 92,\n",
       " 'of': 138,\n",
       " 'users': 228,\n",
       " 'over': 150,\n",
       " 'others': 147,\n",
       " 'can': 34,\n",
       " 'emerge': 66,\n",
       " 'due': 62,\n",
       " 'to': 214,\n",
       " 'many': 125,\n",
       " 'factors': 81,\n",
       " 'including': 107,\n",
       " 'but': 32,\n",
       " 'not': 137,\n",
       " 'limited': 122,\n",
       " 'the': 209,\n",
       " 'design': 58,\n",
       " 'algorithm': 6,\n",
       " 'or': 145,\n",
       " 'unintended': 224,\n",
       " 'unanticipated': 220,\n",
       " 'use': 226,\n",
       " 'decisions': 56,\n",
       " 'relating': 173,\n",
       " 'way': 230,\n",
       " 'data': 54,\n",
       " 'is': 116,\n",
       " 'coded': 40,\n",
       " 'collected': 41,\n",
       " 'selected': 186,\n",
       " 'used': 227,\n",
       " 'train': 216,\n",
       " 'found': 83,\n",
       " 'across': 3,\n",
       " 'platforms': 153,\n",
       " 'search': 184,\n",
       " 'engine': 68,\n",
       " 'results': 182,\n",
       " 'social': 191,\n",
       " 'media': 127,\n",
       " 'have': 95,\n",
       " 'impacts': 102,\n",
       " 'ranging': 167,\n",
       " 'from': 85,\n",
       " 'inadvertent': 106,\n",
       " 'privacy': 157,\n",
       " 'violations': 229,\n",
       " 'reinforcing': 172,\n",
       " 'biases': 31,\n",
       " 'race': 165,\n",
       " 'gender': 89,\n",
       " 'sexuality': 188,\n",
       " 'ethnicity': 71,\n",
       " 'study': 199,\n",
       " 'most': 130,\n",
       " 'concerned': 47,\n",
       " 'with': 236,\n",
       " 'algorithms': 8,\n",
       " 'reflect': 170,\n",
       " 'discrimination': 60,\n",
       " 'this': 213,\n",
       " 'has': 93,\n",
       " 'only': 143,\n",
       " 'recently': 168,\n",
       " 'been': 26,\n",
       " 'addressed': 4,\n",
       " 'legal': 120,\n",
       " 'frameworks': 84,\n",
       " '2018': 0,\n",
       " 'european': 72,\n",
       " 'union': 225,\n",
       " 'general': 90,\n",
       " 'protection': 163,\n",
       " 'regulation': 171,\n",
       " 'more': 129,\n",
       " 'comprehensive': 45,\n",
       " 'needed': 133,\n",
       " 'emerging': 67,\n",
       " 'technologies': 205,\n",
       " 'become': 25,\n",
       " 'increasingly': 108,\n",
       " 'advanced': 5,\n",
       " 'opaque': 144,\n",
       " 'expand': 76,\n",
       " 'their': 210,\n",
       " 'ability': 1,\n",
       " 'organize': 146,\n",
       " 'society': 192,\n",
       " 'politics': 154,\n",
       " 'institutions': 113,\n",
       " 'behavior': 27,\n",
       " 'sociologists': 193,\n",
       " 'ways': 231,\n",
       " 'which': 234,\n",
       " 'output': 149,\n",
       " 'manipulation': 124,\n",
       " 'impact': 101,\n",
       " 'physical': 152,\n",
       " 'world': 238,\n",
       " 'because': 24,\n",
       " 'are': 16,\n",
       " 'often': 139,\n",
       " 'considered': 48,\n",
       " 'be': 23,\n",
       " 'neutral': 135,\n",
       " 'unbiased': 221,\n",
       " 'they': 212,\n",
       " 'inaccurately': 105,\n",
       " 'project': 161,\n",
       " 'greater': 91,\n",
       " 'authority': 21,\n",
       " 'than': 207,\n",
       " 'human': 98,\n",
       " 'expertise': 78,\n",
       " 'some': 195,\n",
       " 'cases': 36,\n",
       " 'reliance': 175,\n",
       " 'on': 140,\n",
       " 'displace': 61,\n",
       " 'responsibility': 180,\n",
       " 'for': 82,\n",
       " 'enter': 69,\n",
       " 'into': 115,\n",
       " 'systems': 203,\n",
       " 'result': 181,\n",
       " 'pre': 156,\n",
       " 'existing': 75,\n",
       " 'cultural': 52,\n",
       " 'institutional': 112,\n",
       " 'expectations': 77,\n",
       " 'technical': 204,\n",
       " 'limitations': 121,\n",
       " 'by': 33,\n",
       " 'being': 28,\n",
       " 'contexts': 49,\n",
       " 'audiences': 20,\n",
       " 'who': 235,\n",
       " 'software': 194,\n",
       " 'initial': 109,\n",
       " 'cited': 39,\n",
       " 'election': 65,\n",
       " 'spread': 197,\n",
       " 'online': 142,\n",
       " 'hate': 94,\n",
       " 'speech': 196,\n",
       " 'it': 118,\n",
       " 'also': 9,\n",
       " 'arisen': 17,\n",
       " 'criminal': 51,\n",
       " 'justice': 119,\n",
       " 'healthcare': 96,\n",
       " 'hiring': 97,\n",
       " 'compounding': 44,\n",
       " 'racial': 166,\n",
       " 'economic': 64,\n",
       " 'relative': 174,\n",
       " 'inability': 104,\n",
       " 'facial': 80,\n",
       " 'recognition': 169,\n",
       " 'technology': 206,\n",
       " 'accurately': 2,\n",
       " 'identify': 99,\n",
       " 'darker': 53,\n",
       " 'skinned': 190,\n",
       " 'faces': 79,\n",
       " 'linked': 123,\n",
       " 'multiple': 131,\n",
       " 'wrongful': 239,\n",
       " 'arrests': 18,\n",
       " 'men': 128,\n",
       " 'color': 42,\n",
       " 'an': 10,\n",
       " 'issue': 117,\n",
       " 'stemming': 198,\n",
       " 'imbalanced': 100,\n",
       " 'datasets': 55,\n",
       " 'problems': 159,\n",
       " 'understanding': 222,\n",
       " 'researching': 178,\n",
       " 'discovering': 59,\n",
       " 'persist': 151,\n",
       " 'proprietary': 162,\n",
       " 'nature': 132,\n",
       " 'typically': 219,\n",
       " 'treated': 218,\n",
       " 'trade': 215,\n",
       " 'secrets': 185,\n",
       " 'even': 73,\n",
       " 'when': 233,\n",
       " 'full': 86,\n",
       " 'transparency': 217,\n",
       " 'provided': 164,\n",
       " 'complexity': 43,\n",
       " 'certain': 37,\n",
       " 'poses': 155,\n",
       " 'barrier': 22,\n",
       " 'functioning': 87,\n",
       " 'furthermore': 88,\n",
       " 'may': 126,\n",
       " 'change': 38,\n",
       " 'respond': 179,\n",
       " 'input': 110,\n",
       " 'cannot': 35,\n",
       " 'anticipated': 13,\n",
       " 'easily': 63,\n",
       " 'reproduced': 177,\n",
       " 'analysis': 11,\n",
       " 'within': 237,\n",
       " 'single': 189,\n",
       " 'website': 232,\n",
       " 'application': 14,\n",
       " 'there': 211,\n",
       " 'no': 136,\n",
       " 'examine': 74,\n",
       " 'network': 134,\n",
       " 'interrelated': 114,\n",
       " 'programs': 160,\n",
       " 'inputs': 111,\n",
       " 'between': 29,\n",
       " 'same': 183,\n",
       " 'service': 187}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71bf3e29",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1830320268.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[37], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cos_similarity_between_A_and_B = np.cos(angle_between_A_and_B) \\\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "cos_similarity_between_A_and_B = np.cos(angle_between_A_and_B) \\\n",
    "   = A.dot(B) / (np.linalg.norm(A) * np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fc381",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a89ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = [val for val in vec1.values()] # <1>\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "\n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f327c85",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39b9291b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24647491]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "vec1 = count_vectors[1,:]\n",
    "vec2 = count_vectors[2,:]\n",
    "cosine_similarity(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10081c7a",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74a491fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "question = \"What is algorithmic bias?\"\n",
    "ngram_docs = copy.copy(docs)\n",
    "ngram_docs.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1d89fbf-0122-4132-b95a-f657cf25b9d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "182782e4",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "718dcadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x240 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vec = vectorizer.transform([new_sentence])\n",
    "question_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd78e23a-c1cb-473a-8634-ed90ea3b64c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6164b639-cce4-4470-b69e-1635b765ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018           0\n",
       "ability        0\n",
       "accurately     0\n",
       "across         0\n",
       "addressed      0\n",
       "advanced       0\n",
       "algorithm      0\n",
       "algorithmic    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in \n",
    "    vectorizer.vocabulary_.items())))[1]\n",
    "pd.Series(question_vec.toarray()[0], index=vocab).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1f41b",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8f7c71b-a175-44c5-8c7c-27684f704cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdf638b7-c147-406c-b510-f36160f475bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21566555]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(count_vectors[1,:], count_vectors[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c2f0634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23570226],\n",
       "       [0.12451456],\n",
       "       [0.24743583],\n",
       "       [0.4330127 ],\n",
       "       [0.12909944],\n",
       "       [0.16012815],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.1490712 ],\n",
       "       [0.27216553],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.24077171],\n",
       "       [0.14002801],\n",
       "       [0.        ],\n",
       "       [0.09128709]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(count_vectors, new_sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666763f",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3fcddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16x616 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 772 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "ngram_vectors = ngram_vectorizer.fit_transform(corpus)\n",
    "ngram_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6e6284d2-b02a-417e-83b6-87d7a2148651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     1\n",
       "10    0\n",
       "11    0\n",
       "12    1\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "Name: algorithmic bias, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(zip(*sorted((i, tok) for tok, i in\n",
    "    ngram_vectorizer.vocabulary_.items())))[1]\n",
    "pd.DataFrame(ngram_vectors.toarray(), columns=vocab)['algorithmic bias']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8901236",
   "metadata": {},
   "source": [
    "#### .Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62a51a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19099662]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(ngram_vectors[1,:], ngram_vectors[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7de3574c-3e0c-4b26-95f8-2adf299bb63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12650692]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(ngram_vectors[1,:], ngram_vectors[3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90bfab",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from this import s\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4716c1d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766882bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1,1), analyzer='char')  # <1>\n",
    "s_char_frequencies = char_vectorizer.fit_transform(s)\n",
    "generate_histogram(\n",
    "    s_char_frequencies, s_char_vectorizer)  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659cba34",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n",
    "            '-/raw/master/src/nlpia/data')\n",
    "url = DATA_DIR + '/machine_learning_full_article.txt'\n",
    "ml_text = requests.get(url).content.decode()\n",
    "ml_char_frequencies = char_vectorizer.fit_transform(ml_text)\n",
    "generate_histogram(s_char_frequencies, s_char_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5c474",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(ord('W') - peak_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb6391",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4005f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "print(codecs.decode(s, 'rot-13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4b38e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33726d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown')  # <1>\n",
    "from nltk.corpus import brown\n",
    "brown.words()[:10]  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377712eb",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e161f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.tagged_words()[:5]  # <3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdadd1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ecfbb5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "puncs = set((',', '.', '--', '-', '!', '?',\n",
    "    ':', ';', '``', \"''\", '(', ')', '[', ']'))\n",
    "word_list = (x.lower() for x in brown.words() if x not in puncs)\n",
    "token_counts = Counter(word_list)\n",
    "token_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa0ea4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86823799",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ('https://gitlab.com/tangibleai/nlpia/'\n",
    "            '-/raw/master/src/nlpia/data')\n",
    "url = DATA_DIR + '/bias_discrimination.txt'\n",
    "bias_discrimination = requests.get(url).content.decode()\n",
    "intro_tokens = [token.text for token in nlp(bias_intro.lower())]\n",
    "disc_tokens = [token.text for token in nlp(bias_discrimination.lower())]\n",
    "intro_total = len(intro_tokens)\n",
    "intro_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09150c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_total = len (disc_tokens)\n",
    "disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffa11b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf = {}\n",
    "disc_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['bias'] = intro_counts['bias'] / intro_total\n",
    "disc_counts = Counter(disc_tokens)\n",
    "disc_tf['bias'] = disc_counts['bias'] / disc_total\n",
    "'Term Frequency of \"bias\" in intro is:{:.4f}'.format(intro_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55823584",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ae964",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Term Frequency of \"bias\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae27d69",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf335416",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['and'] = intro_counts['and'] / intro_total\n",
    "disc_tf['and'] = disc_counts['and'] / disc_total\n",
    "print('Term Frequency of \"and\" in intro is: {:.4f}'\\\n",
    "    .format(intro_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f23342",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Term Frequency of \"and\" in discrimination chapter is: {:.4f}'\\\n",
    "    .format(disc_tf['and']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df7457",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a73fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_containing_and = 0\n",
    "for doc in [intro_tokens, disc_tokens]:\n",
    "    if 'and' in doc:\n",
    "        num_docs_containing_and += 1  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e592279",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tf['black'] = intro_counts['black'] / intro_total\n",
    "disc_tf['black'] = disc_counts['black'] / disc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d217f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a89419",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 2\n",
    "intro_idf = {}\n",
    "disc_idf = {}\n",
    "intro_idf['and'] = num_docs / num_docs_containing_and\n",
    "disc_idf['and'] = num_docs / num_docs_containing_and\n",
    "intro_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "disc_idf['bias'] = num_docs / num_docs_containing_bias\n",
    "intro_idf['black'] = num_docs / num_docs_containing_black\n",
    "disc_idf['black'] = num_docs / num_docs_containing_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdfc1c6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_tfidf = {}\n",
    "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
    "intro_tfidf['bias'] = intro_tf['bias'] * intro_idf['bias']\n",
    "intro_tfidf['black'] = intro_tf['black'] * intro_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb047320",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_tfidf = {}\n",
    "disc_tfidf['and'] = disc_tf['and'] * disc_idf['and']\n",
    "disc_tfidf['bias'] = disc_tf['bias'] * disc_idf['bias']\n",
    "disc_tfidf['black'] = disc_tf['black'] * disc_idf['black']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d560d3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tfidf_vectors = []\n",
    "for doc in docs:  # <1>\n",
    "    vec = copy.copy(zero_vector)  # <2>\n",
    "    tokens = [token.text for token in nlp(doc.lower())]\n",
    "    token_counts = Counter(tokens)\n",
    "\n",
    "    for token, count in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for d in docs:\n",
    "            if token in d:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(vocab)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf\n",
    "    doc_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb8797",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(zero_vector)  # <1>\n",
    "tokens = [token.text for token in nlp(query.lower())]\n",
    "token_counts = Counter(tokens)\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for _doc in docs:\n",
    "      if key in _doc.lower():\n",
    "        docs_containing_key += 1\n",
    "    if docs_containing_key == 0:  # <1>\n",
    "        continue\n",
    "    tf = value / len(tokens)\n",
    "    idf = len(docs) / docs_containing_key\n",
    "    query_vec[key] = tf * idf\n",
    "cosine_sim(query_vec, doc_tfidf_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f545e5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb757923",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim(query_vec, doc_tfidf_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cafee",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46173625",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim(query_vec, doc_tfidf_vectors[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085459e",
   "metadata": {},
   "source": [
    "#### .Computing TF-IDF matrix using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = docs\n",
    "vectorizer = TfidfVectorizer(min_df=1) # <1>\n",
    "vectorizer = vectorizer.fit(corpus)  # <2>\n",
    "vectors = vectorizer.transform(corpus)  # <3>\n",
    "print(vectors.todense().round(2))  # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a11ed2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_FAQ_URL = ('https://gitlab.com/tangibleai/qary/-/raw/main/'\n",
    "    'src/qary/data/faq/faq-python-data-science-cleaned.csv')\n",
    "qa_dataset = pd.read_csv(DS_FAQ_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655414f9",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ee466",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['question'])\n",
    "tfidfvectors_sparse = vectorizer.transform(df['question'])  # <1>\n",
    "tfidfvectors = tfidfvectors_sparse.todense()  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca76a4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_reply(question):\n",
    "   question_vector = vectorizer.transform([question]).todense()\n",
    "   idx = question_vector.dot(tfidfvectors.T).argmax() # <1>\n",
    "\n",
    "   print(\n",
    "       f\"Your question:\\n  {question}\\n\\n\"\n",
    "       f\"Most similar FAQ question:\\n  {df['question'][idx]}\\n\\n\"\n",
    "       f\"Answer to that FAQ question:\\n  {df['answer'][idx]}\\n\\n\"\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727ebda",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_reply(\"What's overfitting a model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2c709",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_reply('How do I decrease overfitting for Logistic Regression?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
