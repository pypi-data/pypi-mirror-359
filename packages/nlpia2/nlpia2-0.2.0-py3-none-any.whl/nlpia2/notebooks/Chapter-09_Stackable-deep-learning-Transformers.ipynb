{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1ecaef",
   "metadata": {},
   "source": [
    "#### [`Chapter-09_Stackable-deep-learning-Transformers`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-09_Stackable-deep-learning-Transformers.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5dc2e",
   "metadata": {},
   "source": [
    "#### .Pytorch PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5753f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model=512, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)  # <1>\n",
    "        self.d_model = d_model  # <2>\n",
    "        self.max_len = max_len  # <3>\n",
    "        pe = torch.zeros(max_len, d_model)  # <4>\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # <5>\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]  # <6>\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb1a51",
   "metadata": {},
   "source": [
    "#### .Load a translation dataset in Hugging Face format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218c1e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b960d3fc86a4674b6a8036288616ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fb5a1107df4565b2d7195258cb516f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/161k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4368bb67665449d83629594e544878f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/20.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590fa1fed3364d44abd1c88ad6798c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bcbb1be39e434cac78c460d60a9669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/51467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 51467\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset  # <1>\n",
    "opus = load_dataset('opus_books', 'de-en')\n",
    "opus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de84942",
   "metadata": {},
   "source": [
    "#### .Load a translation dataset in Hugging Face format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fd185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 46320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 5147\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = opus['train'].train_test_split(test_size=.1)\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd418b4",
   "metadata": {},
   "source": [
    "#### .Load a translation dataset in Hugging Face format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a819ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '42822',\n",
       " 'translation': {'de': 'Und das ist durchaus begreiflich.',\n",
       "  'en': 'That is natural.'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(sents['test']))  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f5f7e",
   "metadata": {},
   "source": [
    "#### .Enable any available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be361e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54e4ee",
   "metadata": {},
   "source": [
    "#### .Enable any available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661111cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SRC = 'en'  # <1>\n",
    "TGT = 'de'  # <2>\n",
    "SOS, EOS = '<s>', '</s>'\n",
    "PAD, UNK, MASK = '<pad>', '<unk>', '<mask>'\n",
    "SPECIAL_TOKS = [SOS, PAD, EOS, UNK, MASK]\n",
    "VOCAB_SIZE = 10_000\n",
    "from tokenizers import ByteLevelBPETokenizer  # <3>\n",
    "tokenize_src = ByteLevelBPETokenizer()\n",
    "tokenize_src.train_from_iterator(\n",
    "    [x[SRC] for x in sents['train']['translation']],\n",
    "    vocab_size=10000, min_frequency=2,\n",
    "    special_tokens=SPECIAL_TOKS)\n",
    "PAD_IDX = tokenize_src.token_to_id(PAD)\n",
    "tokenize_tgt = ByteLevelBPETokenizer()\n",
    "tokenize_tgt.train_from_iterator(\n",
    "    [x[TGT] for x in sents['train']['translation']],\n",
    "    vocab_size=10000, min_frequency=2,\n",
    "    special_tokens=SPECIAL_TOKS)\n",
    "assert PAD_IDX == tokenize_tgt.token_to_id(PAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e405af4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fb6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Optional, Any\n",
    "class CustomDecoderLayer(nn.TransformerDecoderLayer):\n",
    "    def forward(self, tgt: Tensor, memory: Tensor,\n",
    "            tgt_mask: Optional[Tensor] = None,\n",
    "            memory_mask: Optional[Tensor] = None,\n",
    "            tgt_key_padding_mask: Optional[Tensor] = None\n",
    "            ) -> Tensor:\n",
    "        \"\"\"Like decode but returns multi-head attention weights.\"\"\"\n",
    "        tgt2 = self.self_attn(\n",
    "            tgt, tgt, tgt, attn_mask=tgt_mask,\n",
    "            key_padding_mask=tgt_key_padding_mask)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        tgt2, attention_weights = self.multihead_attn(\n",
    "            tgt, memory, memory,  # <1>\n",
    "            attn_mask=memory_mask,\n",
    "            key_padding_mask=mem_key_padding_mask,\n",
    "            need_weights=True)\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        tgt2 = self.linear2(\n",
    "            self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt, attention_weights  # <2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293d06f5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a122bf",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> class CustomDecoder(nn.TransformerDecoder):\n",
    "...     def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "...         super().__init__(\n",
    "...             decoder_layer, num_layers, norm)\n",
    "...\n",
    "...     def forward(self,\n",
    "...             tgt: Tensor, memory: Tensor,\n",
    "...             tgt_mask: Optional[Tensor] = None,\n",
    "...             memory_mask: Optional[Tensor] = None,\n",
    "...             tgt_key_padding_mask: Optional[Tensor] = None\n",
    "...             ) -> Tensor:\n",
    "...         \"\"\"Like TransformerDecoder but cache multi-head attention\"\"\"\n",
    "...         self.attention_weights = []  # <1>\n",
    "...         output = tgt\n",
    "...         for mod in self.layers:\n",
    "...             output, attention = mod(\n",
    "...                 output, memory, tgt_mask=tgt_mask,\n",
    "...                 memory_mask=memory_mask,\n",
    "...                 tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "...             self.attention_weights.append(attention) # <2>\n",
    "...\n",
    "...         if self.norm is not None:\n",
    "...             output = self.norm(output)\n",
    "...\n",
    "...         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050c106",
   "metadata": {},
   "source": [
    "#### .Extend nn.Transformer for translation with a CustomDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange  # <1>\n",
    "class TranslationTransformer(nn.Transformer):  # <2>\n",
    "    def __init__(self,\n",
    "            device=DEVICE,\n",
    "            src_vocab_size: int = VOCAB_SIZE,\n",
    "            src_pad_idx: int = PAD_IDX,\n",
    "            tgt_vocab_size: int = VOCAB_SIZE,\n",
    "            tgt_pad_idx: int = PAD_IDX,\n",
    "            max_sequence_length: int = 100,\n",
    "            d_model: int = 512,\n",
    "            nhead: int = 8,\n",
    "            num_encoder_layers: int = 6,\n",
    "            num_decoder_layers: int = 6,\n",
    "            dim_feedforward: int = 2048,\n",
    "            dropout: float = 0.1,\n",
    "            activation: str = \"relu\"\n",
    "        ):\n",
    "\n",
    "        decoder_layer = CustomDecoderLayer(\n",
    "            d_model, nhead, dim_feedforward,  # <3>\n",
    "            dropout, activation)\n",
    "        decoder_norm = nn.LayerNorm(d_model)\n",
    "        decoder = CustomDecoder(\n",
    "            decoder_layer, num_decoder_layers,\n",
    "            decoder_norm)  # <4>\n",
    "\n",
    "        super().__init__(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, custom_decoder=decoder)\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.tgt_pad_idx = tgt_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "        self.src_emb = nn.Embedding(\n",
    "            src_vocab_size, d_model)  # <5>\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(\n",
    "            d_model, dropout, max_sequence_length)  # <6>\n",
    "        self.linear = nn.Linear(\n",
    "            d_model, tgt_vocab_size)  # <7>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd5efe",
   "metadata": {},
   "source": [
    "#### .TranslationTransformer prepare_src()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _make_key_padding_mask(self, t, pad_idx):\n",
    "        mask = (t == pad_idx).to(self.device)\n",
    "        return mask\n",
    "\n",
    "    def prepare_src(self, src, src_pad_idx):\n",
    "        src_key_padding_mask = self._make_key_padding_mask(\n",
    "            src, src_pad_idx)\n",
    "        src = rearrange(src, 'N S -> S N')\n",
    "        src = self.pos_enc(self.src_emb(src)\n",
    "            * math.sqrt(self.d_model))\n",
    "        return src, src_key_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b59b4d",
   "metadata": {},
   "source": [
    "#### .TranslationTransformer prepare_src()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ccf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def prepare_tgt(self, tgt, tgt_pad_idx):\n",
    "        tgt_key_padding_mask = self._make_key_padding_mask(\n",
    "            tgt, tgt_pad_idx)\n",
    "        tgt = rearrange(tgt, 'N T -> T N')\n",
    "        tgt_mask = self.generate_square_subsequent_mask(\n",
    "            tgt.shape[0]).to(self.device)\n",
    "        tgt = self.pos_enc(self.tgt_emb(tgt)\n",
    "            * math.sqrt(self.d_model))\n",
    "        return tgt, tgt_key_padding_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbf05e",
   "metadata": {},
   "source": [
    "#### .TranslationTransformer prepare_src()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb13058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, src, tgt):\n",
    "        src, src_key_padding_mask = self.prepare_src(\n",
    "            src, self.src_pad_idx)\n",
    "        tgt, tgt_key_padding_mask, tgt_mask = self.prepare_tgt(\n",
    "            tgt, self.tgt_pad_idx)\n",
    "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
    "        output = super().forward(\n",
    "            src, tgt, tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask)\n",
    "        output = rearrange(output, 'T N E -> N T E')\n",
    "        return self.linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa1958",
   "metadata": {},
   "source": [
    "#### .TranslationTransformer init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ac6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def init_weights(self):\n",
    "        def _init_weights(m):\n",
    "            if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "        self.apply(_init_weights);  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446f35f",
   "metadata": {},
   "source": [
    "#### .TranslationTransformer init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a8e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> class TranslationTransformer(nn.Transformer):\n",
    "...     def __init__(self,\n",
    "...             device=DEVICE,\n",
    "...             src_vocab_size: int = 10000,\n",
    "...             src_pad_idx: int = PAD_IDX,\n",
    "...             tgt_vocab_size: int  = 10000,\n",
    "...             tgt_pad_idx: int = PAD_IDX,\n",
    "...             max_sequence_length: int = 100,\n",
    "...             d_model: int = 512,\n",
    "...             nhead: int = 8,\n",
    "...             num_encoder_layers: int = 6,\n",
    "...             num_decoder_layers: int = 6,\n",
    "...             dim_feedforward: int = 2048,\n",
    "...             dropout: float = 0.1,\n",
    "...             activation: str = \"relu\"\n",
    "...             ):\n",
    "...         decoder_layer = CustomDecoderLayer(\n",
    "...             d_model, nhead, dim_feedforward,\n",
    "...             dropout, activation)\n",
    "...         decoder_norm = nn.LayerNorm(d_model)\n",
    "...         decoder = CustomDecoder(\n",
    "...             decoder_layer, num_decoder_layers, decoder_norm)\n",
    "...\n",
    "...         super().__init__(\n",
    "...             d_model=d_model, nhead=nhead,\n",
    "...             num_encoder_layers=num_encoder_layers,\n",
    "...             num_decoder_layers=num_decoder_layers,\n",
    "...             dim_feedforward=dim_feedforward,\n",
    "...             dropout=dropout, custom_decoder=decoder)\n",
    "...\n",
    "...         self.src_pad_idx = src_pad_idx\n",
    "...         self.tgt_pad_idx = tgt_pad_idx\n",
    "...         self.device = device\n",
    "...         self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "...         self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "...         self.pos_enc = PositionalEncoding(\n",
    "...             d_model, dropout, max_sequence_length)\n",
    "...         self.linear = nn.Linear(d_model, tgt_vocab_size)\n",
    "...\n",
    "...     def init_weights(self):\n",
    "...         def _init_weights(m):\n",
    "...             if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "...                 nn.init.xavier_uniform_(m.weight.data)\n",
    "...         self.apply(_init_weights);\n",
    "...\n",
    "...     def _make_key_padding_mask(self, t, pad_idx=PAD_IDX):\n",
    "...         mask = (t == pad_idx).to(self.device)\n",
    "...         return mask\n",
    "...\n",
    "...     def prepare_src(self, src, src_pad_idx):\n",
    "...         src_key_padding_mask = self._make_key_padding_mask(\n",
    "...             src, src_pad_idx)\n",
    "...         src = rearrange(src, 'N S -> S N')\n",
    "...         src = self.pos_enc(self.src_emb(src)\n",
    "...             * math.sqrt(self.d_model))\n",
    "...         return src, src_key_padding_mask\n",
    "...\n",
    "...     def prepare_tgt(self, tgt, tgt_pad_idx):\n",
    "...         tgt_key_padding_mask = self._make_key_padding_mask(\n",
    "...             tgt, tgt_pad_idx)\n",
    "...         tgt = rearrange(tgt, 'N T -> T N')\n",
    "...         tgt_mask = self.generate_square_subsequent_mask(\n",
    "...             tgt.shape[0]).to(self.device)      # <1>\n",
    "...         tgt = self.pos_enc(self.tgt_emb(tgt)\n",
    "...             * math.sqrt(self.d_model))\n",
    "...         return tgt, tgt_key_padding_mask, tgt_mask\n",
    "...\n",
    "...     def forward(self, src, tgt):\n",
    "...         src, src_key_padding_mask = self.prepare_src(\n",
    "...             src, self.src_pad_idx)\n",
    "...         tgt, tgt_key_padding_mask, tgt_mask = self.prepare_tgt(\n",
    "...             tgt, self.tgt_pad_idx)\n",
    "...         memory_key_padding_mask = src_key_padding_mask.clone()\n",
    "...         output = super().forward(\n",
    "...             src, tgt, tgt_mask=tgt_mask,\n",
    "...             src_key_padding_mask=src_key_padding_mask,\n",
    "...             tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "...             memory_key_padding_mask = memory_key_padding_mask,\n",
    "...             )\n",
    "...         output = rearrange(output, 'T N E -> N T E')\n",
    "...         return self.linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1aee2c",
   "metadata": {},
   "source": [
    "#### .Instantiate a TranslationTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7273b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hobs/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TranslationTransformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): CustomDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x CustomDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (src_emb): Embedding(10000, 512)\n",
       "  (tgt_emb): Embedding(10000, 512)\n",
       "  (pos_enc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TranslationTransformer(\n",
    "    device=DEVICE,\n",
    "    src_vocab_size=tokenize_src.get_vocab_size(),\n",
    "    src_pad_idx=tokenize_src.token_to_id('<pad>'),\n",
    "    tgt_vocab_size=tokenize_tgt.get_vocab_size(),\n",
    "    tgt_pad_idx=tokenize_tgt.token_to_id('<pad>')\n",
    "    ).to(DEVICE)\n",
    "model.init_weights()\n",
    "model  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d0757",
   "metadata": {},
   "source": [
    "#### .Instantiate a TranslationTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb3cef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CustomDecoder.forward() got an unexpected keyword argument 'memory_key_padding_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# <2>\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 74\u001b[0m, in \u001b[0;36mTranslationTransformer.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     71\u001b[0m tgt, tgt_key_padding_mask, tgt_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tgt(\n\u001b[1;32m     72\u001b[0m     tgt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_pad_idx)\n\u001b[1;32m     73\u001b[0m memory_key_padding_mask \u001b[38;5;241m=\u001b[39m src_key_padding_mask\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m---> 74\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m output \u001b[38;5;241m=\u001b[39m rearrange(output, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT N E -> N T E\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(output)\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    205\u001b[0m                       is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal)\n\u001b[0;32m--> 206\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: CustomDecoder.forward() got an unexpected keyword argument 'memory_key_padding_mask'"
     ]
    }
   ],
   "source": [
    "src = torch.randint(1, 100, (10, 5)).to(DEVICE)  # <1>\n",
    "tgt = torch.randint(1, 100, (10, 7)).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(src, tgt)  # <2>\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcfedf",
   "metadata": {},
   "source": [
    "#### .Optimizer and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b986ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRG_PAD_IDX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m----> 3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[43mTRG_PAD_IDX\u001b[49m)  \u001b[38;5;66;03m# <1>\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRG_PAD_IDX' is not defined"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a51ea1",
   "metadata": {},
   "source": [
    "#### .Optimizer and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07baace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()  # <1>\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:,:-1])  # <2>\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5339dae",
   "metadata": {},
   "source": [
    "#### .Optimizer and Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf8ba930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()  # <1>\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # <2>\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            output = model(src, trg[:,:-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3e6da",
   "metadata": {},
   "source": [
    "#### .Utility function for elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15ca026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc0187",
   "metadata": {},
   "source": [
    "#### .Utility function for elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f29671f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m----> 6\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m      8\u001b[0m         model, train_iterator, optimizer, criterion, CLIP)\n\u001b[1;32m      9\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_iterator, criterion)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 15\n",
    "CLIP = 1\n",
    "BEST_MODEL_FILE = 'best_model.pytorch'\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(\n",
    "        model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_FILE)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    train_ppl = f'{math.exp(train_loss):7.3f}'\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {train_ppl}')\n",
    "    valid_ppl = f'{math.exp(valid_loss):7.3f}'\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {valid_ppl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71938e34",
   "metadata": {},
   "source": [
    "#### .Load _best_ model from file and perform evaluation on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d622b900",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model.pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBEST_MODEL_FILE\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m evaluate(model, test_iterator, criterion)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmath\u001b[38;5;241m.\u001b[39mexp(test_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m |\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/code/tangibleai/community/nlpia2/.venv/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pytorch'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(BEST_MODEL_FILE))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13128f12",
   "metadata": {},
   "source": [
    "#### .Load _best_ model from file and perform evaluation on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da767f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field,\n",
    "        model, device=DEVICE, max_len=50):\n",
    "    model.eval()\n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    tokens = ([src_field.init_token] + tokens\n",
    "        + [src_field.eos_token])  # <1>\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src, src_key_padding_mask = model.prepare_src(src, SRC_PAD_IDX)\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src,\n",
    "            src_key_padding_mask=src_key_padding_mask)\n",
    "    trg_indexes = [\n",
    "        trg_field.vocab.stoi[trg_field.init_token]]  # <2>\n",
    "\n",
    "    for i in range(max_len):\n",
    "        tgt = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        tgt, tgt_key_padding_mask, tgt_mask = model.prepare_tgt(\n",
    "            tgt, TRG_PAD_IDX)\n",
    "        with torch.no_grad():\n",
    "            output = model.decoder(\n",
    "                tgt, enc_src, tgt_mask=tgt_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "            output = rearrange(output, 'T N E -> N T E')\n",
    "            output = model.linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f331a",
   "metadata": {},
   "source": [
    "#### .Load sample at _test_data_ index 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 10\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522b6f",
   "metadata": {},
   "source": [
    "#### .Load sample at _test_data_ index 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699931d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2608764",
   "metadata": {},
   "source": [
    "#### .Load sample at _test_data_ index 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f'translation = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b36fcb",
   "metadata": {},
   "source": [
    "#### .Load sample at _test_data_ index 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "def display_attention(sentence, translation, attention_weights):\n",
    "    n_attention = len(attention_weights)\n",
    "\n",
    "    n_cols = 2\n",
    "    n_rows = n_attention // n_cols + n_attention % n_cols\n",
    "\n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "\n",
    "    for i in range(n_attention):\n",
    "\n",
    "        attention = attention_weights[i].squeeze(0)\n",
    "        attention = attention.cpu().detach().numpy()\n",
    "        cax = ax.matshow(attention, cmap='gist_yarg')\n",
    "\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels([''] + ['<sos>'] + \n",
    "            [t.lower() for t in sentence]+['<eos>'],\n",
    "            rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadfbd4",
   "metadata": {},
   "source": [
    "#### .Visualize the self-attention weights for the test example translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67944d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b8fe3",
   "metadata": {},
   "source": [
    "#### .Visualize the self-attention weights for the test example translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8313b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = 25\n",
    "src = vars(valid_data.examples[example_idx])['src']\n",
    "trg = vars(valid_data.examples[example_idx])['trg']\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ba4de",
   "metadata": {},
   "source": [
    "#### .Visualize the self-attention weights for the test example translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "print(f'translation = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b08f2",
   "metadata": {},
   "source": [
    "#### .Visualize the self-attention weights for the test example translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28698e1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3035fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    for datum in data:\n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        pred_trg, _ = translate_sentence(\n",
    "            src, src_field, trg_field, model, device, max_len)\n",
    "        # strip <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "\n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6267d3c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e319ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39343b",
   "metadata": {},
   "source": [
    "#### .Pytorch summary of BERT architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6811b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pre-trained('bert-base-uncased')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d20d36",
   "metadata": {},
   "source": [
    "#### .Load the toxic comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b60c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/train.csv')  # <1>\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd87b4d",
   "metadata": {},
   "source": [
    "#### .Load the toxic comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ddaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226b86b",
   "metadata": {},
   "source": [
    "#### .Load the toxic comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state=42\n",
    "labels = ['toxic', 'severe', 'obscene', 'threat', 'insult', 'hate']\n",
    "X = df[['comment_text']]\n",
    "y = df[labels]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2,\n",
    "    random_state=random_state)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854adcb",
   "metadata": {},
   "source": [
    "#### .Create datasets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(X, y):\n",
    "    data = [[X.iloc[i][0], y.iloc[i].values.tolist()] for i in range(X.shape[0])]\n",
    "    return pd.DataFrame(data, columns=['text', 'labels'])\n",
    "train_df = get_dataset(X_train, y_train)\n",
    "eval_df = get_dataset(X_test, y_test)\n",
    "train_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe08e0",
   "metadata": {},
   "source": [
    "#### .Create datasets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc4930",
   "metadata": {},
   "source": [
    "#### .Create datasets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)  # <1>\n",
    "model_type = 'bert'  # <2>\n",
    "model_name = 'bert-base-cased'\n",
    "output_dir = f'{model_type}-example1-outputs'\n",
    "model_args = {\n",
    "    'output_dir': output_dir, # where to save results\n",
    "    'overwrite_output_dir': True, # allow re-run without having to manually clear output_dir\n",
    "    'manual_seed': random_state, # <3>\n",
    "    'no_cache': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bd07e",
   "metadata": {},
   "source": [
    "#### .Create datasets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "model = MultiLabelClassificationModel(\n",
    "    model_type, model_name, num_labels=len(labels),\n",
    "    args=model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe8076",
   "metadata": {},
   "source": [
    "#### .Create datasets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model(train_df=train_df)  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3730c",
   "metadata": {},
   "source": [
    "#### .Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3be2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df,\n",
    "    acc=roc_auc_score)  # <1>\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3955d",
   "metadata": {},
   "source": [
    "#### .Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocessing import TextPreprocessor\n",
    "tp = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5db783",
   "metadata": {},
   "source": [
    "#### .Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'comment_text':'original_text'})\n",
    "df['comment_text'] = df['original_text'].apply(\n",
    "    lambda x: tp.preprocess(x))  # <1>\n",
    "pd.set_option('display.max_colwidth', 45)\n",
    "df[['original_text', 'comment_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e924d",
   "metadata": {},
   "source": [
    "#### .Setup parameters for evaluation during training and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'bert'\n",
    "model_name = 'bert-base-cased'\n",
    "output_dir = f'{model_type}-example2-outputs'  # <1>\n",
    "best_model_dir = f'{output_dir}/best_model'\n",
    "model_args = {\n",
    "    'output_dir': output_dir,\n",
    "    'overwrite_output_dir': True,\n",
    "    'manual_seed': random_state,\n",
    "    'no_cache': True,\n",
    "    'best_model_dir': best_model_dir,\n",
    "    'max_seq_length': 300,\n",
    "    'train_batch_size': 24,\n",
    "    'eval_batch_size': 24,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 5e-5,\n",
    "    'evaluate_during_training': True,\n",
    "    'evaluate_during_training_steps': 1000,\n",
    "    'save_eval_checkpoints': False,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    'save_steps': -1,  # saving model unnecessarily takes time during training\n",
    "    'reprocess_input_data': True,\n",
    "    'num_train_epochs': 5,  # <2>\n",
    "    'use_early_stopping': True,\n",
    "    'early_stopping_patience': 4,  # <3>\n",
    "    'early_stopping_delta': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cb49e",
   "metadata": {},
   "source": [
    "#### .Setup parameters for evaluation during training and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLabelClassificationModel(\n",
    "    model_type, model_name, num_labels=len(labels),\n",
    "    args=model_args)\n",
    "model.train_model(\n",
    "    train_df=train_df, eval_df=eval_df, acc=roc_auc_score,\n",
    "    show_running_loss=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70ae07",
   "metadata": {},
   "source": [
    "#### .Setup parameters for evaluation during training and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MultiLabelClassificationModel(\n",
    "    model_type, best_model_dir,\n",
    "    num_labels=len(labels), args=model_args)\n",
    "result, model_outputs, wrong_predictions = best_model.eval_model(\n",
    "    eval_df, acc=roc_auc_score)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
