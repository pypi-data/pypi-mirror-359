{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e465cc",
   "metadata": {},
   "source": [
    "#### [`Chapter-12_Getting-chatty-dialog-engines`](/home/hobs/code/hobs/nlpia-manuscript/manuscript/adoc/Chapter-12_Getting-chatty-dialog-engines.adoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ff45b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1478f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad Snisar, Ruslan Borisov build ConvoHub w/ spaCy.\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99905bd3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2453c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar, ruslan borisov build convoHub w/ spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362e5ad",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Vlad snisar ruslan borisov convoHub spaCy\"\n",
    "nlp(text).ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3d138",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19902c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_proper_nouns(\n",
    "        context, key=\"user_text\",  # <1>\n",
    "        pos=\"PROPN\", ent_type=None):  # <2>\n",
    "    doc = nlp(context.get(key, ''))  # <3>\n",
    "    names = []\n",
    "    i = 0\n",
    "    while i < len(doc):\n",
    "        tok = doc[i]\n",
    "        ent = []\n",
    "        if ((pos is None or tok.pos_ == pos)\n",
    "                and (ent_type is None or tok.ent_type_ != ent_type)):\n",
    "            for k, t in enumerate(doc[i:]):\n",
    "                if not ((pos is None or t.pos_ == pos)\n",
    "                    and (ent_type is None or t.ent_type_\n",
    "                        != ent_type)):\n",
    "                    break\n",
    "                ent.append(t.text)\n",
    "            names.append(\" \".join(ent))\n",
    "        i += len(ent) + 1\n",
    "    return {'proper_nouns': names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3dc54",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02498a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Ruslan Borisov and Vlad Snisar rebuilt ConvoHub.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd6d95",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mathtext\n",
    "from mathtext.predict_intent import predict_intents_list\n",
    "predict_intents_list('you are mean forty 2')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcaf649",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_intents_list('you are jerk infinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638312e4",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de96854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_data(start, stop, step, question_num=None):\n",
    "    \"\"\" Generate list of possible questions with their contexts \"\"\"\n",
    "    seq = seq2str(start, stop, step)\n",
    "    templates = [\n",
    "        f\"Let's practice counting {seq2str(start, stop, step)}... \" \\\n",
    "        + f\"What is the next number in the sequence after {stop}?\",\n",
    "        f\"What number comes {step} after {stop}?\\n{seq}\",\n",
    "        f\"We're counting by {step}s. \" \\\n",
    "        + f\"What number is 1 after {stop}?\\n{seq}\",\n",
    "        f\"What is {step} number up from {stop}?\\n{seq}\",\n",
    "        f\"If we count up {step} from {stop}, \" \\\n",
    "        + f\"what number is next?\\n{seq}\",\n",
    "    ]\n",
    "    questions = []\n",
    "    for quest in templates:\n",
    "        questions.append({\n",
    "             \"question\": quest,\n",
    "             \"answer\": stop + step,\n",
    "             \"start\": start,\n",
    "             \"stop\": stop,\n",
    "             \"step\": step,\n",
    "             })\n",
    "    return questions[question_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995fdb3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = '<your_API_key_here>'\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:\" +\n",
    "    \"df7690\",  # <1>\n",
    "    input={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 100,\n",
    "        \"top_p\": 1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf7435",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor \n",
    "    chatbot Rori and a user who might be a student \n",
    "    in Africa or a parent. \n",
    "\n",
    "    Human says: {message}\n",
    "    Chatbot responds:\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"message\"],  # <1>\n",
    "    template=template)       \n",
    "chain = LLMChain(\n",
    "    llm=llm, verbose=True, prompt=prompt  # <2>\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56cbb2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d84319",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"Hi Bot! My name is Maria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dac03e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1020a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(message=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712daed8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c502c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    This is a conversation between a math tutor chatbot\n",
    "    Rori and a user who might be a student in Africa or a parent. \n",
    "    The chatbot introduces itself and asks if it's talking to a\n",
    "    student or to a parent. \n",
    "    If the user is a parent, Rori asks the parent for \n",
    "    permission for the child to use Rori over Whatsapp. \n",
    "    If the user is a student, Rori asks the student to\n",
    "     call their parents. \n",
    "    If the parent agrees, Rori thanks them and asks to give the phone to the student. \n",
    "    Provide the tutor's next response based on the conversation history.\n",
    "\n",
    "    {chat_history}\n",
    "    Parent: {message}\n",
    "    Tutor:\"\"\"\n",
    "onboarding_prompt = PromptTemplate(\n",
    "    input_variables = [\"chat_history\", \"message\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a4a6a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history')  # <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc6da2",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf19f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = ConversationBufferMemory\n",
    "    )\n",
    "onboarding_chain.prompt = onboarding_prompt\n",
    "onboarding_chain.predict(message=\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cff0f0",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c850cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_chain.predict(message=\"I'm a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d244b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_pt = \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760363c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathConversation():\n",
    "    def __init__(self, llm, prompt_string):\n",
    "        self.llm = llm\n",
    "        self.memory = \\\n",
    "            ConversationBufferMemory(\n",
    "                memory_key='history',\n",
    "                ai_prefix='tutor',\n",
    "                human_prefix=\"user\")\n",
    "        self.convo_chain = ConversationChain(\n",
    "            llm=llm, memory=self.memory)\n",
    "        self.convo_chain.prompt = PromptTemplate(\n",
    "            input_variables=[\"history\", \"input\"],\n",
    "            template=prompt_string)\n",
    "\n",
    "    def answer(self, user_input):\n",
    "        return self.convo_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae8df1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo = MathConversation(llm, onboarding_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75789869",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"I am a parent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085e3e1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0472ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_convo.answer(\"Yes, I agree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864fcb1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7724de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_quiz_pt = \"\"\"\n",
    "You are a math teacher that's teaching math to a third-grade\n",
    "student. Prompt the student to complete number sequences\n",
    "from the following list and compare their answer with the\n",
    "last number in the sequence:\n",
    "  - 9,10,11,12\n",
    "  - 38,39,40,41\n",
    "  - 2,4,6,8\n",
    "  - 1,5,9,13\n",
    "  {history}\n",
    "  student:{input}\n",
    "  tutor:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb645",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3153817",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo = MathConversation(llm, math_quiz_pt)\n",
    "math_convo.answer(\"Let's start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c05a5",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be844ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_convo.answer(\"12\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
