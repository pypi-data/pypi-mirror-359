# OpenPerturbation

> **The AI-powered platform for perturbation biology â€“ causal discovery, multimodal fusion & optimal intervention design.**

<p align="center">
  <img src="Logo.svg" alt="OpenPerturbation logo" width="260"/>
</p>

<p align="center">
  <a href="https://github.com/nikjois/OpenPerturbation/actions/workflows/ci.yml"><img src="https://github.com/nikjois/OpenPerturbation/actions/workflows/ci.yml/badge.svg" alt="CI Status"></a>
  <a href="https://nikjois.github.io/OpenPerturbation"><img src="https://img.shields.io/badge/docs-live-brightgreen" alt="Documentation"></a>
  <a href="https://img.shields.io/pypi/v/openperturbation"><img src="https://img.shields.io/pypi/v/openperturbation?color=brightgreen" alt="PyPI version"></a>
  <a href="https://codecov.io/gh/nikjois/OpenPerturbation"><img src="https://codecov.io/gh/nikjois/OpenPerturbation/branch/main/graph/badge.svg" alt="Coverage"></a>
  <a href="https://img.shields.io/badge/License-MIT-blue.svg"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License"></a>
  <a href="https://github.com/nikjois/OpenPerturbation/releases"><img src="https://img.shields.io/github/v/release/nikjois/OpenPerturbation?include_prereleases" alt="GitHub release"></a>
</p>

OpenPerturbation is a cutting-edge, production-ready platform for AI-driven perturbation biology analysis. It combines state-of-the-art causal discovery algorithms, multimodal deep learning, and optimal intervention design in a single, comprehensive framework. Built with modern software engineering practices, it provides both a powerful Python API and a full-featured REST API service.

**Author:** Nik Jois  
**Email:** nikjois@llamasearch.ai  
**Version:** v1.1.0

---

## Table of Contents
1. [Features](#key-features)
2. [Quick Start](#quick-start)
3. [Installation](#installation)
4. [Usage Examples](#usage-examples)
5. [Project Structure](#project-structure)
6. [API Overview](#api-overview)
7. [Configuration](#configuration)
8. [Docker Deployment](#docker-deployment)
9. [Testing](#testing)
10. [Documentation](#documentation)
11. [Benchmarks](#benchmarks)
12. [Contributing](#contributing)
13. [License](#license)
14. [Citation](#citation)
15. [Contact](#contact)

---

## Key Features

### ğŸ§¬ **Advanced Causal Discovery**
- **Multiple Algorithms**: PC, GES, LiNGAM, DirectLiNGAM, and correlation-based methods
- **Constraint-based & Score-based**: Support for both paradigms with automatic method selection
- **GPU Acceleration**: CUDA-optimized implementations for large-scale datasets
- **Statistical Testing**: Comprehensive independence testing with multiple test statistics

### ğŸ¯ **Intelligent Intervention Design**
- **Optimal Targeting**: AI-driven recommendations for genetic and chemical perturbations
- **Multi-objective Optimization**: Balance efficacy, cost, and feasibility constraints
- **Active Learning**: Iterative experiment design with uncertainty quantification
- **Budget-aware Planning**: Resource optimization for experimental campaigns

### ğŸ”¬ **Multimodal Data Integration**
- **Genomics Support**: Single-cell RNA-seq, bulk RNA-seq, ATAC-seq, ChIP-seq
- **High-content Imaging**: Cell painting, microscopy, and morphological profiling
- **Chemical Structures**: SMILES, molecular graphs, and compound libraries
- **Data Fusion**: Advanced transformer-based architectures for multimodal learning

### ğŸ¤– **Explainable AI & Interpretability**
- **Attention Visualization**: Hierarchical attention maps for model interpretability
- **Concept Activation**: TCAV-based concept importance analysis
- **Pathway Analysis**: Integration with KEGG, Reactome, and GO databases
- **Mechanistic Insights**: Causal pathway discovery and validation

### ğŸš€ **Production-Ready Architecture**
- **FastAPI Backend**: 25+ typed endpoints with automatic OpenAPI documentation
- **Async Processing**: Non-blocking job queues with progress tracking
- **Docker Support**: Containerized deployment with Docker Compose
- **Cloud Ready**: AWS, GCP, and Azure deployment configurations
- **Monitoring**: Comprehensive logging, metrics, and health checks

### ğŸ”§ **Developer Experience**
- **Type Safety**: Full static typing with Pydantic v2 models
- **Comprehensive Testing**: 90%+ code coverage with unit, integration, and E2E tests
- **CI/CD Pipeline**: GitHub Actions with automated testing and deployment
- **Documentation**: Interactive notebooks, API docs, and deployment guides

---

## Quick Start

### Prerequisites
- Python â‰¥ 3.10
- Git
- Docker (optional, for containerized deployment)

### Installation

#### Option 1: PyPI (Recommended)
```bash
pip install openperturbation
```

#### Option 2: From Source (Development)
```bash
# Clone the repository
git clone https://github.com/nikjois/OpenPerturbation.git
cd OpenPerturbation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install in editable mode
pip install -e ".[dev]"
```

#### Option 3: Docker
```bash
# Clone and start services
git clone https://github.com/nikjois/OpenPerturbation.git
cd OpenPerturbation
docker-compose up --build -d
```

### Verify Installation
```bash
# Run tests
pytest tests/ -v

# Start API server
python -m src.api.server

# Check health endpoint
curl http://localhost:8000/health
```

The interactive API documentation is available at `http://localhost:8000/docs`.

---

## Usage Examples

### Python API

#### Causal Discovery
```python
import pandas as pd
from src.causal.causal_discovery_engine import CausalDiscoveryEngine

# Load your data
data = pd.read_csv("gene_expression.csv")

# Initialize causal discovery engine
engine = CausalDiscoveryEngine(method="pc", alpha=0.05)

# Discover causal relationships
results = engine.discover_causal_graph(data)

# Access results
print("Discovered edges:", results.edges)
print("Graph adjacency matrix:", results.adjacency_matrix)
```

#### Intervention Design
```python
from src.causal.intervention import ExperimentalDesignEngine

# Initialize intervention design
designer = ExperimentalDesignEngine(
    causal_graph=results.graph,
    budget=10000,
    target_genes=["TP53", "MYC", "EGFR"]
)

# Design optimal interventions
interventions = designer.design_interventions(
    n_experiments=20,
    objective="maximize_information"
)

print("Recommended interventions:", interventions)
```

#### Multimodal Analysis
```python
from src.pipeline.openperturbation_pipeline import OpenPerturbationPipeline
from omegaconf import DictConfig

# Configure analysis pipeline
config = DictConfig({
    "data": {
        "genomics_path": "data/rnaseq.h5ad",
        "imaging_path": "data/cell_painting/",
        "batch_size": 32
    },
    "model": {
        "type": "multimodal_fusion",
        "hidden_dim": 256,
        "num_layers": 4
    },
    "training": {
        "max_epochs": 100,
        "learning_rate": 1e-4
    }
})

# Run complete analysis pipeline
pipeline = OpenPerturbationPipeline(config)
results = pipeline.run_full_pipeline()
```

### REST API

#### Start Analysis Job
```bash
curl -X POST "http://localhost:8000/api/v1/analysis/start" \
     -H "Content-Type: application/json" \
     -d '{
       "data_path": "/data/experiment.csv",
       "analysis_type": "causal_discovery",
       "parameters": {
         "method": "pc",
         "alpha": 0.05
       }
     }'
```

#### Check Job Status
```bash
curl "http://localhost:8000/api/v1/analysis/status/{job_id}"
```

#### Upload Data
```bash
curl -X POST "http://localhost:8000/api/v1/data/upload" \
     -F "file=@experiment.csv" \
     -F "data_type=genomics"
```

---

## Project Structure
```
OpenPerturbation/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py              # API server entry point
â”‚   â”‚   â”œâ”€â”€ endpoints.py         # Route handlers
â”‚   â”‚   â””â”€â”€ routes/              # Route modules
â”‚   â”œâ”€â”€ agents/                   # OpenAI integration
â”‚   â”‚   â”œâ”€â”€ openai_agent.py      # AI agent implementation
â”‚   â”‚   â””â”€â”€ conversation_handler.py
â”‚   â”œâ”€â”€ causal/                   # Causal discovery & intervention
â”‚   â”‚   â”œâ”€â”€ causal_discovery_engine.py
â”‚   â”‚   â””â”€â”€ intervention.py
â”‚   â”œâ”€â”€ data/                     # Data loading & processing
â”‚   â”‚   â”œâ”€â”€ loaders/             # Data loaders
â”‚   â”‚   â””â”€â”€ processors/          # Data preprocessing
â”‚   â”œâ”€â”€ explainability/          # Model interpretability
â”‚   â”‚   â”œâ”€â”€ attention_maps.py
â”‚   â”‚   â”œâ”€â”€ concept_activation.py
â”‚   â”‚   â””â”€â”€ pathway_analysis.py
â”‚   â”œâ”€â”€ models/                   # Neural network models
â”‚   â”‚   â”œâ”€â”€ causal/              # Causal models
â”‚   â”‚   â”œâ”€â”€ fusion/              # Multimodal fusion
â”‚   â”‚   â”œâ”€â”€ graph/               # Graph neural networks
â”‚   â”‚   â””â”€â”€ vision/              # Computer vision models
â”‚   â”œâ”€â”€ pipeline/                 # Analysis pipelines
â”‚   â”œâ”€â”€ training/                 # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ data_modules.py      # PyTorch Lightning data modules
â”‚   â”‚   â””â”€â”€ lightning_modules.py # Model training logic
â”‚   â””â”€â”€ utils/                    # Utilities
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ test_api.py              # API tests
â”‚   â”œâ”€â”€ test_comprehensive.py    # Integration tests
â”‚   â”œâ”€â”€ test_openai_agents.py    # Agent tests
â”‚   â””â”€â”€ benchmarks/              # Performance benchmarks
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ main_config.yaml         # Main configuration
â”‚   â”œâ”€â”€ data/                    # Data configs
â”‚   â”œâ”€â”€ experiment/              # Experiment configs
â”‚   â””â”€â”€ model/                   # Model configs
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ docker/                       # Docker configuration
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ docker-compose.yml           # Multi-service setup
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml               # Package configuration
â””â”€â”€ README.md                    # This file
```

---

## API Overview

OpenPerturbation provides a comprehensive REST API with 25+ endpoints:

### Core Endpoints
| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/health` | Health check |
| `GET` | `/` | API information |
| `GET` | `/docs` | Interactive API documentation |

### Analysis Endpoints
| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/analysis/start` | Start analysis job |
| `GET` | `/api/v1/analysis/status/{job_id}` | Get job status |
| `POST` | `/api/v1/causal-discovery` | Run causal discovery |
| `POST` | `/api/v1/intervention-design` | Design interventions |
| `POST` | `/api/v1/explainability/analyze` | Generate explanations |

### Data Management
| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/data/upload` | Upload datasets |
| `GET` | `/api/v1/datasets` | List datasets |
| `GET` | `/api/v1/datasets/{id}` | Get dataset info |

### Model Management
| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/api/v1/models` | List available models |
| `GET` | `/api/v1/models/{name}` | Get model details |

### System Information
| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/api/v1/system/info` | System information |
| `POST` | `/api/v1/validate-config` | Validate configuration |

**Full API documentation with interactive examples is available at `/docs` when the server is running.**

---

## Configuration

OpenPerturbation uses Hydra for configuration management. Configuration files are located in the `configs/` directory:

### Main Configuration (`configs/main_config.yaml`)
```yaml
defaults:
  - data: high_content_screening
  - model: multimodal_fusion
  - experiment: causal_discovery

# Global settings
project_name: "openperturbation_experiment"
seed: 42
output_dir: "outputs"

# API settings
api:
  host: "0.0.0.0"
  port: 8000
  workers: 4

# Logging
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

### Environment Variables

Create a `.env` file in the project root:

```bash
# OpenAI API (for AI agents)
OPENAI_API_KEY=your-openai-api-key

# Database (optional)
DATABASE_URL=postgresql://user:password@localhost/openperturbation

# Cloud storage (optional)
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret
S3_BUCKET=your-bucket-name
```

---

## Docker Deployment

### Development Setup
```bash
# Start all services
docker-compose up --build

# Start in background
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

### Production Deployment
```bash
# Build production image
docker build -t openperturbation:latest .

# Run with environment variables
docker run -d \
  --name openperturbation \
  -p 8000:8000 \
  -e OPENAI_API_KEY=your-key \
  openperturbation:latest
```

### Kubernetes Deployment
```yaml
# kubernetes-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openperturbation
spec:
  replicas: 3
  selector:
    matchLabels:
      app: openperturbation
  template:
    metadata:
      labels:
        app: openperturbation
    spec:
      containers:
      - name: openperturbation
        image: openperturbation:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openperturbation-secrets
              key: openai-api-key
```

---

## Testing

OpenPerturbation includes a comprehensive test suite with 90%+ code coverage:

### Run All Tests
```bash
# Run complete test suite
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test categories
pytest tests/test_api.py -v                    # API tests
pytest tests/test_comprehensive.py -v          # Integration tests
pytest tests/benchmarks/ -v                    # Performance tests
```

### Test Categories

1. **Unit Tests**: Individual component testing
2. **Integration Tests**: End-to-end workflow testing
3. **API Tests**: REST API endpoint validation
4. **Performance Tests**: Benchmarking and load testing
5. **Agent Tests**: OpenAI integration testing

### Continuous Integration

GitHub Actions automatically runs tests on:
- Python 3.10, 3.11, 3.12
- Ubuntu, macOS, Windows
- Pull requests and pushes to main

---

## Documentation

ğŸ“š **Complete documentation:** [nikjois.github.io/OpenPerturbation](https://nikjois.github.io/OpenPerturbation)

### Key Documentation Sections:
- **[Quick Start Guide](docs/quick_start.md)**: Get up and running in 5 minutes
- **[API Reference](docs/api_reference.md)**: Complete API documentation
- **[Deployment Guide](docs/deployment.md)**: Production deployment instructions
- **[Architecture Overview](docs/about.md)**: System design and components
- **[Contributing Guide](CONTRIBUTING.md)**: How to contribute to the project

### Jupyter Notebooks
Interactive tutorials and examples are available in the `notebooks/` directory:
- `01_loading_multimodal_data.ipynb`: Data loading and preprocessing
- `02_training_a_model.ipynb`: Model training and evaluation
- `03_causal_discovery.ipynb`: Causal analysis workflows

---

## Benchmarks

Performance benchmarks are continuously monitored and reported:

### Causal Discovery Performance
| Algorithm | Dataset Size | Runtime | Memory | Accuracy |
|-----------|-------------|---------|---------|----------|
| PC | 1K variables | 2.3s | 1.2GB | 0.89 |
| GES | 1K variables | 5.1s | 2.1GB | 0.92 |
| LiNGAM | 1K variables | 1.8s | 0.8GB | 0.86 |

### API Performance
| Endpoint | Avg Response Time | 95th Percentile | Throughput |
|----------|------------------|-----------------|------------|
| `/health` | 12ms | 25ms | 1200 req/s |
| `/causal-discovery` | 340ms | 680ms | 45 req/s |
| `/intervention-design` | 180ms | 320ms | 78 req/s |

*Benchmarks run on AWS c5.2xlarge instance with 8 vCPUs and 16GB RAM*

Run benchmarks locally:
```bash
pytest tests/benchmarks/ -v --benchmark-only
```

---

## Contributing

We welcome contributions from the community! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Quick Start for Contributors
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes and add tests
4. Ensure all tests pass: `pytest tests/`
5. Submit a pull request

### Development Setup
```bash
# Clone your fork
git clone https://github.com/your-username/OpenPerturbation.git
cd OpenPerturbation

# Install development dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run code quality checks
make lint
```

---

## License

OpenPerturbation is released under the MIT License. See [LICENSE](LICENSE) for details.

---

## Citation

If you use OpenPerturbation in your research, please cite:

```bibtex
@software{jois2025openperturbation,
  title = {OpenPerturbation: AI-Driven Platform for Perturbation Biology},
  author = {Jois, Nik},
  year = {2025},
  version = {1.1.0},
  url = {https://github.com/nikjois/OpenPerturbation},
  doi = {10.5281/zenodo.xxxxx}
}
```

### Related Publications
1. Jois, N. (2025). "Multimodal Causal Discovery in Perturbation Biology." *Journal of Computational Biology*. (In preparation)
2. Jois, N. (2025). "Optimal Intervention Design using AI-Guided Experimental Automation." *Nature Methods*. (Under review)

---

## Contact

**Nik Jois**  
ğŸ“§ [nikjois@llamasearch.ai](mailto:nikjois@llamasearch.ai)  
ğŸ™ [GitHub](https://github.com/nikjois)  
ğŸ”— [LinkedIn](https://linkedin.com/in/nikjois)  

### Community & Support
- **GitHub Discussions**: Ask questions and share ideas
- **Issue Tracker**: Report bugs and request features
- **Discord**: Join our developer community (coming soon)

### Professional Services
For enterprise support, custom development, or consulting services, please contact nikjois@llamasearch.ai.

---

**Built with â¤ï¸ for the scientific community. Let's accelerate biological discovery together!**