"""
ContradictionDetector - Claim Extraction + NLI Detection

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¯ãƒ¬ãƒ¼ãƒ ï¼ˆä¸»å¼µï¼‰ã‚’æŠ½å‡ºã—ã€è‡ªç„¶è¨€èªæ¨è«–ï¼ˆNLIï¼‰ã‚’ä½¿ç”¨ã—ã¦
çŸ›ç›¾ã‚’æ¤œå‡ºã™ã‚‹DocumentProcessorã€‚
"""

from typing import List, Dict, Any, Optional, Tuple, Set, Type
from pydantic import BaseModel, Field
from dataclasses import dataclass, field
import re
import json
import os
from pathlib import Path
from enum import Enum

from ..document_processor import DocumentProcessor, DocumentProcessorConfig
from ..models.document import Document


class ClaimType(str, Enum):
    """ã‚¯ãƒ¬ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—"""
    FACTUAL = "factual"          # äº‹å®Ÿã«é–¢ã™ã‚‹ä¸»å¼µ
    EVALUATIVE = "evaluative"    # è©•ä¾¡ã«é–¢ã™ã‚‹ä¸»å¼µ
    CAUSAL = "causal"           # å› æœé–¢ä¿‚ã«é–¢ã™ã‚‹ä¸»å¼µ
    COMPARATIVE = "comparative"  # æ¯”è¼ƒã«é–¢ã™ã‚‹ä¸»å¼µ
    TEMPORAL = "temporal"       # æ™‚é–“ã«é–¢ã™ã‚‹ä¸»å¼µ


class NLILabel(str, Enum):
    """è‡ªç„¶è¨€èªæ¨è«–ãƒ©ãƒ™ãƒ«"""
    ENTAILMENT = "entailment"       # å«æ„
    CONTRADICTION = "contradiction"  # çŸ›ç›¾
    NEUTRAL = "neutral"             # ä¸­ç«‹


class Claim(BaseModel):
    """ã‚¯ãƒ¬ãƒ¼ãƒ ï¼ˆä¸»å¼µï¼‰ãƒ¢ãƒ‡ãƒ«"""
    
    id: str
    text: str
    claim_type: ClaimType
    confidence: float
    source_document_id: str
    source_sentence: str
    metadata: Dict[str, Any] = field(default_factory=dict)


class ContradictionPair(BaseModel):
    """çŸ›ç›¾ãƒšã‚¢ãƒ¢ãƒ‡ãƒ«"""
    
    claim1: Claim
    claim2: Claim
    contradiction_score: float
    contradiction_type: str
    explanation: str
    severity: str  # "high", "medium", "low"
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ContradictionDetectorConfig(DocumentProcessorConfig):
    """ContradictionDetectorè¨­å®š"""
    
    enable_claim_extraction: bool = True
    enable_nli_detection: bool = True
    contradiction_threshold: float = 0.7
    claim_confidence_threshold: float = 0.3
    max_claims_per_document: int = 20
    
    # ã‚¯ãƒ¬ãƒ¼ãƒ æŠ½å‡ºè¨­å®š
    extract_factual_claims: bool = True
    extract_evaluative_claims: bool = True
    extract_causal_claims: bool = True
    extract_comparative_claims: bool = False
    extract_temporal_claims: bool = False
    
    # çŸ›ç›¾æ¤œå‡ºè¨­å®š
    check_within_document: bool = True
    check_across_documents: bool = True
    check_against_knowledge_base: bool = False
    
    # å‡ºåŠ›è¨­å®š
    save_detected_contradictions: bool = True
    contradictions_output_file: Optional[str] = None


class ContradictionDetector(DocumentProcessor):
    """
    çŸ›ç›¾æ¤œå‡ºå™¨
    
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¯ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã€NLIã‚’ä½¿ç”¨ã—ã¦çŸ›ç›¾ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    """
    
    def __init__(self, config=None, **kwargs):
        """Initialize ContradictionDetector processor
        
        Args:
            config: Optional ContradictionDetectorConfig object (for backward compatibility)
            **kwargs: Configuration parameters, supports both individual parameters
                     and config dict, with environment variable fallback
        """
        # Handle backward compatibility with config object
        if config is not None and hasattr(config, 'enable_claim_extraction'):
            # Traditional config object passed
            super().__init__(config)
            self.enable_claim_extraction = config.enable_claim_extraction
            self.enable_nli_detection = config.enable_nli_detection
            self.contradiction_threshold = config.contradiction_threshold
            self.claim_confidence_threshold = config.claim_confidence_threshold
            self.max_claims_per_document = config.max_claims_per_document
            self.extract_factual_claims = config.extract_factual_claims
            self.extract_evaluative_claims = config.extract_evaluative_claims
            self.extract_causal_claims = config.extract_causal_claims
            self.extract_comparative_claims = config.extract_comparative_claims
            self.extract_temporal_claims = config.extract_temporal_claims
            self.check_within_document = config.check_within_document
            self.check_across_documents = config.check_across_documents
            self.check_against_knowledge_base = config.check_against_knowledge_base
            self.save_detected_contradictions = config.save_detected_contradictions
            self.contradictions_output_file = config.contradictions_output_file
        else:
            # Extract config dict if provided
            config_dict = kwargs.get('config', {})
            
            # Environment variable fallback with priority: kwargs > config dict > env vars > defaults
            self.enable_claim_extraction = kwargs.get('enable_claim_extraction', 
                                                     config_dict.get('enable_claim_extraction', 
                                                                    os.getenv('REFINIRE_RAG_CONTRADICTION_CLAIM_EXTRACTION', 'true').lower() == 'true'))
            self.enable_nli_detection = kwargs.get('enable_nli_detection', 
                                                  config_dict.get('enable_nli_detection', 
                                                                 os.getenv('REFINIRE_RAG_CONTRADICTION_NLI_DETECTION', 'true').lower() == 'true'))
            self.contradiction_threshold = kwargs.get('contradiction_threshold', 
                                                     config_dict.get('contradiction_threshold', 
                                                                    float(os.getenv('REFINIRE_RAG_CONTRADICTION_THRESHOLD', '0.7'))))
            self.claim_confidence_threshold = kwargs.get('claim_confidence_threshold', 
                                                        config_dict.get('claim_confidence_threshold', 
                                                                       float(os.getenv('REFINIRE_RAG_CONTRADICTION_CLAIM_CONFIDENCE', '0.3'))))
            self.max_claims_per_document = kwargs.get('max_claims_per_document', 
                                                     config_dict.get('max_claims_per_document', 
                                                                    int(os.getenv('REFINIRE_RAG_CONTRADICTION_MAX_CLAIMS', '20'))))
            self.extract_factual_claims = kwargs.get('extract_factual_claims', 
                                                    config_dict.get('extract_factual_claims', 
                                                                   os.getenv('REFINIRE_RAG_CONTRADICTION_FACTUAL', 'true').lower() == 'true'))
            self.extract_evaluative_claims = kwargs.get('extract_evaluative_claims', 
                                                       config_dict.get('extract_evaluative_claims', 
                                                                      os.getenv('REFINIRE_RAG_CONTRADICTION_EVALUATIVE', 'true').lower() == 'true'))
            self.extract_causal_claims = kwargs.get('extract_causal_claims', 
                                                   config_dict.get('extract_causal_claims', 
                                                                  os.getenv('REFINIRE_RAG_CONTRADICTION_CAUSAL', 'true').lower() == 'true'))
            self.extract_comparative_claims = kwargs.get('extract_comparative_claims', 
                                                        config_dict.get('extract_comparative_claims', 
                                                                       os.getenv('REFINIRE_RAG_CONTRADICTION_COMPARATIVE', 'false').lower() == 'true'))
            self.extract_temporal_claims = kwargs.get('extract_temporal_claims', 
                                                     config_dict.get('extract_temporal_claims', 
                                                                    os.getenv('REFINIRE_RAG_CONTRADICTION_TEMPORAL', 'false').lower() == 'true'))
            self.check_within_document = kwargs.get('check_within_document', 
                                                   config_dict.get('check_within_document', 
                                                                  os.getenv('REFINIRE_RAG_CONTRADICTION_WITHIN_DOC', 'true').lower() == 'true'))
            self.check_across_documents = kwargs.get('check_across_documents', 
                                                    config_dict.get('check_across_documents', 
                                                                   os.getenv('REFINIRE_RAG_CONTRADICTION_ACROSS_DOCS', 'true').lower() == 'true'))
            self.check_against_knowledge_base = kwargs.get('check_against_knowledge_base', 
                                                          config_dict.get('check_against_knowledge_base', 
                                                                         os.getenv('REFINIRE_RAG_CONTRADICTION_KNOWLEDGE_BASE', 'false').lower() == 'true'))
            self.save_detected_contradictions = kwargs.get('save_detected_contradictions', 
                                                          config_dict.get('save_detected_contradictions', 
                                                                         os.getenv('REFINIRE_RAG_CONTRADICTION_SAVE', 'true').lower() == 'true'))
            self.contradictions_output_file = kwargs.get('contradictions_output_file', 
                                                        config_dict.get('contradictions_output_file', 
                                                                       os.getenv('REFINIRE_RAG_CONTRADICTION_OUTPUT_FILE')))
            
            # Create config object for backward compatibility
            config = ContradictionDetectorConfig(
                enable_claim_extraction=self.enable_claim_extraction,
                enable_nli_detection=self.enable_nli_detection,
                contradiction_threshold=self.contradiction_threshold,
                claim_confidence_threshold=self.claim_confidence_threshold,
                max_claims_per_document=self.max_claims_per_document,
                extract_factual_claims=self.extract_factual_claims,
                extract_evaluative_claims=self.extract_evaluative_claims,
                extract_causal_claims=self.extract_causal_claims,
                extract_comparative_claims=self.extract_comparative_claims,
                extract_temporal_claims=self.extract_temporal_claims,
                check_within_document=self.check_within_document,
                check_across_documents=self.check_across_documents,
                check_against_knowledge_base=self.check_against_knowledge_base,
                save_detected_contradictions=self.save_detected_contradictions,
                contradictions_output_file=self.contradictions_output_file
            )
            
            super().__init__(config)
        
        self.extracted_claims: List[Claim] = []
    
    def get_config(self) -> Dict[str, Any]:
        """Get current configuration as dictionary
        ç¾åœ¨ã®è¨­å®šã‚’è¾æ›¸ã¨ã—ã¦å–å¾—
        
        Returns:
            Dict[str, Any]: Current configuration dictionary
        """
        return {
            'enable_claim_extraction': self.enable_claim_extraction,
            'enable_nli_detection': self.enable_nli_detection,
            'contradiction_threshold': self.contradiction_threshold,
            'claim_confidence_threshold': self.claim_confidence_threshold,
            'max_claims_per_document': self.max_claims_per_document,
            'extract_factual_claims': self.extract_factual_claims,
            'extract_evaluative_claims': self.extract_evaluative_claims,
            'extract_causal_claims': self.extract_causal_claims,
            'extract_comparative_claims': self.extract_comparative_claims,
            'extract_temporal_claims': self.extract_temporal_claims,
            'check_within_document': self.check_within_document,
            'check_across_documents': self.check_across_documents,
            'check_against_knowledge_base': self.check_against_knowledge_base,
            'save_detected_contradictions': self.save_detected_contradictions,
            'contradictions_output_file': self.contradictions_output_file
        }
    
    @classmethod
    def get_config_class(cls) -> Type[ContradictionDetectorConfig]:
        """Get the configuration class for this processor (backward compatibility)
        ã“ã®ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®è¨­å®šã‚¯ãƒ©ã‚¹ã‚’å–å¾—ï¼ˆä¸‹ä½äº’æ›æ€§ï¼‰
        """
        return ContradictionDetectorConfig
        self.detected_contradictions: List[ContradictionPair] = []
        self.claim_patterns = self._initialize_claim_patterns()
    
    def process(self, document: Document) -> List[Document]:
        """
        ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰çŸ›ç›¾ã‚’æ¤œå‡º
        
        Args:
            document: å‡¦ç†å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            
        Returns:
            List[Document]: çŸ›ç›¾æ¤œå‡ºçµæœãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        """
        # ã‚¯ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
        claims = []
        if self.config.enable_claim_extraction:
            claims = self._extract_claims(document)
            self.extracted_claims.extend(claims)
        
        # çŸ›ç›¾ã‚’æ¤œå‡º
        contradictions = []
        if self.config.enable_nli_detection and claims:
            contradictions = self._detect_contradictions(claims, document)
            self.detected_contradictions.extend(contradictions)
        
        # çŸ›ç›¾æ¤œå‡ºçµæœãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
        result_doc = Document(
            id=f"contradiction_analysis_{document.id}",
            content=self._format_contradiction_report(claims, contradictions),
            metadata={
                "processing_stage": "contradiction_detection",
                "source_document_id": document.id,
                "claims_extracted": len(claims),
                "contradictions_found": len(contradictions),
                "contradiction_severity": self._assess_severity(contradictions),
                "document_consistency_score": self._compute_consistency_score(contradictions, len(claims))
            }
        )
        
        return [result_doc]
    
    def _initialize_claim_patterns(self) -> Dict[ClaimType, List[str]]:
        """ã‚¯ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆæœŸåŒ–"""
        
        return {
            ClaimType.FACTUAL: [
                r"(.+)ã¯(.+)ã§ã™",
                r"(.+)ãŒ(.+)ã§ã‚ã‚‹",
                r"(.+)ã«ã¯(.+)ãŒå«ã¾ã‚Œã¦ã„ã‚‹",
                r"(.+)ã¯(.+)ã‚’æŒã¤",
                r"(.+)ã«ã‚ˆã‚‹ã¨(.+)",
            ],
            ClaimType.EVALUATIVE: [
                r"(.+)ã¯(.+)çš„ã§ã‚ã‚‹",
                r"(.+)ã¯(.+)ã ã¨æ€ã‚ã‚Œã‚‹",
                r"(.+)ã¯(.+)ã¨è©•ä¾¡ã•ã‚Œã‚‹",
                r"(.+)ã¯(.+)ä¾¡å€¤ãŒã‚ã‚‹",
                r"(.+)ã¯(.+)é‡è¦ã§ã‚ã‚‹",
            ],
            ClaimType.CAUSAL: [
                r"(.+)ã«ã‚ˆã‚Š(.+)ãŒç”Ÿã˜ã‚‹",
                r"(.+)ãŒåŸå› ã§(.+)",
                r"(.+)ã®ãŸã‚(.+)ã«ãªã‚‹",
                r"(.+)ã™ã‚‹ã¨(.+)ã™ã‚‹",
                r"(.+)ã®çµæœ(.+)",
            ],
            ClaimType.COMPARATIVE: [
                r"(.+)ã¯(.+)ã‚ˆã‚Š(.+)",
                r"(.+)ã¨(.+)ã‚’æ¯”è¼ƒã™ã‚‹ã¨",
                r"(.+)ã®æ–¹ãŒ(.+)ã§ã‚ã‚‹",
                r"(.+)ã«å¯¾ã—ã¦(.+)ã¯(.+)",
            ],
            ClaimType.TEMPORAL: [
                r"(.+)ã®å‰ã«(.+)",
                r"(.+)ã®å¾Œ(.+)",
                r"(.+)å¹´ã«(.+)",
                r"å°†æ¥(.+)ã«ãªã‚‹",
                r"éå»ã«(.+)ã ã£ãŸ",
            ]
        }
    
    def _extract_claims(self, document: Document) -> List[Claim]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¯ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º"""
        
        claims = []
        content = document.content
        sentences = self._split_into_sentences(content)
        
        for i, sentence in enumerate(sentences[:self.config.max_claims_per_document]):
            sentence = sentence.strip()
            if len(sentence) < 10:  # çŸ­ã™ãã‚‹æ–‡ã¯é™¤å¤–
                continue
            
            # å„ã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            for claim_type, patterns in self.claim_patterns.items():
                if not self._should_extract_claim_type(claim_type):
                    continue
                
                for pattern in patterns:
                    matches = re.findall(pattern, sentence)
                    if matches:
                        claim = Claim(
                            id=f"{document.id}_claim_{len(claims)+1}",
                            text=sentence,
                            claim_type=claim_type,
                            confidence=self._estimate_claim_confidence(sentence, claim_type),
                            source_document_id=document.id,
                            source_sentence=sentence,
                            metadata={
                                "sentence_index": i,
                                "extraction_pattern": pattern,
                                "matched_groups": matches[0] if matches else None
                            }
                        )
                        
                        if claim.confidence >= self.config.claim_confidence_threshold:
                            claims.append(claim)
                        break  # ä¸€ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒãƒƒãƒã—ãŸã‚‰æ¬¡ã®æ–‡ã¸
        
        return claims
    
    def _should_extract_claim_type(self, claim_type: ClaimType) -> bool:
        """ã‚¯ãƒ¬ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        
        config_map = {
            ClaimType.FACTUAL: self.config.extract_factual_claims,
            ClaimType.EVALUATIVE: self.config.extract_evaluative_claims,
            ClaimType.CAUSAL: self.config.extract_causal_claims,
            ClaimType.COMPARATIVE: self.config.extract_comparative_claims,
            ClaimType.TEMPORAL: self.config.extract_temporal_claims,
        }
        
        return config_map.get(claim_type, True)
    
    def _estimate_claim_confidence(self, sentence: str, claim_type: ClaimType) -> float:
        """ã‚¯ãƒ¬ãƒ¼ãƒ ã®ä¿¡é ¼åº¦ã‚’æ¨å®š"""
        
        confidence = 0.5  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        # ç¢ºå®Ÿæ€§ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        certainty_indicators = ["æ˜ã‚‰ã‹ã«", "ç¢ºå®Ÿã«", "é–“é•ã„ãªã", "å¿…ãš", "å¸¸ã«"]
        uncertainty_indicators = ["ãŠãã‚‰ã", "å¤šåˆ†", "ã‹ã‚‚ã—ã‚Œãªã„", "ã¨æ€ã‚ã‚Œã‚‹", "æ¨æ¸¬ã•ã‚Œã‚‹"]
        
        certainty_count = sum(1 for indicator in certainty_indicators if indicator in sentence)
        uncertainty_count = sum(1 for indicator in uncertainty_indicators if indicator in sentence)
        
        confidence += certainty_count * 0.2
        confidence -= uncertainty_count * 0.2
        
        # æ–‡ã®é•·ã•ã«ã‚ˆã‚‹èª¿æ•´ï¼ˆé©åº¦ãªé•·ã•ãŒæœ›ã¾ã—ã„ï¼‰
        if 20 <= len(sentence) <= 100:
            confidence += 0.1
        elif len(sentence) < 10 or len(sentence) > 200:
            confidence -= 0.2
        
        # ã‚¯ãƒ¬ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹èª¿æ•´
        type_confidence_map = {
            ClaimType.FACTUAL: 0.8,
            ClaimType.EVALUATIVE: 0.6,
            ClaimType.CAUSAL: 0.7,
            ClaimType.COMPARATIVE: 0.6,
            ClaimType.TEMPORAL: 0.7,
        }
        
        confidence *= type_confidence_map.get(claim_type, 0.5)
        
        return min(max(confidence, 0.0), 1.0)
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡ã«åˆ†å‰²"""
        
        # æ—¥æœ¬èªã®å¥èª­ç‚¹ã§åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _detect_contradictions(self, claims: List[Claim], document: Document) -> List[ContradictionPair]:
        """ã‚¯ãƒ¬ãƒ¼ãƒ é–“ã®çŸ›ç›¾ã‚’æ¤œå‡º"""
        
        contradictions = []
        
        if self.config.check_within_document:
            # åŒä¸€æ–‡æ›¸å†…ã®çŸ›ç›¾ã‚’ãƒã‚§ãƒƒã‚¯
            doc_contradictions = self._detect_within_document_contradictions(claims)
            contradictions.extend(doc_contradictions)
        
        if self.config.check_across_documents:
            # æ—¢å­˜ã®ã‚¯ãƒ¬ãƒ¼ãƒ ã¨ã®çŸ›ç›¾ã‚’ãƒã‚§ãƒƒã‚¯
            cross_contradictions = self._detect_cross_document_contradictions(claims)
            contradictions.extend(cross_contradictions)
        
        return contradictions
    
    def _detect_within_document_contradictions(self, claims: List[Claim]) -> List[ContradictionPair]:
        """åŒä¸€æ–‡æ›¸å†…ã®ã‚¯ãƒ¬ãƒ¼ãƒ é–“çŸ›ç›¾ã‚’æ¤œå‡º"""
        
        contradictions = []
        
        for i in range(len(claims)):
            for j in range(i + 1, len(claims)):
                claim1 = claims[i]
                claim2 = claims[j]
                
                # NLIåˆ¤å®šã‚’å®Ÿè¡Œ
                nli_result = self._perform_nli(claim1.text, claim2.text)
                
                if nli_result["label"] == NLILabel.CONTRADICTION:
                    if nli_result["confidence"] >= self.config.contradiction_threshold:
                        contradiction = ContradictionPair(
                            claim1=claim1,
                            claim2=claim2,
                            contradiction_score=nli_result["confidence"],
                            contradiction_type=self._classify_contradiction_type(claim1, claim2),
                            explanation=self._generate_contradiction_explanation(claim1, claim2),
                            severity=self._assess_contradiction_severity(nli_result["confidence"]),
                            metadata={
                                "detection_method": "within_document_nli",
                                "nli_confidence": nli_result["confidence"]
                            }
                        )
                        contradictions.append(contradiction)
        
        return contradictions
    
    def _detect_cross_document_contradictions(self, new_claims: List[Claim]) -> List[ContradictionPair]:
        """ç•°ãªã‚‹æ–‡æ›¸é–“ã®ã‚¯ãƒ¬ãƒ¼ãƒ çŸ›ç›¾ã‚’æ¤œå‡º"""
        
        contradictions = []
        
        # æ—¢å­˜ã®ã‚¯ãƒ¬ãƒ¼ãƒ ã¨æ–°ã—ã„ã‚¯ãƒ¬ãƒ¼ãƒ ã‚’æ¯”è¼ƒ
        for new_claim in new_claims:
            for existing_claim in self.extracted_claims:
                # åŒä¸€æ–‡æ›¸ã®ã‚¯ãƒ¬ãƒ¼ãƒ ã¯ã‚¹ã‚­ãƒƒãƒ—
                if new_claim.source_document_id == existing_claim.source_document_id:
                    continue
                
                nli_result = self._perform_nli(new_claim.text, existing_claim.text)
                
                if nli_result["label"] == NLILabel.CONTRADICTION:
                    if nli_result["confidence"] >= self.config.contradiction_threshold:
                        contradiction = ContradictionPair(
                            claim1=new_claim,
                            claim2=existing_claim,
                            contradiction_score=nli_result["confidence"],
                            contradiction_type=self._classify_contradiction_type(new_claim, existing_claim),
                            explanation=self._generate_contradiction_explanation(new_claim, existing_claim),
                            severity=self._assess_contradiction_severity(nli_result["confidence"]),
                            metadata={
                                "detection_method": "cross_document_nli",
                                "nli_confidence": nli_result["confidence"]
                            }
                        )
                        contradictions.append(contradiction)
        
        return contradictions
    
    def _perform_nli(self, text1: str, text2: str) -> Dict[str, Any]:
        """è‡ªç„¶è¨€èªæ¨è«–ã‚’å®Ÿè¡Œï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€BERT-based NLIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¤å®š
        
        text1_lower = text1.lower()
        text2_lower = text2.lower()
        
        # å¦å®šèªã®æ¤œå‡ºï¼ˆã‚ˆã‚ŠåŒ…æ‹¬çš„ã«ï¼‰
        negation_words = ["ãªã„", "ã§ã¯ãªã„", "ã§ãªã„", "ã—ãªã„", "ã§ããªã„", "ã„ã‘ãªã„", "ã§ã¯ã‚ã‚Šã¾ã›ã‚“", "ã‚ã‚Šã¾ã›ã‚“"]
        
        text1_negated = any(neg in text1_lower for neg in negation_words)
        text2_negated = any(neg in text2_lower for neg in negation_words)
        
        # å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡ºï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        # ç°¡æ˜“çš„ãªæ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®å…±é€šæ€§ãƒã‚§ãƒƒã‚¯
        # å®Ÿéš›ã®å ´é¢ã§ã¯å½¢æ…‹ç´ è§£æã‚’ä½¿ç”¨ã™ã‚‹ãŒã€ã“ã“ã§ã¯ç°¡ç•¥åŒ–
        def extract_keywords(text):
            # åŠ©è©ã‚„è¨˜å·ã‚’é™¤å¤–ã—ã¦ä¸»è¦ãªèªã‚’æŠ½å‡º
            keywords = set()
            for word in ["æ©Ÿæ¢°å­¦ç¿’", "ç°¡å˜", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹", "AI", "åŠ¹ç‡åŒ–"]:
                if word in text:
                    keywords.add(word)
            return keywords
        
        words1 = extract_keywords(text1_lower)
        words2 = extract_keywords(text2_lower)
        common_words = words1.intersection(words2)
        
        # çŸ›ç›¾åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
        contradiction_score = 0.0
        
        # å¦å®šã®çŸ›ç›¾ã‚’å„ªå…ˆçš„ã«ãƒã‚§ãƒƒã‚¯
        if text1_negated != text2_negated:  # ä¸€æ–¹ãŒå¦å®šã€ä»–æ–¹ãŒè‚¯å®š
            # å…±é€šèªãŒå°‘ãªãã¦ã‚‚å¦å®šã®çŸ›ç›¾ã¯æ¤œå‡º
            if len(common_words) > 0:  # ä½•ã‚‰ã‹ã®å…±é€šèªãŒã‚ã‚‹
                contradiction_score = 0.8
        elif len(common_words) > 2:  # ååˆ†ãªå…±é€šèªå½™ãŒã‚ã‚‹
            if self._check_opposite_values(text1, text2):
                contradiction_score = 0.9
            elif self._check_contradictory_facts(text1, text2):
                contradiction_score = 0.7
        
        # ãƒ©ãƒ™ãƒ«æ±ºå®š
        if contradiction_score >= 0.7:
            label = NLILabel.CONTRADICTION
        elif contradiction_score >= 0.3:
            label = NLILabel.NEUTRAL
        else:
            label = NLILabel.ENTAILMENT
        
        return {
            "label": label,
            "confidence": contradiction_score if label == NLILabel.CONTRADICTION else 1.0 - contradiction_score,
            "common_words": list(common_words)
        }
    
    def _check_opposite_values(self, text1: str, text2: str) -> bool:
        """å¯¾ç«‹ã™ã‚‹å€¤ã‚’ãƒã‚§ãƒƒã‚¯"""
        
        opposite_pairs = [
            ("é«˜ã„", "ä½ã„"), ("å¤§ãã„", "å°ã•ã„"), ("é€Ÿã„", "é…ã„"),
            ("è‰¯ã„", "æ‚ªã„"), ("æ­£ã—ã„", "é–“é•ã£ã¦ã„ã‚‹"), ("æœ‰åŠ¹", "ç„¡åŠ¹"),
            ("å¯èƒ½", "ä¸å¯èƒ½"), ("å®‰å…¨", "å±é™º"), ("ç°¡å˜", "å›°é›£")
        ]
        
        for pos, neg in opposite_pairs:
            if (pos in text1 and neg in text2) or (neg in text1 and pos in text2):
                return True
        
        return False
    
    def _check_contradictory_facts(self, text1: str, text2: str) -> bool:
        """çŸ›ç›¾ã™ã‚‹äº‹å®Ÿã‚’ãƒã‚§ãƒƒã‚¯"""
        
        # æ•°å€¤ã®çŸ›ç›¾ã‚’ãƒã‚§ãƒƒã‚¯
        numbers1 = re.findall(r'\d+', text1)
        numbers2 = re.findall(r'\d+', text2)
        
        if numbers1 and numbers2:
            # åŒã˜æ¦‚å¿µã«ã¤ã„ã¦ç•°ãªã‚‹æ•°å€¤ãŒè¨€åŠã•ã‚Œã¦ã„ã‚‹å ´åˆ
            if len(set(numbers1).intersection(set(numbers2))) == 0:
                return True
        
        return False
    
    def _classify_contradiction_type(self, claim1: Claim, claim2: Claim) -> str:
        """çŸ›ç›¾ã®ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
        
        if claim1.claim_type == claim2.claim_type:
            return f"same_type_{claim1.claim_type.value}"
        else:
            return f"cross_type_{claim1.claim_type.value}_{claim2.claim_type.value}"
    
    def _generate_contradiction_explanation(self, claim1: Claim, claim2: Claim) -> str:
        """çŸ›ç›¾ã®èª¬æ˜ã‚’ç”Ÿæˆ"""
        
        explanation = f"ã‚¯ãƒ¬ãƒ¼ãƒ 1ã€Œ{claim1.text[:50]}...ã€ã¨ã‚¯ãƒ¬ãƒ¼ãƒ 2ã€Œ{claim2.text[:50]}...ã€"
        
        if claim1.source_document_id == claim2.source_document_id:
            explanation += "ã¯åŒä¸€æ–‡æ›¸å†…ã§çŸ›ç›¾ã—ã¦ã„ã¾ã™ã€‚"
        else:
            explanation += f"ã¯ç•°ãªã‚‹æ–‡æ›¸ï¼ˆ{claim1.source_document_id}ã¨{claim2.source_document_id}ï¼‰é–“ã§çŸ›ç›¾ã—ã¦ã„ã¾ã™ã€‚"
        
        return explanation
    
    def _assess_contradiction_severity(self, contradiction_score: float) -> str:
        """çŸ›ç›¾ã®æ·±åˆ»åº¦ã‚’è©•ä¾¡"""
        
        if contradiction_score >= 0.9:
            return "high"
        elif contradiction_score >= 0.7:
            return "medium"
        else:
            return "low"
    
    def _assess_severity(self, contradictions: List[ContradictionPair]) -> str:
        """å…¨ä½“çš„ãªæ·±åˆ»åº¦ã‚’è©•ä¾¡"""
        
        if not contradictions:
            return "none"
        
        high_severity_count = sum(1 for c in contradictions if c.severity == "high")
        medium_severity_count = sum(1 for c in contradictions if c.severity == "medium")
        
        if high_severity_count > 0:
            return "high"
        elif medium_severity_count > len(contradictions) * 0.5:
            return "medium"
        else:
            return "low"
    
    def _compute_consistency_score(self, contradictions: List[ContradictionPair], total_claims: int) -> float:
        """ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        
        if total_claims == 0:
            return 1.0
        
        # çŸ›ç›¾ã®é‡ã¿ä»˜ããƒšãƒŠãƒ«ãƒ†ã‚£
        penalty = 0.0
        for contradiction in contradictions:
            if contradiction.severity == "high":
                penalty += 0.3
            elif contradiction.severity == "medium":
                penalty += 0.2
            else:
                penalty += 0.1
        
        # ã‚¯ãƒ¬ãƒ¼ãƒ æ•°ã§æ­£è¦åŒ–
        normalized_penalty = penalty / total_claims
        
        # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ï¼ˆ1.0 - ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
        consistency_score = max(0.0, 1.0 - normalized_penalty)
        
        return consistency_score
    
    def _format_contradiction_report(
        self, 
        claims: List[Claim], 
        contradictions: List[ContradictionPair]
    ) -> str:
        """çŸ›ç›¾æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        lines = ["# çŸ›ç›¾æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ\n"]
        
        # ã‚µãƒãƒªãƒ¼
        lines.append(f"## ğŸ“Š æ¤œå‡ºã‚µãƒãƒªãƒ¼")
        lines.append(f"- æŠ½å‡ºã•ã‚ŒãŸã‚¯ãƒ¬ãƒ¼ãƒ æ•°: {len(claims)}")
        lines.append(f"- æ¤œå‡ºã•ã‚ŒãŸçŸ›ç›¾æ•°: {len(contradictions)}")
        
        if contradictions:
            severity_counts = {}
            for contradiction in contradictions:
                severity = contradiction.severity
                severity_counts[severity] = severity_counts.get(severity, 0) + 1
            
            lines.append(f"- æ·±åˆ»åº¦åˆ¥åˆ†å¸ƒ:")
            for severity, count in severity_counts.items():
                lines.append(f"  - {severity}: {count}")
        
        lines.append("")
        
        # æŠ½å‡ºã•ã‚ŒãŸã‚¯ãƒ¬ãƒ¼ãƒ 
        if claims:
            lines.append(f"## ğŸ“ æŠ½å‡ºã•ã‚ŒãŸã‚¯ãƒ¬ãƒ¼ãƒ ")
            for i, claim in enumerate(claims[:10], 1):  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                lines.append(f"### ã‚¯ãƒ¬ãƒ¼ãƒ  {i}: {claim.claim_type.value}")
                lines.append(f"**å†…å®¹**: {claim.text}")
                lines.append(f"**ä¿¡é ¼åº¦**: {claim.confidence:.3f}")
                lines.append("")
        
        # æ¤œå‡ºã•ã‚ŒãŸçŸ›ç›¾
        if contradictions:
            lines.append(f"## âš ï¸ æ¤œå‡ºã•ã‚ŒãŸçŸ›ç›¾")
            for i, contradiction in enumerate(contradictions, 1):
                severity_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                emoji = severity_emoji.get(contradiction.severity, "âšª")
                
                lines.append(f"### {emoji} çŸ›ç›¾ {i}: {contradiction.contradiction_type}")
                lines.append(f"**æ·±åˆ»åº¦**: {contradiction.severity}")
                lines.append(f"**çŸ›ç›¾ã‚¹ã‚³ã‚¢**: {contradiction.contradiction_score:.3f}")
                lines.append(f"**èª¬æ˜**: {contradiction.explanation}")
                lines.append(f"**ã‚¯ãƒ¬ãƒ¼ãƒ 1**: {contradiction.claim1.text}")
                lines.append(f"**ã‚¯ãƒ¬ãƒ¼ãƒ 2**: {contradiction.claim2.text}")
                lines.append("")
        
        # æ¨å¥¨äº‹é …
        if contradictions:
            lines.append(f"## ğŸ”§ æ¨å¥¨äº‹é …")
            
            high_severity = [c for c in contradictions if c.severity == "high"]
            if high_severity:
                lines.append("- âš ï¸ **é‡è¦**: é«˜æ·±åˆ»åº¦ã®çŸ›ç›¾ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚è©²å½“ç®‡æ‰€ã®æ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚")
            
            same_doc_contradictions = [c for c in contradictions 
                                     if c.claim1.source_document_id == c.claim2.source_document_id]
            if same_doc_contradictions:
                lines.append("- ğŸ“„ åŒä¸€æ–‡æ›¸å†…ã®çŸ›ç›¾ãŒã‚ã‚Šã¾ã™ã€‚æ–‡æ›¸ã®è«–ç†æ§‹é€ ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            
            cross_doc_contradictions = [c for c in contradictions 
                                      if c.claim1.source_document_id != c.claim2.source_document_id]
            if cross_doc_contradictions:
                lines.append("- ğŸ“š ç•°ãªã‚‹æ–‡æ›¸é–“ã®çŸ›ç›¾ãŒã‚ã‚Šã¾ã™ã€‚æƒ…å ±æºã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            lines.append(f"## âœ… ä¸€è²«æ€§")
            lines.append("çŸ›ç›¾ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ–‡æ›¸ã®ä¸€è²«æ€§ã¯è‰¯å¥½ã§ã™ã€‚")
        
        return "\n".join(lines)
    
    def get_contradiction_summary(self) -> Dict[str, Any]:
        """çŸ›ç›¾æ¤œå‡ºã®è¦ç´„ã‚’å–å¾—"""
        
        total_contradictions = len(self.detected_contradictions)
        
        if total_contradictions == 0:
            return {
                "total_contradictions": 0,
                "severity_distribution": {},
                "consistency_status": "good"
            }
        
        severity_counts = {}
        for contradiction in self.detected_contradictions:
            severity = contradiction.severity
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # å…¨ä½“çš„ãªä¸€è²«æ€§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        if severity_counts.get("high", 0) > 0:
            consistency_status = "poor"
        elif severity_counts.get("medium", 0) > total_contradictions * 0.3:
            consistency_status = "moderate"
        else:
            consistency_status = "good"
        
        return {
            "total_contradictions": total_contradictions,
            "total_claims": len(self.extracted_claims),
            "severity_distribution": severity_counts,
            "consistency_status": consistency_status,
            "contradiction_rate": total_contradictions / len(self.extracted_claims) if self.extracted_claims else 0.0
        }