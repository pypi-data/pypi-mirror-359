from .dashboard_abstract import AbstractDashboard
from typing import List, Any
import pandas as pd
import random
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
class OrganizationalDashboard (AbstractDashboard):
    streams: List[str] = ["issues"]
    issues_df: Any = None
    monte_carlo_simulations:int = 1000
    output_dir:str = "organization_charts"
    
    def model_post_init(self, __context):
        super().model_post_init(__context)
        self.issues_df = self.cache["issues"].to_pandas()

    
    def compute_stats(self) -> dict:
        """Compute overall organization stats."""
        # Group all issues by state
        state_counts = self.issues_df['state'].value_counts().to_dict()
        
        # Ensure we have open and closed counts
        open_count = state_counts.get('open', 0)
        closed_count = state_counts.get('closed', 0)
        
        # Calculate totals
        total_issues = open_count + closed_count
        percent_closed = round((closed_count / total_issues * 100), 1) if total_issues > 0 else 0
        
        return {
            'open': open_count,
            'closed': closed_count,
            'total': total_issues,
            'percent_closed': percent_closed
        }

    def generate_markdown_header(self, stats: dict) -> str:
        markdown = "# ðŸ“ˆ GitHub Issue Stats - OrganizaÃ§Ã£o\n\n"
        markdown += "| ðŸŸ¢ Abertas | ðŸ”´ Fechadas | ðŸ“¦ Total | âœ… % Fechadas |\n"
        markdown += "|----------|------------|---------|------------|\n"
        markdown += f"| {stats['open']} | {stats['closed']} | {stats['total']} | {stats['percent_closed']}% |\n\n"
        return markdown

    def plot_weekly_delivery(self, weekly_data: pd.DataFrame):
        """Create biweekly delivery chart for the entire organization."""
        filename = f"/{self.output_dir}/organization_biweekly.png"
        
        periods = weekly_data["period"].dt.strftime("%Y-%m-%d")
        promised = weekly_data["promised"]
        delivered = weekly_data["delivered"]
        percent_completed = weekly_data["percent_completed"].round(1)
        
        fig, ax1 = plt.subplots(figsize=(12, 5))
        bar_width = 0.4
        x = range(len(periods))
        
        # Bar chart for issues
        ax1.bar([i - bar_width / 2 for i in x], promised, width=bar_width, label="Prometido", color="navy")
        ax1.bar([i + bar_width / 2 for i in x], delivered, width=bar_width, label="Entregue", color="green")
        ax1.set_ylabel("Issues", fontsize=12)
        ax1.set_xticks(x)
        ax1.set_xticklabels(periods, rotation=45)
        ax1.tick_params(axis='y', labelsize=10)
        ax1.legend(loc="upper left", fontsize=10)
        
        # Line chart for completion percentage
        ax2 = ax1.twinx()
        ax2.plot(x, percent_completed, color="darkred", marker="o", linewidth=2, label="% ConcluÃ­do")
        ax2.set_ylabel("% ConcluÃ­do", fontsize=12)
        ax2.set_ylim(0, 110)
        ax2.tick_params(axis='y', labelsize=10)
        ax2.legend(loc="upper right", fontsize=10)
        
        plt.title("Entregas Quinzenais da OrganizaÃ§Ã£o (Ultimos 6 meses)", fontsize=14, pad=20)
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/organization_biweekly.png")
        plt.close()
        
        return filename

    def plot_burnup_chart(self, weekly_data: pd.DataFrame):
        """Create burnup chart for the entire organization."""
        filename = f"/{self.output_dir}/organization_burnup.png"
        
        # Sort by period and calculate cumulative metrics
        df = weekly_data.sort_values("period")
        df["cumulative_promised"] = df["promised"].cumsum()
        df["cumulative_delivered"] = df["delivered"].cumsum()
        
        # Convert periods to list for proper indexing
        periods_list = df["period"].dt.strftime("%Y-%m-%d").tolist()
        x = range(len(periods_list))
        
        plt.figure(figsize=(12, 5))
        
        # Plot the cumulative lines
        plt.plot(x, df["cumulative_promised"], label="Prometido acumulado", color="blue", marker="o", linewidth=2)
        plt.plot(x, df["cumulative_delivered"], label="Entregue acumulado", color="green", marker="o", linewidth=2)
        plt.fill_between(x, df["cumulative_delivered"], df["cumulative_promised"], color="lightgray", alpha=0.3)
        
        # Add trend line and projection if we have enough data
        if len(df) >= 2:
            z = pd.Series(df["cumulative_delivered"].values).interpolate(method='linear')
            trend = pd.Series(z).rolling(window=2, min_periods=1).mean()
            plt.plot(x, trend, linestyle="--", color="orange", label="TendÃªncia", linewidth=2)
            
            total_prometido = df["cumulative_promised"].max()
            if trend.iloc[-1] > 0 and len(trend) >= 2:
                delta = trend.iloc[-1] - trend.iloc[-2]
                if delta > 0:  # Only predict if there's positive progress
                    periods_to_finish = (total_prometido - trend.iloc[-1]) / delta
                    if 0 < periods_to_finish < 20:
                        # Calculate future date - multiply by 14 for days since we're using biweekly periods
                        last_period_date = pd.to_datetime(df["period"].iloc[-1])
                        predicted_date = last_period_date + pd.Timedelta(days=int(periods_to_finish * 14))
                        predicted_date_str = predicted_date.strftime('%Y-%m-%d')
                        
                        # Add vertical line at prediction
                        future_x = len(periods_list) - 1 + periods_to_finish
                        plt.axvline(x=future_x, linestyle=":", color="red", 
                                   label=f"PrevisÃ£o: {predicted_date_str}", linewidth=2)
        
        plt.xticks(x, periods_list, rotation=45)
        plt.xlabel("PerÃ­odo", fontsize=12)
        plt.ylabel("Issues acumuladas", fontsize=12)
        plt.title("ðŸ”¥ Burn-up Chart da OrganizaÃ§Ã£o  (Ultimos 6 meses) ", fontsize=14, pad=20)
        plt.legend(fontsize=10)
        plt.grid(axis='y', linestyle='--', alpha=0.3)
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/organization_burnup.png")
        plt.close()
        
        return filename, df
        
    def compute_weekly_delivery_stats(self) -> pd.DataFrame:
        """Compute biweekly stats for all issues across all repositories."""
        df = self.issues_df.copy()
        
        # Convert created_at to datetime and get two-week period
        df["created_at"] = pd.to_datetime(df["created_at"])
        # Use 2W for two-week periods instead of W for weekly
        df["period"] = df["created_at"].dt.to_period("2W").apply(lambda r: r.start_time)
        
        # Group by two-week period and state, calculate counts
        grouped = df.groupby(["period", "state"]).size().unstack(fill_value=0)
        
        # Ensure we have open and closed columns
        for col in ["open", "closed"]:
            if col not in grouped.columns:
                grouped[col] = 0
        
        # Calculate additional metrics
        grouped["promised"] = grouped["open"] + grouped["closed"]
        grouped["delivered"] = grouped["closed"]
        grouped["percent_completed"] = (grouped["closed"] / grouped["promised"]).fillna(0) * 100
        
        # Reset index to make period a column
        return grouped.reset_index()
    def run_monte_carlo_simulation(self, weekly_data: pd.DataFrame) -> dict:
        """Run Monte Carlo simulation for organization completion date."""
        # Sort data chronologically
        df = weekly_data.sort_values("period")
        
        # Extract historical velocities
        velocities = df["delivered"].tolist()
        
        # Calculate remaining work
        df["cumulative_promised"] = df["promised"].cumsum()
        df["cumulative_delivered"] = df["delivered"].cumsum()
        remaining_work = df["cumulative_promised"].max() - df["cumulative_delivered"].max()
        
        # If no work left, return completed status
        if remaining_work <= 0:
            return {
                'velocity_mean': np.mean(velocities),
                'velocity_p10': np.percentile(velocities, 10) if len(velocities) > 0 else 0,
                'velocity_p50': np.percentile(velocities, 50) if len(velocities) > 0 else 0,
                'velocity_p90': np.percentile(velocities, 90) if len(velocities) > 0 else 0,
                'completion_date_p10': "Complete",
                'completion_date_p50': "Complete",
                'completion_date_p90': "Complete",
                'simulation_data': [],
            }
        
        # Get last date as starting point
        last_date = pd.to_datetime(df["period"].max())
        
        # Run simulations
        simulation_data = []
        print(f"ðŸŽ² Executando {self.monte_carlo_simulations} simulaÃ§Ãµes Monte Carlo...")
        
        for _ in range(self.monte_carlo_simulations):
            # Bootstrap sampling of historical velocities
            sampled_velocities = random.choices(velocities, k=len(velocities))
            
            # Calculate mean velocity with random factor
            mean_velocity = np.mean(sampled_velocities) * random.uniform(0.8, 1.2)
            
            # Skip if velocity is zero or negative
            if mean_velocity <= 0:
                continue
            
            # Calculate periods to completion
            periods_to_completion = remaining_work / mean_velocity
            
            # Calculate completion date - now each period is 14 days (biweekly)
            completion_date = last_date + pd.Timedelta(days=int(periods_to_completion * 14))
            
            # Store simulation results
            simulation_data.append({
                'velocity': mean_velocity,
                'periods_to_completion': periods_to_completion,
                'completion_date': completion_date
            })
        
        # Calculate statistics from simulation results
        if not simulation_data:
            return {
                'velocity_mean': np.mean(velocities) if velocities else 0,
                'velocity_p10': 0, 
                'velocity_p50': 0,
                'velocity_p90': 0,
                'completion_date_p10': None,
                'completion_date_p50': None,
                'completion_date_p90': None,
                'simulation_data': [],
            }
        
        # Extract velocities and completion dates
        all_velocities = [sim['velocity'] for sim in simulation_data]
        all_completion_dates = [sim['completion_date'] for sim in simulation_data]
        
        # Calculate percentiles
        velocity_mean = np.mean(all_velocities)
        velocity_p10 = np.percentile(all_velocities, 10)
        velocity_p50 = np.percentile(all_velocities, 50)
        velocity_p90 = np.percentile(all_velocities, 90)
        
        # Calculate date percentiles
        completion_dates_sorted = sorted(all_completion_dates)
        idx_p10 = min(int(0.1 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        idx_p50 = min(int(0.5 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        idx_p90 = min(int(0.9 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        
        completion_date_p10 = completion_dates_sorted[idx_p10]
        completion_date_p50 = completion_dates_sorted[idx_p50]
        completion_date_p90 = completion_dates_sorted[idx_p90]
        
        print("âœ… SimulaÃ§Ãµes Monte Carlo concluÃ­das.")
        
        return {
            'velocity_mean': velocity_mean,
            'velocity_p10': velocity_p10,
            'velocity_p50': velocity_p50,
            'velocity_p90': velocity_p90,
            'completion_date_p10': completion_date_p10.strftime('%Y-%m-%d'),
            'completion_date_p50': completion_date_p50.strftime('%Y-%m-%d'),
            'completion_date_p90': completion_date_p90.strftime('%Y-%m-%d'),
            'simulation_data': simulation_data,
        }

    def plot_monte_carlo_simulations(self, mc_results: dict):
        """Create Monte Carlo visualizations for the organization."""
        if not mc_results['simulation_data']:
            return None, None
        
        # Completion date histogram
        mc_filename = f"/{self.output_dir}/organization_monte_carlo.png"
        plt.figure(figsize=(12, 6))
        
        # Extract completion dates
        completion_dates = [sim['completion_date'] for sim in mc_results['simulation_data']]
        
        # Calculate bins
        min_date = min(completion_dates)
        max_date = max(completion_dates)
        weeks_span = (max_date - min_date).days // 7 + 1
        bins = min(weeks_span, 20)
        
        # Convert dates to numerical format
        completion_dates_num = [(date - min_date).days / 7 for date in completion_dates]
        
        # Plot histogram
        plt.hist(completion_dates_num, bins=bins, alpha=0.7, color='blue', edgecolor='black', linewidth=0.5)
        
        # Add percentile lines
        p10_idx = int(len(completion_dates) * 0.1)
        p50_idx = int(len(completion_dates) * 0.5)
        p90_idx = int(len(completion_dates) * 0.9)
        
        sorted_dates_num = sorted(completion_dates_num)
        p10_value = sorted_dates_num[p10_idx] if p10_idx < len(sorted_dates_num) else sorted_dates_num[-1]
        p50_value = sorted_dates_num[p50_idx] if p50_idx < len(sorted_dates_num) else sorted_dates_num[-1]
        p90_value = sorted_dates_num[p90_idx] if p90_idx < len(sorted_dates_num) else sorted_dates_num[-1]
        
        plt.axvline(x=p10_value, color='green', linestyle='--', linewidth=2, label='P10 (Otimista)')
        plt.axvline(x=p50_value, color='orange', linestyle='--', linewidth=2, label='P50 (ProvÃ¡vel)')
        plt.axvline(x=p90_value, color='red', linestyle='--', linewidth=2, label='P90 (Conservador)')
        
        # Set x-axis ticks to show dates
        tick_positions = np.linspace(0, max(completion_dates_num), min(10, bins))
        tick_labels = [(min_date + pd.Timedelta(days=int(pos * 7))).strftime('%Y-%m-%d') for pos in tick_positions]
        plt.xticks(tick_positions, tick_labels, rotation=45)
        
        plt.title("ðŸŽ² SimulaÃ§Ã£o Monte Carlo - PrevisÃ£o de ConclusÃ£o", fontsize=14, pad=20)
        plt.xlabel("Data de ConclusÃ£o Prevista", fontsize=12)
        plt.ylabel("NÃºmero de SimulaÃ§Ãµes", fontsize=12)
        plt.grid(axis='y', linestyle='--', alpha=0.3)
        plt.legend(fontsize=10)
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/organization_monte_carlo.png")
        plt.close()
        
        # Velocity distribution chart
        vel_filename = f"/{self.output_dir}/organization_velocity_dist.png"
        plt.figure(figsize=(12, 5))
        
        velocities = [sim['velocity'] for sim in mc_results['simulation_data']]
        plt.hist(velocities, bins=min(20, len(velocities)//5 + 1), alpha=0.7, color='green', 
                edgecolor='black', linewidth=0.5)
        
        plt.axvline(x=mc_results['velocity_p10'], color='green', linestyle='--', linewidth=2, label='P10')
        plt.axvline(x=mc_results['velocity_p50'], color='orange', linestyle='--', linewidth=2, label='P50')
        plt.axvline(x=mc_results['velocity_p90'], color='red', linestyle='--', linewidth=2, label='P90')
        
        plt.title("ðŸ“Š DistribuiÃ§Ã£o de Velocidade da OrganizaÃ§Ã£o", fontsize=14, pad=20)
        plt.xlabel("Velocidade (issues/semana)", fontsize=12)
        plt.ylabel("FrequÃªncia", fontsize=12)
        plt.grid(axis='y', linestyle='--', alpha=0.3)
        plt.legend(fontsize=10)
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/organization_velocity_dist.png")
        plt.close()
        
        return mc_filename, vel_filename

    def create_monte_carlo_explanation(self, mc_results: dict) -> str:
        """Create explanation for Monte Carlo simulation results."""
        markdown = "### ExplicaÃ§Ã£o da SimulaÃ§Ã£o Monte Carlo\n\n"
        markdown += "| Conceito | ExplicaÃ§Ã£o |\n"
        markdown += "|---------|------------|\n"
        markdown += "| **O que Ã© Monte Carlo?** | TÃ©cnica estatÃ­stica que utiliza amostragens aleatÃ³rias repetidas para obter resultados numÃ©ricos e estimar probabilidades. |\n"
        markdown += "| **Como funciona a simulaÃ§Ã£o?** | 1) Coletamos o histÃ³rico de velocidade da organizaÃ§Ã£o (issues concluÃ­das/semana)<br>2) Fazemos 1000 simulaÃ§Ãµes com variaÃ§Ãµes aleatÃ³rias dessas velocidades<br>3) Para cada simulaÃ§Ã£o, calculamos quando o trabalho restante seria concluÃ­do<br>4) Organizamos os resultados e calculamos os percentis |\n"
        markdown += "| **O que significa P10?** | CenÃ¡rio otimista. Existe apenas 10% de chance de concluir o trabalho antes desta data. Ã‰ um resultado rÃ¡pido e favorÃ¡vel, mas menos provÃ¡vel. |\n"
        markdown += "| **O que significa P50?** | CenÃ¡rio mais provÃ¡vel. 50% de chance de terminar antes ou depois desta data. Ã‰ nossa melhor estimativa 'realista'. |\n"
        markdown += "| **O que significa P90?** | CenÃ¡rio conservador. Existe 90% de chance de concluir antes desta data. Ãštil para planejamento seguro, pois Ã© improvÃ¡vel atrasar alÃ©m deste ponto. |\n"
        markdown += "| **Por que usar Monte Carlo?** | Fornece intervalos de confianÃ§a em vez de datas Ãºnicas, reconhecendo a incerteza natural no desenvolvimento. Captura a variabilidade histÃ³rica da organizaÃ§Ã£o. |\n"
        markdown += "| **Como interpretar velocidades?** | Quanto maior a velocidade, mais rÃ¡pido a organizaÃ§Ã£o conclui issues. P10/P50/P90 para velocidades mostram diferentes cenÃ¡rios de produtividade que usamos nos cÃ¡lculos. |\n"
        
        # Add data context if we have simulation data
        if mc_results['simulation_data'] and len(mc_results['simulation_data']) > 0:
            historical_context = "| **Contexto dos dados** | "
            
            if mc_results['completion_date_p10'] != "Complete" and mc_results['completion_date_p10'] is not None:
                # Extract velocity info for volatility calculation
                historical_velocities = []
                for sim in mc_results['simulation_data']:
                    if 'velocity' in sim:
                        historical_velocities.append(sim['velocity'])
                
                # Calculate and interpret volatility
                if historical_velocities:
                    mean_velocity = np.mean(historical_velocities)
                    std_velocity = np.std(historical_velocities)
                    volatility = (std_velocity / mean_velocity) * 100 if mean_velocity > 0 else 0
                    
                    if volatility < 20:
                        volatility_desc = "baixa volatilidade (organizaÃ§Ã£o consistente)"
                    elif volatility < 40:
                        volatility_desc = "volatilidade moderada (alguma variaÃ§Ã£o na entrega)"
                    else:
                        volatility_desc = "alta volatilidade (entregas inconsistentes)"
                    
                    # Calculate spread between scenarios
                    if mc_results['completion_date_p10'] and mc_results['completion_date_p90']:
                        p10_date = pd.to_datetime(mc_results['completion_date_p10'])
                        p90_date = pd.to_datetime(mc_results['completion_date_p90'])
                        delta_days = (p90_date - p10_date).days
                        
                        historical_context += f"Com base nos dados histÃ³ricos, a organizaÃ§Ã£o tem {volatility_desc}. "
                        historical_context += f"A diferenÃ§a entre o cenÃ¡rio otimista e conservador Ã© de {delta_days} dias. "
                        
                        # Add recommendation based on data quality
                        if volatility < 30:
                            historical_context += f"Os dados sÃ£o confiÃ¡veis para planejamento. Recomendamos usar P50 ({mc_results['completion_date_p50']}) para comunicaÃ§Ã£o de prazos."
                        else:
                            historical_context += f"Devido Ã  alta variabilidade, considere usar P70-P80 para comunicaÃ§Ã£o de prazos ao invÃ©s de P50."
            
            historical_context += " |"
            markdown += historical_context + "\n"
        
        return markdown

    def generate_markdown_report(self, stats: dict, weekly_data: pd.DataFrame, mc_results: dict) -> str:
        """Generate complete markdown report for the organization."""
        # Limitar aos Ãºltimos 6 meses
        now = datetime.now()
        six_months_ago = now - pd.DateOffset(months=6)
        filtered_weekly = weekly_data[weekly_data["period"] >= six_months_ago]

        # Start with the header and summary stats
        markdown = self.generate_markdown_header(stats)
        markdown += "\n---\n"
        
        # Add biweekly delivery section
        weekly_file = self.plot_weekly_delivery(filtered_weekly)
        markdown += "## ðŸ“Š Entregas Quinzenais da OrganizaÃ§Ã£o\n\n"
        markdown += f"![Organization biweekly chart]({weekly_file})\n\n"
        
        # Add velocity stats
        avg_velocity = filtered_weekly["delivered"].mean().round(2)
        markdown += f"**Velocidade mÃ©dia quinzenal:** {avg_velocity} issues/quinzena\n\n"
        
        # Add biweekly data table
        markdown += "| PerÃ­odo | Prometido | Entregue | % ConcluÃ­do | Velocidade |\n"
        markdown += "|--------|------------|----------|--------------|------------|\n"
        
        for _, row in filtered_weekly.sort_values("period").iterrows():
            period = row['period'].strftime('%Y-%m-%d')
            markdown += f"| {period} | {int(row['promised'])} | {int(row['delivered'])} | {round(row['percent_completed'], 1)}% | {int(row['delivered'])} |\n"
        
        markdown += "\n"
        
        # Add burnup chart section
        burnup_file, _ = self.plot_burnup_chart(filtered_weekly)
        markdown += "## ðŸ”¥ Burn-up Chart da OrganizaÃ§Ã£o\n\n"
        markdown += f"![Organization burnup chart]({burnup_file})\n\n"
        
        # Add Monte Carlo section if we have simulation data
        if mc_results and mc_results['simulation_data']:
            mc_file, vel_file = self.plot_monte_carlo_simulations(mc_results)
            
            markdown += "## ðŸŽ² SimulaÃ§Ã£o Monte Carlo\n\n"
            markdown += f"![Organization monte carlo simulation]({mc_file})\n\n"
            markdown += f"![Organization velocity distribution]({vel_file})\n\n"
            
            # Add results table
            markdown += "### PrevisÃµes de Velocidade e ConclusÃ£o da OrganizaÃ§Ã£o\n\n"
            markdown += "| MÃ©trica | Valor |\n"
            markdown += "|--------|-------|\n"
            
            markdown += f"| Velocidade MÃ©dia | {mc_results['velocity_mean']:.2f} issues/quinzena |\n"
            markdown += f"| Velocidade P10 (Otimista) | {mc_results['velocity_p10']:.2f} issues/quinzena |\n"
            markdown += f"| Velocidade P50 (ProvÃ¡vel) | {mc_results['velocity_p50']:.2f} issues/quinzena |\n"
            markdown += f"| Velocidade P90 (Conservador) | {mc_results['velocity_p90']:.2f} issues/quinzena |\n"
            
            if mc_results['completion_date_p10'] == "Complete":
                markdown += f"| ConclusÃ£o | JÃ¡ concluÃ­do |\n"
            elif mc_results['completion_date_p10'] is None:
                markdown += f"| ConclusÃ£o | Dados insuficientes para previsÃ£o |\n"
            else:
                markdown += f"| Data de ConclusÃ£o P10 (Otimista) | {mc_results['completion_date_p10']} |\n"
                markdown += f"| Data de ConclusÃ£o P50 (ProvÃ¡vel) | {mc_results['completion_date_p50']} |\n"
                markdown += f"| Data de ConclusÃ£o P90 (Conservador) | {mc_results['completion_date_p90']} |\n"
            
            markdown += "\n"
            
            # Add Monte Carlo explanation
            markdown += self.create_monte_carlo_explanation(mc_results)
        
        return markdown
    def run_monte_carlo_simulation(self, weekly_data: pd.DataFrame) -> dict:
        """Run Monte Carlo simulation for organization completion date."""
        # Sort data chronologically
        df = weekly_data.sort_values("period")
        
        # Extract historical velocities
        velocities = df["delivered"].tolist()
        
        # Calculate remaining work
        df["cumulative_promised"] = df["promised"].cumsum()
        df["cumulative_delivered"] = df["delivered"].cumsum()
        remaining_work = df["cumulative_promised"].max() - df["cumulative_delivered"].max()
        
        # If no work left, return completed status
        if remaining_work <= 0:
            return {
                'velocity_mean': np.mean(velocities),
                'velocity_p10': np.percentile(velocities, 10) if len(velocities) > 0 else 0,
                'velocity_p50': np.percentile(velocities, 50) if len(velocities) > 0 else 0,
                'velocity_p90': np.percentile(velocities, 90) if len(velocities) > 0 else 0,
                'completion_date_p10': "Complete",
                'completion_date_p50': "Complete",
                'completion_date_p90': "Complete",
                'simulation_data': [],
            }
        
        # Get last date as starting point
        last_date = pd.to_datetime(df["period"].max())
        
        # Run simulations
        simulation_data = []
        print(f"ðŸŽ² Executando {self.monte_carlo_simulations} simulaÃ§Ãµes Monte Carlo...")
        
        for _ in range(self.monte_carlo_simulations):
            # Bootstrap sampling of historical velocities
            sampled_velocities = random.choices(velocities, k=len(velocities))
            
            # Calculate mean velocity with random factor
            mean_velocity = np.mean(sampled_velocities) * random.uniform(0.8, 1.2)
            
            # Skip if velocity is zero or negative
            if mean_velocity <= 0:
                continue
            
            # Calculate periods to completion
            periods_to_completion = remaining_work / mean_velocity
            
            # Calculate completion date - now each period is 14 days (biweekly)
            completion_date = last_date + pd.Timedelta(days=int(periods_to_completion * 14))
            
            # Store simulation results
            simulation_data.append({
                'velocity': mean_velocity,
                'periods_to_completion': periods_to_completion,
                'completion_date': completion_date
            })
        
        # Calculate statistics from simulation results
        if not simulation_data:
            return {
                'velocity_mean': np.mean(velocities) if velocities else 0,
                'velocity_p10': 0, 
                'velocity_p50': 0,
                'velocity_p90': 0,
                'completion_date_p10': None,
                'completion_date_p50': None,
                'completion_date_p90': None,
                'simulation_data': [],
            }
        
        # Extract velocities and completion dates
        all_velocities = [sim['velocity'] for sim in simulation_data]
        all_completion_dates = [sim['completion_date'] for sim in simulation_data]
        
        # Calculate percentiles
        velocity_mean = np.mean(all_velocities)
        velocity_p10 = np.percentile(all_velocities, 10)
        velocity_p50 = np.percentile(all_velocities, 50)
        velocity_p90 = np.percentile(all_velocities, 90)
        
        # Calculate date percentiles
        completion_dates_sorted = sorted(all_completion_dates)
        idx_p10 = min(int(0.1 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        idx_p50 = min(int(0.5 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        idx_p90 = min(int(0.9 * len(completion_dates_sorted)), len(completion_dates_sorted) - 1)
        
        completion_date_p10 = completion_dates_sorted[idx_p10]
        completion_date_p50 = completion_dates_sorted[idx_p50]
        completion_date_p90 = completion_dates_sorted[idx_p90]
        
        print("âœ… SimulaÃ§Ãµes Monte Carlo concluÃ­das.")
        
        return {
            'velocity_mean': velocity_mean,
            'velocity_p10': velocity_p10,
            'velocity_p50': velocity_p50,
            'velocity_p90': velocity_p90,
            'completion_date_p10': completion_date_p10.strftime('%Y-%m-%d'),
            'completion_date_p50': completion_date_p50.strftime('%Y-%m-%d'),
            'completion_date_p90': completion_date_p90.strftime('%Y-%m-%d'),
            'simulation_data': simulation_data,
        }





    def run(self):
        # Compute overall stats
        stats = self.compute_stats()
        print(f"ðŸ“Š EstatÃ­sticas calculadas: {stats['total']} issues totais, {stats['percent_closed']}% concluÃ­das.")
        
        # Compute weekly stats
        weekly_data = self.compute_weekly_delivery_stats()
        print(f"ðŸ“… Dados semanais processados para {len(weekly_data)} semanas.")
        
        # Run Monte Carlo simulation
        mc_results = self.run_monte_carlo_simulation(weekly_data)
        
        # Generate markdown report
        markdown = self.generate_markdown_report(stats, weekly_data, mc_results)
        if self.save_func is None:
            raise ValueError("FunÃ§Ã£o de salvamento nÃ£o definida. Por favor, forneÃ§a uma funÃ§Ã£o de salvamento vÃ¡lida.")
        self.save_func("organization_stats.md", markdown)
        print("ðŸ“„ RelatÃ³rio gerado com sucesso: organization_stats.md")
        
        
        