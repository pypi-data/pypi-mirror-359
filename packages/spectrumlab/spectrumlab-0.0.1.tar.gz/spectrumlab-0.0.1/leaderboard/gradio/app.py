import gradio as gr
import pandas as pd
import json
from pathlib import Path
from typing import Dict, Optional


class SpectralLeaderboard:
    def __init__(self, data_file: str = "../leaderboard.json"):
        self.data_file = Path(data_file)
        self.data = self._load_data()

    def _load_data(self) -> Dict:
        """åŠ è½½æ’è¡Œæ¦œæ•°æ®"""
        with open(self.data_file, "r", encoding="utf-8") as f:
            return json.load(f)

    def _format_accuracy(self, accuracy: Optional[float]) -> str:
        """æ ¼å¼åŒ–å‡†ç¡®ç‡æ˜¾ç¤º"""
        if accuracy is None:
            return "-"
        return f"{accuracy:.1f}%"

    def _calculate_average(self, results: Dict) -> Optional[float]:
        """è®¡ç®—å¹³å‡å‡†ç¡®ç‡ï¼Œå¿½ç•¥nullå€¼"""
        valid_accuracies = []
        for level_data in results.values():
            if level_data["accuracy"] is not None:
                valid_accuracies.append(level_data["accuracy"])

        if valid_accuracies:
            return sum(valid_accuracies) / len(valid_accuracies)
        return None

    def _get_model_type_icon(self, model_type: str) -> str:
        """è·å–æ¨¡å‹ç±»å‹å›¾æ ‡"""
        icons = {"open_source": "ğŸ”“", "proprietary": "ğŸ”’", "baseline": "ğŸ“Š"}
        return icons.get(model_type, "â“")

    def _get_multimodal_icon(self, is_multimodal: bool) -> str:
        """è·å–å¤šæ¨¡æ€å›¾æ ‡"""
        return "ğŸ‘ï¸" if is_multimodal else "ğŸ“"

    def _get_rank_display(self, rank: int) -> str:
        """è·å–æ’åæ˜¾ç¤ºï¼Œå‰ä¸‰åæ˜¾ç¤ºå¥–ç‰Œ"""
        medals = {1: "ğŸ¥‡", 2: "ğŸ¥ˆ", 3: "ğŸ¥‰"}
        return medals.get(rank, str(rank))

    def _create_link(self, text: str, url: str) -> str:
        """åˆ›å»ºHTMLé“¾æ¥"""
        if url and url.strip():
            return f'<a href="{url}" target="_blank" style="text-decoration: none; color: inherit;">{text}</a>'
        return text

    def get_leaderboard_df(
        self,
        model_type_filter: str = "All",
        multimodal_filter: str = "All",
        sort_by: str = "Average",
        ascending: bool = False,
    ) -> pd.DataFrame:
        """ç”Ÿæˆæ’è¡Œæ¦œDataFrame"""

        models = self.data["models"]

        # ç­›é€‰æ¨¡å‹
        filtered_models = []
        for model in models:
            # æ¨¡å‹ç±»å‹ç­›é€‰
            if model_type_filter != "All" and model["model_type"] != model_type_filter:
                continue

            # å¤šæ¨¡æ€ç­›é€‰
            if multimodal_filter == "Multimodal Only" and not model["is_multimodal"]:
                continue
            elif multimodal_filter == "Text Only" and model["is_multimodal"]:
                continue

            filtered_models.append(model)

        # æ„å»ºDataFrameæ•°æ®
        data = []
        for model in filtered_models:
            results = model["results"]

            # è®¡ç®—å¹³å‡åˆ†
            avg_accuracy = self._calculate_average(results)

            # åˆ›å»ºå¸¦é“¾æ¥çš„æ¨¡å‹åå’Œæäº¤è€…
            model_name_display = self._create_link(
                model["name"], model.get("name_link", "")
            )
            submitter_display = self._create_link(
                model["submitter"], model.get("submitter_link", "")
            )

            row = {
                "Type": self._get_model_type_icon(model["model_type"]),
                "Model": model_name_display,
                "Size": model["model_size"],
                "MM": self._get_multimodal_icon(model["is_multimodal"]),
                "Average": self._format_accuracy(avg_accuracy),
                "Signal": self._format_accuracy(results["Signal"]["accuracy"]),
                "Perception": self._format_accuracy(results["Perception"]["accuracy"]),
                "Semantic": self._format_accuracy(results["Semantic"]["accuracy"]),
                "Generation": self._format_accuracy(results["Generation"]["accuracy"]),
                "Submitter": submitter_display,
                "Date": (
                    model["submission_time"][:10] if model["submission_time"] else "-"
                ),
                # ç”¨äºæ’åºçš„æ•°å€¼åˆ—
                "avg_val": avg_accuracy or 0,
                "signal_val": results["Signal"]["accuracy"] or 0,
                "perception_val": results["Perception"]["accuracy"] or 0,
                "semantic_val": results["Semantic"]["accuracy"] or 0,
                "generation_val": results["Generation"]["accuracy"] or 0,
            }
            data.append(row)

        df = pd.DataFrame(data)

        if len(df) == 0:
            return df

        # æ’åº
        sort_mapping = {
            "Average": "avg_val",
            "Signal": "signal_val",
            "Perception": "perception_val",
            "Semantic": "semantic_val",
            "Generation": "generation_val",
            "Model": "Model",
            "Date": "Date",
        }

        sort_col = sort_mapping.get(sort_by, "avg_val")
        df = df.sort_values(by=sort_col, ascending=ascending)

        # æ·»åŠ å¸¦å¥–ç‰Œçš„æ’å
        ranks = []
        for i in range(len(df)):
            rank_num = i + 1
            ranks.append(self._get_rank_display(rank_num))

        df.insert(0, "Rank", ranks)

        # ç§»é™¤ç”¨äºæ’åºçš„è¾…åŠ©åˆ—
        display_columns = [
            "Rank",
            "Type",
            "Model",
            "Size",
            "MM",
            "Average",
            "Signal",
            "Perception",
            "Semantic",
            "Generation",
            "Submitter",
            "Date",
        ]
        return df[display_columns]

    def get_subcategory_details(self, model_name: str) -> pd.DataFrame:
        """è·å–æ¨¡å‹çš„å­ç±»åˆ«è¯¦ç»†ç»“æœ"""
        # ç§»é™¤HTMLæ ‡ç­¾è¿›è¡ŒåŒ¹é…
        clean_model_name = model_name
        if "<a href=" in model_name:
            # æå–é“¾æ¥ä¸­çš„æ–‡æœ¬
            import re

            match = re.search(r">([^<]+)<", model_name)
            if match:
                clean_model_name = match.group(1)

        for model in self.data["models"]:
            if model["name"] == clean_model_name:
                data = []
                for level, level_data in model["results"].items():
                    for subcat, subcat_data in level_data["subcategories"].items():
                        data.append(
                            {
                                "Level": level,
                                "Subcategory": subcat,
                                "Accuracy": self._format_accuracy(
                                    subcat_data["accuracy"]
                                ),
                            }
                        )
                return pd.DataFrame(data)
        return pd.DataFrame()


def create_leaderboard():
    """åˆ›å»ºæ’è¡Œæ¦œGradioç•Œé¢"""

    leaderboard = SpectralLeaderboard()

    with gr.Blocks(
        title="ğŸ”¬ Spectral Hub Leaderboard",
        theme=gr.themes.Default(),
        css="""
        .gradio-container {
            max-width: 1400px !important;
        }
        .dataframe table {
            border-collapse: collapse !important;
        }
        .dataframe td, .dataframe th {
            padding: 8px 12px !important;
            border: 1px solid #e1e5e9 !important;
        }
        .dataframe th {
            background-color: #f8f9fa !important;
            font-weight: 600 !important;
        }
        .dataframe tr:nth-child(even) {
            background-color: #f8f9fa !important;
        }
        .dataframe tr:hover {
            background-color: #e8f4f8 !important;
        }
        """,
    ) as demo:
        gr.Markdown(
            """
            # ğŸ† Spectral Hub Leaderboard
            
            A comprehensive benchmark for evaluating large language models on **spectroscopic analysis tasks**.
            
            ğŸ“Š **Evaluation Levels**: Signal Processing, Perception, Semantic Understanding, Generation  
            ğŸ”¬ **Domains**: IR, NMR, UV-Vis, Mass Spectrometry and more  
            ğŸŒŸ **Multimodal**: Support for both text-only and vision-language models
            """
        )

        with gr.Row():
            info = leaderboard.data["leaderboard_info"]
            gr.Markdown(
                f"""
                **ğŸ“ˆ Stats**: {info["total_models"]} models evaluated  
                **ğŸ… Rankings**: ğŸ¥‡ğŸ¥ˆğŸ¥‰ medals for top performers  
                **ğŸ”— Submit**: Send evaluation results to contribute your model!
                """
            )

        with gr.Row():
            with gr.Column(scale=2):
                model_type_filter = gr.Dropdown(
                    choices=["All", "open_source", "proprietary", "baseline"],
                    value="All",
                    label="ğŸ·ï¸ Model Type",
                )

            with gr.Column(scale=2):
                multimodal_filter = gr.Dropdown(
                    choices=["All", "Multimodal Only", "Text Only"],
                    value="All",
                    label="ğŸ‘ï¸ Modality",
                )

            with gr.Column(scale=2):
                sort_by = gr.Dropdown(
                    choices=[
                        "Average",
                        "Signal",
                        "Perception",
                        "Semantic",
                        "Generation",
                        "Model",
                        "Date",
                    ],
                    value="Average",
                    label="ğŸ“Š Sort By",
                )

            with gr.Column(scale=1):
                ascending = gr.Checkbox(value=False, label="â¬†ï¸ Ascending")

            with gr.Column(scale=1):
                refresh_btn = gr.Button("ğŸ”„ Refresh", variant="secondary")

        # ä¸»æ’è¡Œæ¦œè¡¨æ ¼
        leaderboard_table = gr.Dataframe(
            value=leaderboard.get_leaderboard_df(),
            interactive=False,
            wrap=True,
            datatype=["html"] * 12,
            column_widths=[
                "6%",
                "5%",
                "18%",
                "8%",
                "5%",
                "10%",
                "10%",
                "10%",
                "10%",
                "10%",
                "16%",
                "10%",
            ],
            label="ğŸ† Model Rankings",
        )

        # æ¨¡å‹è¯¦ç»†ä¿¡æ¯
        with gr.Accordion("ğŸ“‹ Model Details", open=False):
            model_select = gr.Dropdown(
                choices=[model["name"] for model in leaderboard.data["models"]],
                label="Select Model for Details",
            )

            with gr.Row():
                with gr.Column():
                    subcategory_table = gr.Dataframe(label="ğŸ“Š Subcategory Results")

                with gr.Column():
                    model_info = gr.Markdown(label="â„¹ï¸ Model Information")

        # å›¾ä¾‹è¯´æ˜
        with gr.Accordion("ğŸ“– Legend & Info", open=False):
            gr.Markdown(
                """
                ### ğŸ” Column Explanations
                
                - **Rank**: ğŸ¥‡ 1st place, ğŸ¥ˆ 2nd place, ğŸ¥‰ 3rd place, then numbers
                - **Type**: ğŸ”“ Open Source, ğŸ”’ Proprietary, ğŸ“Š Baseline
                - **MM**: ğŸ‘ï¸ Multimodal, ğŸ“ Text-only  
                - **Average**: Average accuracy across all evaluated levels
                - **Signal**: Low-level signal processing tasks
                - **Perception**: Mid-level feature extraction tasks  
                - **Semantic**: High-level understanding tasks
                - **Generation**: Spectrum generation tasks
                
                ### ğŸ“ Notes
                - "-" indicates the model was not evaluated on that benchmark
                - Rankings are based on average performance across evaluated tasks
                - Multimodal models can process both text and images
                - Click on model names and submitters to visit their pages
                """
            )

        def update_leaderboard(model_type, multimodal, sort_by_val, asc):
            """æ›´æ–°æ’è¡Œæ¦œ"""
            return leaderboard.get_leaderboard_df(
                model_type_filter=model_type,
                multimodal_filter=multimodal,
                sort_by=sort_by_val,
                ascending=asc,
            )

        def update_model_details(model_name):
            """æ›´æ–°æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
            if not model_name:
                return pd.DataFrame(), ""

            # è·å–å­ç±»åˆ«è¯¦æƒ…
            subcategory_df = leaderboard.get_subcategory_details(model_name)

            # è·å–æ¨¡å‹åŸºæœ¬ä¿¡æ¯
            for model in leaderboard.data["models"]:
                if model["name"] == model_name:
                    info_md = f"""
                    ### {model["name"]}
                    
                    **ğŸ‘¤ Submitter**: {model["submitter"]}  
                    **ğŸ“… Submission**: {model["submission_time"][:10] if model["submission_time"] else "Unknown"}  
                    **ğŸ·ï¸ Type**: {model["model_type"]}  
                    **ğŸ“ Size**: {model["model_size"]}  
                    **ğŸ‘ï¸ Multimodal**: {"Yes" if model["is_multimodal"] else "No"}  
                    
                    **ğŸ“ Description**: {model["model_info"]["description"]}
                    
                    **ğŸ”— Links**:  
                    - [Homepage]({model["model_info"]["homepage"]}) {model["model_info"]["homepage"]}
                    - [Paper]({model["model_info"]["paper"]}) {model["model_info"]["paper"]}  
                    - [Code]({model["model_info"]["code"]}) {model["model_info"]["code"]}
                    """
                    return subcategory_df, info_md

            return pd.DataFrame(), ""

        # äº‹ä»¶ç»‘å®š
        for component in [model_type_filter, multimodal_filter, sort_by, ascending]:
            component.change(
                fn=update_leaderboard,
                inputs=[model_type_filter, multimodal_filter, sort_by, ascending],
                outputs=[leaderboard_table],
            )

        refresh_btn.click(
            fn=update_leaderboard,
            inputs=[model_type_filter, multimodal_filter, sort_by, ascending],
            outputs=[leaderboard_table],
        )

        model_select.change(
            fn=update_model_details,
            inputs=[model_select],
            outputs=[subcategory_table, model_info],
        )

    return demo


if __name__ == "__main__":
    app = create_leaderboard()
    print("ğŸš€ Starting Spectral Hub Leaderboard...")
    app.launch(
        server_name="0.0.0.0",
        share=True,
        show_api=False,
        inbrowser=True,
    )
