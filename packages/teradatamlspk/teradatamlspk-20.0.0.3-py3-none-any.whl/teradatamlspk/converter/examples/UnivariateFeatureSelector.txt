PySpark code

>>> from pyspark.ml.feature import UnivariateFeatureSelector, VectorAssembler
>>> df = VectorAssembler(inputCols=['feature1', 'feature2', 'feature3'], outputCol="features").transform(df)
>>> selector = UnivariateFeatureSelector(featuresCol="features", outputCol="selectedFeatures")
>>> selector.setFeatureType("continuous").setLabelType("categorical").setSelectionThreshold(2)
>>> scaled_df = selector.fit(df).transform(df)
>>> scaled_df.show()
+--------+--------+--------+-----+-------------+----------------+
|feature1|feature2|feature3|label|     features|selectedFeatures|
+--------+--------+--------+-----+-------------+----------------+
|     1.7|     8.8|     1.2|  3.0|[1.7,8.8,1.2]|       [1.7,8.8]|
|     4.4|     7.3|     9.5|  2.0|[4.4,7.3,9.5]|       [4.4,7.3]|
|     7.6|     5.7|     2.5|  1.0|[7.6,5.7,2.5]|       [7.6,5.7]|
|     2.3|     4.1|     2.5|  4.0|[2.3,4.1,2.5]|       [2.3,4.1]|
+--------+--------+--------+-----+-------------+----------------+

teradatamlspk code

>>> from teradatamlspk.ml.feature import UnivariateFeatureSelector
>>> selector = UnivariateFeatureSelector(featuresCol = ['feature1', 'feature2', 'feature3'], outputCol="selectedFeatures")
>>> selector.setFeatureType("continuous").setLabelType("categorical").setSelectionThreshold(2)
>>> scaled_df = selector.fit(df).transform(df)
>>> scaled_df.show()
+--------+--------+--------+-----------------------+-----------------------+
|feature1|feature2|feature3|selectkbest_transform_1|selectkbest_transform_2|
+--------+--------+--------+-----------------------+-----------------------+
|     1.7|     8.8|     1.2|                    1.7|                    8.8|
|     7.6|     5.7|     2.5|                    7.6|                    5.7|
|     4.4|     7.3|     9.5|                    4.4|                    7.3|
|     2.3|     4.1|     2.5|                    2.3|                    4.1|
+--------+--------+--------+-----------------------+-----------------------+
 