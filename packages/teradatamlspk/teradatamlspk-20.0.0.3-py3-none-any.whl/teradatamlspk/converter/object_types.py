from typing import Any
from enum import Enum
import datetime


general_dict = {"fromInternal": Any,
                "json": str,
                "jsonValue":  [str or dict], 
                "needConversion": bool,
                "simpleString": str,
                "toInternal": Any}

class PysparkObjects(Enum):
    Column = "Column"
    DataFrame = "DataFrame"
    GroupedData = "GroupedData"
    Row  = "Row"
    Iterator = "Iterator"
    WindowSpec = "WindowSpec"
    RDD = "RDD"
    StructType = "StructType"
    DataFrameNaFunctions = "DataFrameNaFunctions"
    DataFrameStatFunctions = "DataFrameStatFunctions"
    PandasOnSparkDataFrame = "PandasOnSparkDataFrame"
    DataFrameWriterV2 = "DataFrameWriterV2"
    StorageLevel = "StorageLevel"
    PandasDataFrameLike = "PandasDataFrameLike"
    DataFrameReader = "DataFrameReader"
    DataFrameWriter = "DataFrameWriter"
    DataStreamWriter = "DataStreamWriter"
    sparkSession = "sparkSession"
    PandasCogroupedOps = "PandasCogroupedOps"
    UDF = "UDF"
    
spark_objects_ = {
    "pyspark":{

        "sql":{
            
            "DataFrame":{
                "agg": PysparkObjects.DataFrame,
                "alias": PysparkObjects.DataFrame,
                "approxQuantile": list,
                "cache": PysparkObjects.DataFrame,
                "checkpoint": PysparkObjects.DataFrame,
                "coalesce": PysparkObjects.DataFrame,
                "colRegex": PysparkObjects.Column,
                "collect": list,
                "columns": list,
                "corr": float,
                "count": int,
                "cov": float,
                "createGlobalTempView": None,
                "createOrReplaceGlobalTempView": None,
                "createOrReplaceTempView": None,
                "createTempView": None,
                "crossJoin": PysparkObjects.DataFrame,
                "crosstab": PysparkObjects.DataFrame,
                "cube": PysparkObjects.GroupedData,
                "describe": PysparkObjects.DataFrame,
                "distinct": PysparkObjects.DataFrame,
                "drop": PysparkObjects.DataFrame,
                "dropDuplicates": PysparkObjects.DataFrame,
                "dropDuplicatesWithinWatermark": PysparkObjects.DataFrame,
                "drop_duplicates": PysparkObjects.DataFrame,
                "dropna": PysparkObjects.DataFrame,
                "dtypes": list,
                "exceptAll": PysparkObjects.DataFrame,
                "explain": None,
                "fillna": PysparkObjects.DataFrame,
                "filter": PysparkObjects.DataFrame,
                "first": PysparkObjects.Row,
                "foreach": None,
                "foreachPartition": None,
                "freqItems": PysparkObjects.DataFrame,
                "groupBy": PysparkObjects.GroupedData,
                "head": [PysparkObjects.Row or list],
                "hint": PysparkObjects.DataFrame,
                "inputFiles":list,
                "intersect": PysparkObjects.DataFrame,
                "intersectAll": PysparkObjects.DataFrame,
                "isEmpty": bool,
                "isLocal": bool,
                "isStreaming": bool,
                "limit": PysparkObjects.DataFrame,
                "join": PysparkObjects.DataFrame,
                "localCheckpoint": PysparkObjects.DataFrame,
                "mapInPandas": PysparkObjects.DataFrame,
                "mapInArrow": PysparkObjects.DataFrame,
                "melt": PysparkObjects.DataFrame,
                "na": PysparkObjects.DataFrameNaFunctions,
                "observe": PysparkObjects.DataFrame,
                "offset": PysparkObjects.DataFrame,
                "orderBy": PysparkObjects.DataFrame,
                "persist": PysparkObjects.DataFrame,
                "printSchema": None,
                "randomSplit": list,
                "rdd": PysparkObjects.RDD,
                "registerTempTable": None,
                "repartition": PysparkObjects.DataFrame,
                "repartitionByRange": PysparkObjects.DataFrame,
                "replace": PysparkObjects.DataFrame,
                "rollup": PysparkObjects.GroupedData,
                "sameSemantics": bool,
                "sample": PysparkObjects.DataFrame,
                "sampleBy": PysparkObjects.DataFrame,
                "select": PysparkObjects.DataFrame,
                "selectExpr": PysparkObjects.DataFrame,
                "semanticHash": int,
                "show": None,
                "sort": PysparkObjects.DataFrame,
                "sortWithinPartitions": PysparkObjects.DataFrame,
                "subtract": PysparkObjects.DataFrame,
                "sparkSession": PysparkObjects.sparkSession,
                "stat": PysparkObjects.DataFrameStatFunctions,
                "storageLevel": PysparkObjects.StorageLevel,
                "summary": PysparkObjects.DataFrame,
                "tail": list,
                "take": list,
                "to": PysparkObjects.DataFrame,
                "toDF": PysparkObjects.DataFrame,
                "toJSON": PysparkObjects.RDD,
                "toLocalIterator": PysparkObjects.Iterator,
                "toPandas": PysparkObjects.PandasDataFrameLike,
                "to_pandas_on_spark":PysparkObjects.PandasOnSparkDataFrame,
                "transform": PysparkObjects.DataFrame,
                "union": PysparkObjects.DataFrame,
                "unionAll": PysparkObjects.DataFrame,
                "unionByName": PysparkObjects.DataFrame,
                "unpersist": PysparkObjects.DataFrame,
                "unpivot": PysparkObjects.DataFrame,
                "where": PysparkObjects.DataFrame,
                "withColumn": PysparkObjects.DataFrame,
                "withColumns": PysparkObjects.DataFrame,
                "withColumnRenamed": PysparkObjects.DataFrame,
                "withColumnsRenamed": PysparkObjects.DataFrame,
                "withMetadata": PysparkObjects.DataFrame,
                "withWatermark": PysparkObjects.DataFrame,
                "write": PysparkObjects.DataFrameWriter,
                "writeStream": PysparkObjects.DataStreamWriter,
                "writeTo": PysparkObjects.DataFrameWriterV2,
                "pandas_api": PysparkObjects.PandasOnSparkDataFrame
            },
            
            "DataFrameNaFunctions":{
                "drop": PysparkObjects.DataFrame,
                "fill": PysparkObjects.DataFrame,
                "replace": PysparkObjects.DataFrame
            },
            
            "DataFrameStatFunctions":{
                "approxQuantile": list,
                "corr": float,
                "cov": float,
                "crosstab": PysparkObjects.DataFrame,
                "freqItems": PysparkObjects.DataFrame,
                "sampleBy": PysparkObjects.DataFrame
            },

            "Column":{
                "alias": PysparkObjects.Column,
                "asc": PysparkObjects.Column,
                "asc_nulls_first": PysparkObjects.Column,
                "asc_nulls_last": PysparkObjects.Column,
                "astype": PysparkObjects.Column,
                "between": PysparkObjects.Column,
                "bitwiseAND": PysparkObjects.Column,
                "bitwiseOR": PysparkObjects.Column,
                "bitwiseXOR": PysparkObjects.Column,
                "cast": PysparkObjects.Column,
                "contains": PysparkObjects.Column,
                "desc": PysparkObjects.Column,
                "desc_nulls_first": PysparkObjects.Column,
                "desc_nulls_last": PysparkObjects.Column,
                "dropFields": PysparkObjects.Column,
                "endswith": PysparkObjects.Column,
                "eqNullSafe": PysparkObjects.Column,
                "getField": PysparkObjects.Column,
                "getItem": PysparkObjects.Column,
                "ilike": PysparkObjects.Column,
                "isNotNull": PysparkObjects.Column,
                "isNull": PysparkObjects.Column,
                "isin": PysparkObjects.Column,
                "like": PysparkObjects.Column,
                "name": PysparkObjects.Column,
                "otherwise": PysparkObjects.Column,
                "over": PysparkObjects.Column,
                "rlike": PysparkObjects.Column,
                "startswith": PysparkObjects.Column,
                "substr": PysparkObjects.Column,
                "when": PysparkObjects.Column,
                "withField": PysparkObjects.Column,
            },
            
            "Row":{
                "asDict": dict
            },

            "GroupedData": {
                "agg": PysparkObjects.DataFrame,
                "apply": PysparkObjects.DataFrame,
                "applyInPandas": PysparkObjects.DataFrame,
                "applyInPandasWithState": PysparkObjects.DataFrame,
                "avg": PysparkObjects.DataFrame,
                "cogroup": PysparkObjects.PandasCogroupedOps,
                "count": PysparkObjects.DataFrame,
                "max": PysparkObjects.DataFrame,
                "mean": PysparkObjects.DataFrame,
                "min": PysparkObjects.DataFrame,
                "pivot": PysparkObjects.GroupedData,
                "sum": PysparkObjects.DataFrame
            },

            "PandasCogroupedOps":{
                "applyInPandas": PysparkObjects.DataFrame
            },

            "functions":{
                "col": PysparkObjects.Column,
                "column": PysparkObjects.Column,
                "lit": PysparkObjects.Column,
                "broadcast": PysparkObjects.DataFrame,
                "coalesce": PysparkObjects.Column,
                "input_file_name": PysparkObjects.Column,
                "isnan": PysparkObjects.Column,
                "isnull": PysparkObjects.Column,
                "monotonically_increasing_id": PysparkObjects.Column,
                "named_struct": PysparkObjects.Column,
                "nanvl": PysparkObjects.Column,
                "rand": PysparkObjects.Column,
                "randn": PysparkObjects.Column,
                "spark_partition_id": PysparkObjects.Column,
                "when": PysparkObjects.Column,
                "bitwise_not": PysparkObjects.Column,
                "bitwiseNOT": PysparkObjects.Column,
                "expr": PysparkObjects.Column,
                "greatest": PysparkObjects.Column,
                "least": PysparkObjects.Column,
                # Math Functions
                "sqrt": PysparkObjects.Column,
                "abs": PysparkObjects.Column,
                "acos": PysparkObjects.Column,
                "acosh": PysparkObjects.Column,
                "asin": PysparkObjects.Column,
                "asinh": PysparkObjects.Column,
                "atan": PysparkObjects.Column,
                "atanh": PysparkObjects.Column,
                "atan2": PysparkObjects.Column,
                "bin": PysparkObjects.Column,
                "cbrt": PysparkObjects.Column,
                "ceil": PysparkObjects.Column,
                "ceiling": PysparkObjects.Column,
                "conv": PysparkObjects.Column,
                "cos": PysparkObjects.Column,
                "cosh": PysparkObjects.Column,
                "cot": PysparkObjects.Column,
                "csc": PysparkObjects.Column,
                "e": PysparkObjects.Column,
                "exp": PysparkObjects.Column,
                "expm1": PysparkObjects.Column,
                "factorial": PysparkObjects.Column,
                "floor": PysparkObjects.Column,
                "hex": PysparkObjects.Column,
                "unhex": PysparkObjects.Column,
                "hypot": PysparkObjects.Column,
                "ln": PysparkObjects.Column,
                "log10": PysparkObjects.Column,
                "log": PysparkObjects.Column,
                "log1p": PysparkObjects.Column,
                "log2": PysparkObjects.Column,
                "negate": PysparkObjects.Column,
                "negative": PysparkObjects.Column,
                "pi": PysparkObjects.Column,
                "pmod": PysparkObjects.Column,
                "positive": PysparkObjects.Column,
                "pow": PysparkObjects.Column,
                "power": PysparkObjects.Column,
                "rint": PysparkObjects.Column,
                "round": PysparkObjects.Column,
                "bround": PysparkObjects.Column,
                "sec": PysparkObjects.Column,
                "shiftleft": PysparkObjects.Column,
                "shiftright": PysparkObjects.Column,
                "shiftrightunsigned": PysparkObjects.Column,
                "sign": PysparkObjects.Column,
                "signum": PysparkObjects.Column,
                "sin": PysparkObjects.Column,
                "sinh": PysparkObjects.Column,
                "tan": PysparkObjects.Column,
                "tanh": PysparkObjects.Column,
                "toDegrees": PysparkObjects.Column,
                "try_add": PysparkObjects.Column,
                "try_avg": PysparkObjects.Column,
                "try_divide": PysparkObjects.Column,
                "try_multiply": PysparkObjects.Column,
                "try_subtract": PysparkObjects.Column,
                "try_sum": PysparkObjects.Column,
                "try_to_number": PysparkObjects.Column,
                "try_to_binary": PysparkObjects.Column,
                "degrees": PysparkObjects.Column,
                "toRadians": PysparkObjects.Column,
                "radians": PysparkObjects.Column,
                "width_bucket": PysparkObjects.Column,
                # Datetime Functions
                "add_months": PysparkObjects.Column,
                "convert_timezone": PysparkObjects.Column,
                "curdate": PysparkObjects.Column,
                "current_date": PysparkObjects.Column,
                "current_timestamp": PysparkObjects.Column,
                "current_timezone": PysparkObjects.Column,
                "date_add": PysparkObjects.Column,
                "date_diff": PysparkObjects.Column,
                "date_format": PysparkObjects.Column,
                "date_from_unix_date": PysparkObjects.Column,
                "date_sub": PysparkObjects.Column,
                "date_trunc": PysparkObjects.Column,
                "dateadd": PysparkObjects.Column,
                "datediff": PysparkObjects.Column,
                "day": PysparkObjects.Column,
                "date_part": PysparkObjects.Column,
                "datepart": PysparkObjects.Column,
                "dayofmonth": PysparkObjects.Column,
                "dayofweek": PysparkObjects.Column,
                "dayofyear": PysparkObjects.Column,
                "extract": PysparkObjects.Column,
                "second": PysparkObjects.Column,
                "weekofyear": PysparkObjects.Column,
                "year": PysparkObjects.Column,
                "quarter": PysparkObjects.Column,
                "month": PysparkObjects.Column,
                "last_day": PysparkObjects.Column,
                "localtimestamp": PysparkObjects.Column,
                "make_dt_interval": PysparkObjects.Column,
                "make_interval": PysparkObjects.Column,
                "make_timestamp": PysparkObjects.Column,
                "make_timestamp_ltz": PysparkObjects.Column,
                "make_timestamp_ntz": PysparkObjects.Column,
                "make_ym_interval": PysparkObjects.Column,
                "minute": PysparkObjects.Column,
                "months_between": PysparkObjects.Column,
                "next_day": PysparkObjects.Column,
                "hour": PysparkObjects.Column,
                "make_date": PysparkObjects.Column,
                "now": PysparkObjects.Column,
                "from_unixtime": PysparkObjects.Column,
                "unix_timestamp": PysparkObjects.Column,
                "to_unix_timestamp": None, 
                "to_timestamp": PysparkObjects.Column,
                "to_timestamp_ltz": PysparkObjects.Column,
                "to_timestamp_ntz": PysparkObjects.Column,
                "to_date": PysparkObjects.Column,
                "trunc": PysparkObjects.Column,
                "from_utc_timestamp": PysparkObjects.Column,
                "to_utc_timestamp": PysparkObjects.Column,
                "weekday": PysparkObjects.Column,
                "window": PysparkObjects.Column,
                "session_window": PysparkObjects.Column,
                "timestamp_micros": PysparkObjects.Column,
                "timestamp_millis": PysparkObjects.Column,
                "timestamp_seconds": PysparkObjects.Column,
                "try_to_timestamp": PysparkObjects.Column,
                "unix_date": PysparkObjects.Column,
                "unix_micros": PysparkObjects.Column,
                "unix_millis": PysparkObjects.Column,
                "unix_seconds": PysparkObjects.Column,
                "window_time": PysparkObjects.Column,
                # Collection Functions
                "array": PysparkObjects.Column,
                "array_contains": PysparkObjects.Column,
                "arrays_overlap": PysparkObjects.Column,
                "array_join": PysparkObjects.Column,
                "create_map": PysparkObjects.Column,
                "slice": PysparkObjects.Column,
                "concat": PysparkObjects.Column,
                "array_position": PysparkObjects.Column,
                "element_at": PysparkObjects.Column,
                "array_append": PysparkObjects.Column,
                "array_size": PysparkObjects.Column,
                "array_sort": PysparkObjects.Column,
                "array_insert": PysparkObjects.Column,
                "array_prepend": PysparkObjects.Column,
                "array_remove": PysparkObjects.Column,
                "array_distinct": PysparkObjects.Column,
                "array_intersect": PysparkObjects.Column,
                "array_union": PysparkObjects.Column,
                "array_except": PysparkObjects.Column,
                "array_compact": PysparkObjects.Column,
                "transform": PysparkObjects.Column,
                "exists": PysparkObjects.Column,
                "forall": PysparkObjects.Column,
                "filter": PysparkObjects.Column,
                "aggregate": PysparkObjects.Column,
                "zip_with": PysparkObjects.Column,
                "transform_keys": PysparkObjects.Column,
                "transform_values": PysparkObjects.Column,
                "map_filter": PysparkObjects.Column,
                "map_from_arrays": PysparkObjects.Column,
                "map_zip_with": PysparkObjects.Column,
                "explode": PysparkObjects.Column,
                "explode_outer": PysparkObjects.Column,
                "posexplode": PysparkObjects.Column,
                "posexplode_outer": PysparkObjects.Column,
                "inline": PysparkObjects.Column,
                "inline_outer": PysparkObjects.Column,
                "get": PysparkObjects.Column,
                "get_json_object": PysparkObjects.Column,
                "json_tuple": PysparkObjects.Column,
                "from_json": PysparkObjects.Column,
                "schema_of_json": PysparkObjects.Column,
                "to_json": PysparkObjects.Column,
                "json_array_length": PysparkObjects.Column,
                "json_object_keys": PysparkObjects.Column,
                "size": PysparkObjects.Column,
                "cardinality": PysparkObjects.Column,
                "struct": PysparkObjects.Column,
                "sort_array": PysparkObjects.Column,
                "array_max": PysparkObjects.Column,
                "array_min": PysparkObjects.Column,
                "shuffle": PysparkObjects.Column,
                "reverse": PysparkObjects.Column,
                "flatten": PysparkObjects.Column,
                "sequence": PysparkObjects.Column,
                "array_repeat": PysparkObjects.Column,
                "map_contains_key": PysparkObjects.Column,
                "map_keys": PysparkObjects.Column,
                "map_values": PysparkObjects.Column,
                "map_entries": PysparkObjects.Column,
                "map_from_entries": PysparkObjects.Column,
                "arrays_zip": PysparkObjects.Column,
                "map_concat": PysparkObjects.Column,            
                "from_csv": PysparkObjects.Column,
                "schema_of_csv": PysparkObjects.Column,
                "str_to_map": PysparkObjects.Column,
                "to_csv": PysparkObjects.Column,
                "try_element_at": PysparkObjects.Column,
                # Partition Transformation Functions
                "years": PysparkObjects.Column,
                "months": PysparkObjects.Column,
                "days": PysparkObjects.Column,
                "hours": PysparkObjects.Column,
                "bucket": PysparkObjects.Column,
                # Aggregate Functions
                "any_value": PysparkObjects.Column,
                "approx_count_distinct": PysparkObjects.Column,
                "approx_percentile": PysparkObjects.Column,
                "array_agg": PysparkObjects.Column,
                "avg": PysparkObjects.Column,
                "bit_and": PysparkObjects.Column,
                "bit_or": PysparkObjects.Column,
                "bit_xor": PysparkObjects.Column,
                "bool_and": PysparkObjects.Column,
                "bool_or": PysparkObjects.Column,
                "collect_list": PysparkObjects.Column,
                "collect_set": PysparkObjects.Column,
                "corr": PysparkObjects.Column,
                "count": PysparkObjects.Column,
                "count_distinct": PysparkObjects.Column,
                "countDistinct": PysparkObjects.Column,
                "count_min_sketch": PysparkObjects.Column,
                "count_if": PysparkObjects.Column,
                "covar_pop": PysparkObjects.Column,
                "covar_samp": PysparkObjects.Column,
                "every": PysparkObjects.Column,
                "first": PysparkObjects.Column,
                "first_value": PysparkObjects.Column,
                "grouping": PysparkObjects.Column,
                "grouping_id": PysparkObjects.Column,
                "histogram_numeric": PysparkObjects.Column,
                "hll_sketch_agg": PysparkObjects.Column,
                "hll_union_agg": PysparkObjects.Column,
                "kurtosis": PysparkObjects.Column,
                "last": PysparkObjects.Column,
                "last_value": PysparkObjects.Column,
                "max": PysparkObjects.Column,
                "max_by": PysparkObjects.Column,
                "mean": PysparkObjects.Column,
                "median": PysparkObjects.Column,
                "min": PysparkObjects.Column,
                "min_by": PysparkObjects.Column,
                "mode": PysparkObjects.Column,
                "percentile": PysparkObjects.Column,
                "percentile_approx": PysparkObjects.Column,
                "product": PysparkObjects.Column,
                "reduce": PysparkObjects.Column,
                "regr_avgx": PysparkObjects.Column,
                "regr_avgy": PysparkObjects.Column,
                "regr_count": PysparkObjects.Column,
                "regr_intercept": PysparkObjects.Column,
                "regr_r2": PysparkObjects.Column,
                "regr_slope": PysparkObjects.Column,
                "regr_sxx": PysparkObjects.Column,
                "regr_sxy": PysparkObjects.Column,
                "regr_syy": PysparkObjects.Column,
                "skewness": PysparkObjects.Column,
                "some": PysparkObjects.Column,
                "stddev": PysparkObjects.Column,
                "stddev_pop": PysparkObjects.Column,
                "stddev_samp": PysparkObjects.Column,
                "sum": PysparkObjects.Column,
                "sumDistinct": PysparkObjects.Column,
                "sum_distinct": PysparkObjects.Column,
                "var_pop": PysparkObjects.Column,
                "var_samp": PysparkObjects.Column,
                "variance": PysparkObjects.Column,
                # Window Functions
                "cume_dist": PysparkObjects.Column,
                "dense_rank": PysparkObjects.Column,
                "lag": PysparkObjects.Column,
                "lead": PysparkObjects.Column,
                "nth_value": PysparkObjects.Column,
                "ntile": PysparkObjects.Column,
                "percent_rank": PysparkObjects.Column,
                "rank": PysparkObjects.Column,
                "row_number": PysparkObjects.Column,
                # Sort Functions
                "asc": PysparkObjects.Column,
                "asc_nulls_first": PysparkObjects.Column,
                "asc_nulls_last": PysparkObjects.Column,
                "desc": PysparkObjects.Column,
                "desc_nulls_first": PysparkObjects.Column,
                "desc_nulls_last": PysparkObjects.Column,
                # String Functions
                "ascii": PysparkObjects.Column,
                "base64": PysparkObjects.Column,
                "bit_length": PysparkObjects.Column,
                "btrim": PysparkObjects.Column,
                "char": PysparkObjects.Column,
                "char_length": PysparkObjects.Column,
                "character_length": PysparkObjects.Column,
                "concat": PysparkObjects.Column,
                "concat_ws": PysparkObjects.Column,
                "contains": PysparkObjects.Column,
                "decode": PysparkObjects.Column,
                "elt": PysparkObjects.Column,
                "encode": PysparkObjects.Column,
                "endswith": PysparkObjects.Column,
                "find_in_set": PysparkObjects.Column,
                "format_number": PysparkObjects.Column,
                "format_string": PysparkObjects.Column,
                "initcap": PysparkObjects.Column,
                "instr": PysparkObjects.Column,
                "length": PysparkObjects.Column,
                "lower": PysparkObjects.Column,
                "lpad": PysparkObjects.Column,
                "ltrim": PysparkObjects.Column,
                "octet_length": PysparkObjects.Column,
                "parse_url": PysparkObjects.Column,
                "position": PysparkObjects.Column,
                "printf": PysparkObjects.Column,
                "regexp": PysparkObjects.Column,
                "regexp_extract": PysparkObjects.Column,
                "regexp_extract_all": PysparkObjects.Column,
                "regexp_replace": PysparkObjects.Column,
                "regexp_substr": PysparkObjects.Column,
                "regexp_instr": PysparkObjects.Column,
                "repeat": PysparkObjects.Column,
                "replace": PysparkObjects.Column,
                "reverse": PysparkObjects.Column,
                "rpad": PysparkObjects.Column,
                "rtrim": PysparkObjects.Column,
                "soundex": PysparkObjects.Column,
                "split": PysparkObjects.Column,
                "split_part": PysparkObjects.Column,
                "substr": PysparkObjects.Column,
                "substring": PysparkObjects.Column,
                "substring_index": PysparkObjects.Column,
                "translate": PysparkObjects.Column,
                "trim": PysparkObjects.Column,
                "upper": PysparkObjects.Column,
                "overlay": PysparkObjects.Column,
                "sentences": PysparkObjects.Column,
                "to_binary": PysparkObjects.Column,
                "to_char": PysparkObjects.Column,
                "to_number": PysparkObjects.Column,
                "to_varchar": PysparkObjects.Column,
                "url_decode": PysparkObjects.Column,
                "url_encode": PysparkObjects.Column,
                "unbase64": PysparkObjects.Column,
                "unhex": PysparkObjects.Column,
                "levenshtein": PysparkObjects.Column,
                "locate": PysparkObjects.Column,
                "lcase": PysparkObjects.Column,
                "left": PysparkObjects.Column,
                "right": PysparkObjects.Column,
                "ucase": PysparkObjects.Column,
                "mask": PysparkObjects.Column,
                "regexp_like": PysparkObjects.Column,
                "regexp_count": PysparkObjects.Column,
                "ilike": PysparkObjects.Column,
                "like": PysparkObjects.Column,
                "rlike": PysparkObjects.Column,
                "startswith": PysparkObjects.Column,
                # Bitwise Functions
                "bit_count": PysparkObjects.Column,
                "bit_get": PysparkObjects.Column,
                "getbit": PysparkObjects.Column,
                # Call Functions
                "call_function": PysparkObjects.Column,
                "call_udf": PysparkObjects.Column,
                "pandas_udf": None,
                "udf": PysparkObjects.UDF,
                "udtf": PysparkObjects.UDF,
                "unwrap_udt": PysparkObjects.Column,
                # Misc Functions
                "aes_decrypt": PysparkObjects.Column,
                "aes_encrypt": PysparkObjects.Column,
                "bitmap_bit_position": PysparkObjects.Column,
                "bitmap_bucket_number": PysparkObjects.Column,
                "bitmap_construct_agg": PysparkObjects.Column,
                "bitmap_count": PysparkObjects.Column,
                "bitmap_or_agg": PysparkObjects.Column,
                "current_catalog": PysparkObjects.Column,
                "current_database": PysparkObjects.Column,
                "current_schema": PysparkObjects.Column,
                "current_user": PysparkObjects.Column,
                "input_file_block_length": PysparkObjects.Column,
                "input_file_block_start": PysparkObjects.Column,
                "md5": PysparkObjects.Column,
                "sha": PysparkObjects.Column,
                "sha1": PysparkObjects.Column,
                "sha2": PysparkObjects.Column,
                "crc32": PysparkObjects.Column,
                "hash": PysparkObjects.Column,
                "xxhash64": PysparkObjects.Column,
                "assert_true": PysparkObjects.Column,
                "raise_error": PysparkObjects.Column,
                "reflect": PysparkObjects.Column,
                "hll_sketch_estimate": PysparkObjects.Column,
                "hll_union": PysparkObjects.Column,
                "java_method": PysparkObjects.Column,
                "stack": PysparkObjects.Column,
                "try_aes_decrypt": PysparkObjects.Column,
                "typeof": PysparkObjects.Column,
                "user": PysparkObjects.Column,
                "version": PysparkObjects.Column,
                # Predicate Functions
                "equal_null": PysparkObjects.Column,
                "ifnull": PysparkObjects.Column,
                "isnotnull": PysparkObjects.Column,
                "nullif": PysparkObjects.Column,
                "nvl": PysparkObjects.Column,
                "nvl2": PysparkObjects.Column,
                # XML Functions
                "xpath": PysparkObjects.Column,
                "xpath_boolean": PysparkObjects.Column,
                "xpath_double": PysparkObjects.Column,
                "xpath_float": PysparkObjects.Column,
                "xpath_int": PysparkObjects.Column,
                "xpath_long": PysparkObjects.Column,
                "xpath_number": PysparkObjects.Column,
                "xpath_short": PysparkObjects.Column,
                "xpath_string": PysparkObjects.Column,
            },

            "DataFrameReader": {
                "csv": PysparkObjects.DataFrame,
                "json": PysparkObjects.DataFrame,
                "jdbc": PysparkObjects.DataFrame,
                "parquet": PysparkObjects.DataFrame,
                "orc": PysparkObjects.DataFrame,
                "text": PysparkObjects.DataFrame,
                "load": PysparkObjects.DataFrame,
                "table": PysparkObjects.DataFrame,
                "text": PysparkObjects.DataFrame,
                "format": PysparkObjects.DataFrameReader,
                "schema": PysparkObjects.DataFrameReader,
                "option": PysparkObjects.DataFrameReader,
                "options": PysparkObjects.DataFrameReader,
            },

            "DataFrameWriter": {
                "bucketBy": PysparkObjects.DataFrameWriter,
                "csv": None,
                "format": PysparkObjects.DataFrameWriter,
                "insertInto": None,
                "jdbc": None,
                "json": None,
                "parquet": None,
                "orc": None,
                "text": None,
                "save": None,  
                "mode": PysparkObjects.DataFrameWriter,
                "option": PysparkObjects.DataFrameWriter,
                "options": PysparkObjects.DataFrameWriter,
                "partitionBy": PysparkObjects.DataFrameWriter,
                "saveAsTable": None,
                "sortBy": PysparkObjects.DataFrameWriter,
            },

            "DataFrameWriterV2": {
                "using": PysparkObjects.DataFrameWriterV2,
                "option": PysparkObjects.DataFrameWriterV2,
                "options": PysparkObjects.DataFrameWriterV2,
                "tableProperty": PysparkObjects.DataFrameWriterV2,
                "partitionedBy": PysparkObjects.DataFrameWriterV2,
                "create": None,
                "replace": None,
                "createOrReplace": None,  
                "append": None,  
                "overwrite": None,  
                "overwritePartitions": None
            },

            "types":{
                "ArrayType": {
                    "fromInternal": list,
                    "json": str,
                    "jsonValue": dict,
                    "needConversion": bool,
                    "simpleString": str,
                    "toInternal": list,
                },
                "BinaryType":{
                    **general_dict
                },
                "BooleanType":{
                    **general_dict             
                },
                "ByteType":{
                    **general_dict
                },
                "DataType":{
                    **general_dict
                },
                "DateType":{
                    "fromInternal": datetime.date,
                    "json":str,
                    "jsonValue":  [str or dict],
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": int
                },
                "DecimalType":{
                    "fromInternal": Any,
                    "json":str,
                    "jsonValue":  str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": Any
                },
                "DoubleType":{
                    **general_dict
                },
                "FloatType":{
                    **general_dict
                },
                "IntegerType":{
                    **general_dict
                },
                "LongType":{
                    **general_dict
                },
                "MapType":{
                    "fromInternal": dict,
                    "json": dict,
                    "jsonValue":  str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": Any
                },
                "NullType":{
                    **general_dict
                },
                "ShortType":{
                    **general_dict
                },
                "StringType":{
                    **general_dict
                },
                "CharType":{
                    "fromInternal": Any,
                    "json":str,
                    "jsonValue":  str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": Any
                },
                "VarcharType":{
                    "fromInternal": Any,
                    "json":str,
                    "jsonValue":  str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": Any
                },
                "StructField":{
                    "fromInternal": "T",
                    "json":str,
                    "jsonValue":  dict,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": "T"
                },
                "StructType":{
                    "add": PysparkObjects.StructType,
                    "fieldNames": list,
                    "fromInternal": PysparkObjects.Row,
                    "json": str,
                    "jsonValue":  dict,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": tuple

                },
                "TimestampType":{
                    "fromInternal": datetime.datetime,
                    "json": str,
                    "jsonValue":  [str or dict],
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": int
                },
                "TimestampNTZType":{
                    "fromInternal": datetime.datetime,
                    "json": str,
                    "jsonValue": [str or dict],
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": int
                },
                "DayTimeIntervalType":{
                    "fromInternal": datetime.timedelta,
                    "json": str,
                    "jsonValue": str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": int
                },
                "YearMonthIntervalType":{
                    "fromInternal": Any,
                    "json": str,
                    "jsonValue": str,
                    "needConversion": bool,
                    "simpleString":str,
                    "toInternal": Any
                }
            },
              
            "Window":{
                "partitionBy": PysparkObjects.WindowSpec,
                "orderBy": PysparkObjects.WindowSpec,
                "rowsBetween": PysparkObjects.WindowSpec,
                "rangeBetween": PysparkObjects.WindowSpec,
                "unboundedPreceding": PysparkObjects.WindowSpec,
                "unboundedFollowing": PysparkObjects.WindowSpec,
                "currentRow": PysparkObjects.WindowSpec,
            }

        }
        
    }

}