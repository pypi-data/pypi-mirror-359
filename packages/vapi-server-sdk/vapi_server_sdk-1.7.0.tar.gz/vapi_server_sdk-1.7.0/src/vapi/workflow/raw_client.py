# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.http_response import AsyncHttpResponse, HttpResponse
from ..core.jsonable_encoder import jsonable_encoder
from ..core.request_options import RequestOptions
from ..core.serialization import convert_and_respect_annotation_metadata
from ..core.unchecked_base_model import construct_type
from ..types.analysis_plan import AnalysisPlan
from ..types.artifact_plan import ArtifactPlan
from ..types.background_speech_denoising_plan import BackgroundSpeechDenoisingPlan
from ..types.compliance_plan import CompliancePlan
from ..types.create_workflow_dto_background_sound import CreateWorkflowDtoBackgroundSound
from ..types.create_workflow_dto_credentials_item import CreateWorkflowDtoCredentialsItem
from ..types.create_workflow_dto_nodes_item import CreateWorkflowDtoNodesItem
from ..types.create_workflow_dto_transcriber import CreateWorkflowDtoTranscriber
from ..types.create_workflow_dto_voice import CreateWorkflowDtoVoice
from ..types.edge import Edge
from ..types.langfuse_observability_plan import LangfuseObservabilityPlan
from ..types.monitor_plan import MonitorPlan
from ..types.server import Server
from ..types.start_speaking_plan import StartSpeakingPlan
from ..types.stop_speaking_plan import StopSpeakingPlan
from ..types.workflow import Workflow
from .types.update_workflow_dto_background_sound import UpdateWorkflowDtoBackgroundSound
from .types.update_workflow_dto_credentials_item import UpdateWorkflowDtoCredentialsItem
from .types.update_workflow_dto_nodes_item import UpdateWorkflowDtoNodesItem
from .types.update_workflow_dto_transcriber import UpdateWorkflowDtoTranscriber
from .types.update_workflow_dto_voice import UpdateWorkflowDtoVoice

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class RawWorkflowClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def workflow_controller_find_all(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[typing.List[Workflow]]:
        """
        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[Workflow]]

        """
        _response = self._client_wrapper.httpx_client.request(
            "workflow",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[Workflow],
                    construct_type(
                        type_=typing.List[Workflow],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def workflow_controller_create(
        self,
        *,
        nodes: typing.Sequence[CreateWorkflowDtoNodesItem],
        name: str,
        edges: typing.Sequence[Edge],
        transcriber: typing.Optional[CreateWorkflowDtoTranscriber] = OMIT,
        voice: typing.Optional[CreateWorkflowDtoVoice] = OMIT,
        observability_plan: typing.Optional[LangfuseObservabilityPlan] = OMIT,
        background_sound: typing.Optional[CreateWorkflowDtoBackgroundSound] = OMIT,
        credentials: typing.Optional[typing.Sequence[CreateWorkflowDtoCredentialsItem]] = OMIT,
        global_prompt: typing.Optional[str] = OMIT,
        server: typing.Optional[Server] = OMIT,
        compliance_plan: typing.Optional[CompliancePlan] = OMIT,
        analysis_plan: typing.Optional[AnalysisPlan] = OMIT,
        artifact_plan: typing.Optional[ArtifactPlan] = OMIT,
        start_speaking_plan: typing.Optional[StartSpeakingPlan] = OMIT,
        stop_speaking_plan: typing.Optional[StopSpeakingPlan] = OMIT,
        monitor_plan: typing.Optional[MonitorPlan] = OMIT,
        background_speech_denoising_plan: typing.Optional[BackgroundSpeechDenoisingPlan] = OMIT,
        credential_ids: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[Workflow]:
        """
        Parameters
        ----------
        nodes : typing.Sequence[CreateWorkflowDtoNodesItem]

        name : str

        edges : typing.Sequence[Edge]

        transcriber : typing.Optional[CreateWorkflowDtoTranscriber]
            This is the transcriber for the workflow.

            This can be overridden at node level using `nodes[n].transcriber`.

        voice : typing.Optional[CreateWorkflowDtoVoice]
            This is the voice for the workflow.

            This can be overridden at node level using `nodes[n].voice`.

        observability_plan : typing.Optional[LangfuseObservabilityPlan]
            This is the plan for observability of workflow's calls.

            Currently, only Langfuse is supported.

        background_sound : typing.Optional[CreateWorkflowDtoBackgroundSound]
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.

        credentials : typing.Optional[typing.Sequence[CreateWorkflowDtoCredentialsItem]]
            These are dynamic credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials.

        global_prompt : typing.Optional[str]

        server : typing.Optional[Server]
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. tool.server
            2. workflow.server / assistant.server
            3. phoneNumber.server
            4. org.server

        compliance_plan : typing.Optional[CompliancePlan]
            This is the compliance plan for the workflow. It allows you to configure HIPAA and other compliance settings.

        analysis_plan : typing.Optional[AnalysisPlan]
            This is the plan for analysis of workflow's calls. Stored in `call.analysis`.

        artifact_plan : typing.Optional[ArtifactPlan]
            This is the plan for artifacts generated during workflow's calls. Stored in `call.artifact`.

        start_speaking_plan : typing.Optional[StartSpeakingPlan]
            This is the plan for when the workflow nodes should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.

        stop_speaking_plan : typing.Optional[StopSpeakingPlan]
            This is the plan for when workflow nodes should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.

        monitor_plan : typing.Optional[MonitorPlan]
            This is the plan for real-time monitoring of the workflow's calls.

            Usage:
            - To enable live listening of the workflow's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the workflow's calls, set `monitorPlan.controlEnabled` to `true`.

        background_speech_denoising_plan : typing.Optional[BackgroundSpeechDenoisingPlan]
            This enables filtering of noise and background speech while the user is talking.

            Features:
            - Smart denoising using Krisp
            - Fourier denoising

            Both can be used together. Order of precedence:
            - Smart denoising
            - Fourier denoising

        credential_ids : typing.Optional[typing.Sequence[str]]
            These are the credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can provide a subset using this.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[Workflow]

        """
        _response = self._client_wrapper.httpx_client.request(
            "workflow",
            method="POST",
            json={
                "nodes": convert_and_respect_annotation_metadata(
                    object_=nodes, annotation=typing.Sequence[CreateWorkflowDtoNodesItem], direction="write"
                ),
                "transcriber": convert_and_respect_annotation_metadata(
                    object_=transcriber, annotation=CreateWorkflowDtoTranscriber, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=CreateWorkflowDtoVoice, direction="write"
                ),
                "observabilityPlan": convert_and_respect_annotation_metadata(
                    object_=observability_plan, annotation=LangfuseObservabilityPlan, direction="write"
                ),
                "backgroundSound": convert_and_respect_annotation_metadata(
                    object_=background_sound, annotation=CreateWorkflowDtoBackgroundSound, direction="write"
                ),
                "credentials": convert_and_respect_annotation_metadata(
                    object_=credentials, annotation=typing.Sequence[CreateWorkflowDtoCredentialsItem], direction="write"
                ),
                "name": name,
                "edges": convert_and_respect_annotation_metadata(
                    object_=edges, annotation=typing.Sequence[Edge], direction="write"
                ),
                "globalPrompt": global_prompt,
                "server": convert_and_respect_annotation_metadata(object_=server, annotation=Server, direction="write"),
                "compliancePlan": convert_and_respect_annotation_metadata(
                    object_=compliance_plan, annotation=CompliancePlan, direction="write"
                ),
                "analysisPlan": convert_and_respect_annotation_metadata(
                    object_=analysis_plan, annotation=AnalysisPlan, direction="write"
                ),
                "artifactPlan": convert_and_respect_annotation_metadata(
                    object_=artifact_plan, annotation=ArtifactPlan, direction="write"
                ),
                "startSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=start_speaking_plan, annotation=StartSpeakingPlan, direction="write"
                ),
                "stopSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=stop_speaking_plan, annotation=StopSpeakingPlan, direction="write"
                ),
                "monitorPlan": convert_and_respect_annotation_metadata(
                    object_=monitor_plan, annotation=MonitorPlan, direction="write"
                ),
                "backgroundSpeechDenoisingPlan": convert_and_respect_annotation_metadata(
                    object_=background_speech_denoising_plan,
                    annotation=BackgroundSpeechDenoisingPlan,
                    direction="write",
                ),
                "credentialIds": credential_ids,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def workflow_controller_find_one(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[Workflow]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def workflow_controller_delete(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[Workflow]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def workflow_controller_update(
        self,
        id: str,
        *,
        nodes: typing.Optional[typing.Sequence[UpdateWorkflowDtoNodesItem]] = OMIT,
        transcriber: typing.Optional[UpdateWorkflowDtoTranscriber] = OMIT,
        voice: typing.Optional[UpdateWorkflowDtoVoice] = OMIT,
        observability_plan: typing.Optional[LangfuseObservabilityPlan] = OMIT,
        background_sound: typing.Optional[UpdateWorkflowDtoBackgroundSound] = OMIT,
        credentials: typing.Optional[typing.Sequence[UpdateWorkflowDtoCredentialsItem]] = OMIT,
        name: typing.Optional[str] = OMIT,
        edges: typing.Optional[typing.Sequence[Edge]] = OMIT,
        global_prompt: typing.Optional[str] = OMIT,
        server: typing.Optional[Server] = OMIT,
        compliance_plan: typing.Optional[CompliancePlan] = OMIT,
        analysis_plan: typing.Optional[AnalysisPlan] = OMIT,
        artifact_plan: typing.Optional[ArtifactPlan] = OMIT,
        start_speaking_plan: typing.Optional[StartSpeakingPlan] = OMIT,
        stop_speaking_plan: typing.Optional[StopSpeakingPlan] = OMIT,
        monitor_plan: typing.Optional[MonitorPlan] = OMIT,
        background_speech_denoising_plan: typing.Optional[BackgroundSpeechDenoisingPlan] = OMIT,
        credential_ids: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        nodes : typing.Optional[typing.Sequence[UpdateWorkflowDtoNodesItem]]

        transcriber : typing.Optional[UpdateWorkflowDtoTranscriber]
            This is the transcriber for the workflow.

            This can be overridden at node level using `nodes[n].transcriber`.

        voice : typing.Optional[UpdateWorkflowDtoVoice]
            This is the voice for the workflow.

            This can be overridden at node level using `nodes[n].voice`.

        observability_plan : typing.Optional[LangfuseObservabilityPlan]
            This is the plan for observability of workflow's calls.

            Currently, only Langfuse is supported.

        background_sound : typing.Optional[UpdateWorkflowDtoBackgroundSound]
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.

        credentials : typing.Optional[typing.Sequence[UpdateWorkflowDtoCredentialsItem]]
            These are dynamic credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials.

        name : typing.Optional[str]

        edges : typing.Optional[typing.Sequence[Edge]]

        global_prompt : typing.Optional[str]

        server : typing.Optional[Server]
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. tool.server
            2. workflow.server / assistant.server
            3. phoneNumber.server
            4. org.server

        compliance_plan : typing.Optional[CompliancePlan]
            This is the compliance plan for the workflow. It allows you to configure HIPAA and other compliance settings.

        analysis_plan : typing.Optional[AnalysisPlan]
            This is the plan for analysis of workflow's calls. Stored in `call.analysis`.

        artifact_plan : typing.Optional[ArtifactPlan]
            This is the plan for artifacts generated during workflow's calls. Stored in `call.artifact`.

        start_speaking_plan : typing.Optional[StartSpeakingPlan]
            This is the plan for when the workflow nodes should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.

        stop_speaking_plan : typing.Optional[StopSpeakingPlan]
            This is the plan for when workflow nodes should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.

        monitor_plan : typing.Optional[MonitorPlan]
            This is the plan for real-time monitoring of the workflow's calls.

            Usage:
            - To enable live listening of the workflow's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the workflow's calls, set `monitorPlan.controlEnabled` to `true`.

        background_speech_denoising_plan : typing.Optional[BackgroundSpeechDenoisingPlan]
            This enables filtering of noise and background speech while the user is talking.

            Features:
            - Smart denoising using Krisp
            - Fourier denoising

            Both can be used together. Order of precedence:
            - Smart denoising
            - Fourier denoising

        credential_ids : typing.Optional[typing.Sequence[str]]
            These are the credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can provide a subset using this.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[Workflow]

        """
        _response = self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "nodes": convert_and_respect_annotation_metadata(
                    object_=nodes, annotation=typing.Sequence[UpdateWorkflowDtoNodesItem], direction="write"
                ),
                "transcriber": convert_and_respect_annotation_metadata(
                    object_=transcriber, annotation=UpdateWorkflowDtoTranscriber, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=UpdateWorkflowDtoVoice, direction="write"
                ),
                "observabilityPlan": convert_and_respect_annotation_metadata(
                    object_=observability_plan, annotation=LangfuseObservabilityPlan, direction="write"
                ),
                "backgroundSound": convert_and_respect_annotation_metadata(
                    object_=background_sound, annotation=UpdateWorkflowDtoBackgroundSound, direction="write"
                ),
                "credentials": convert_and_respect_annotation_metadata(
                    object_=credentials, annotation=typing.Sequence[UpdateWorkflowDtoCredentialsItem], direction="write"
                ),
                "name": name,
                "edges": convert_and_respect_annotation_metadata(
                    object_=edges, annotation=typing.Sequence[Edge], direction="write"
                ),
                "globalPrompt": global_prompt,
                "server": convert_and_respect_annotation_metadata(object_=server, annotation=Server, direction="write"),
                "compliancePlan": convert_and_respect_annotation_metadata(
                    object_=compliance_plan, annotation=CompliancePlan, direction="write"
                ),
                "analysisPlan": convert_and_respect_annotation_metadata(
                    object_=analysis_plan, annotation=AnalysisPlan, direction="write"
                ),
                "artifactPlan": convert_and_respect_annotation_metadata(
                    object_=artifact_plan, annotation=ArtifactPlan, direction="write"
                ),
                "startSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=start_speaking_plan, annotation=StartSpeakingPlan, direction="write"
                ),
                "stopSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=stop_speaking_plan, annotation=StopSpeakingPlan, direction="write"
                ),
                "monitorPlan": convert_and_respect_annotation_metadata(
                    object_=monitor_plan, annotation=MonitorPlan, direction="write"
                ),
                "backgroundSpeechDenoisingPlan": convert_and_respect_annotation_metadata(
                    object_=background_speech_denoising_plan,
                    annotation=BackgroundSpeechDenoisingPlan,
                    direction="write",
                ),
                "credentialIds": credential_ids,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawWorkflowClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def workflow_controller_find_all(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[typing.List[Workflow]]:
        """
        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[Workflow]]

        """
        _response = await self._client_wrapper.httpx_client.request(
            "workflow",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[Workflow],
                    construct_type(
                        type_=typing.List[Workflow],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def workflow_controller_create(
        self,
        *,
        nodes: typing.Sequence[CreateWorkflowDtoNodesItem],
        name: str,
        edges: typing.Sequence[Edge],
        transcriber: typing.Optional[CreateWorkflowDtoTranscriber] = OMIT,
        voice: typing.Optional[CreateWorkflowDtoVoice] = OMIT,
        observability_plan: typing.Optional[LangfuseObservabilityPlan] = OMIT,
        background_sound: typing.Optional[CreateWorkflowDtoBackgroundSound] = OMIT,
        credentials: typing.Optional[typing.Sequence[CreateWorkflowDtoCredentialsItem]] = OMIT,
        global_prompt: typing.Optional[str] = OMIT,
        server: typing.Optional[Server] = OMIT,
        compliance_plan: typing.Optional[CompliancePlan] = OMIT,
        analysis_plan: typing.Optional[AnalysisPlan] = OMIT,
        artifact_plan: typing.Optional[ArtifactPlan] = OMIT,
        start_speaking_plan: typing.Optional[StartSpeakingPlan] = OMIT,
        stop_speaking_plan: typing.Optional[StopSpeakingPlan] = OMIT,
        monitor_plan: typing.Optional[MonitorPlan] = OMIT,
        background_speech_denoising_plan: typing.Optional[BackgroundSpeechDenoisingPlan] = OMIT,
        credential_ids: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[Workflow]:
        """
        Parameters
        ----------
        nodes : typing.Sequence[CreateWorkflowDtoNodesItem]

        name : str

        edges : typing.Sequence[Edge]

        transcriber : typing.Optional[CreateWorkflowDtoTranscriber]
            This is the transcriber for the workflow.

            This can be overridden at node level using `nodes[n].transcriber`.

        voice : typing.Optional[CreateWorkflowDtoVoice]
            This is the voice for the workflow.

            This can be overridden at node level using `nodes[n].voice`.

        observability_plan : typing.Optional[LangfuseObservabilityPlan]
            This is the plan for observability of workflow's calls.

            Currently, only Langfuse is supported.

        background_sound : typing.Optional[CreateWorkflowDtoBackgroundSound]
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.

        credentials : typing.Optional[typing.Sequence[CreateWorkflowDtoCredentialsItem]]
            These are dynamic credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials.

        global_prompt : typing.Optional[str]

        server : typing.Optional[Server]
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. tool.server
            2. workflow.server / assistant.server
            3. phoneNumber.server
            4. org.server

        compliance_plan : typing.Optional[CompliancePlan]
            This is the compliance plan for the workflow. It allows you to configure HIPAA and other compliance settings.

        analysis_plan : typing.Optional[AnalysisPlan]
            This is the plan for analysis of workflow's calls. Stored in `call.analysis`.

        artifact_plan : typing.Optional[ArtifactPlan]
            This is the plan for artifacts generated during workflow's calls. Stored in `call.artifact`.

        start_speaking_plan : typing.Optional[StartSpeakingPlan]
            This is the plan for when the workflow nodes should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.

        stop_speaking_plan : typing.Optional[StopSpeakingPlan]
            This is the plan for when workflow nodes should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.

        monitor_plan : typing.Optional[MonitorPlan]
            This is the plan for real-time monitoring of the workflow's calls.

            Usage:
            - To enable live listening of the workflow's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the workflow's calls, set `monitorPlan.controlEnabled` to `true`.

        background_speech_denoising_plan : typing.Optional[BackgroundSpeechDenoisingPlan]
            This enables filtering of noise and background speech while the user is talking.

            Features:
            - Smart denoising using Krisp
            - Fourier denoising

            Both can be used together. Order of precedence:
            - Smart denoising
            - Fourier denoising

        credential_ids : typing.Optional[typing.Sequence[str]]
            These are the credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can provide a subset using this.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[Workflow]

        """
        _response = await self._client_wrapper.httpx_client.request(
            "workflow",
            method="POST",
            json={
                "nodes": convert_and_respect_annotation_metadata(
                    object_=nodes, annotation=typing.Sequence[CreateWorkflowDtoNodesItem], direction="write"
                ),
                "transcriber": convert_and_respect_annotation_metadata(
                    object_=transcriber, annotation=CreateWorkflowDtoTranscriber, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=CreateWorkflowDtoVoice, direction="write"
                ),
                "observabilityPlan": convert_and_respect_annotation_metadata(
                    object_=observability_plan, annotation=LangfuseObservabilityPlan, direction="write"
                ),
                "backgroundSound": convert_and_respect_annotation_metadata(
                    object_=background_sound, annotation=CreateWorkflowDtoBackgroundSound, direction="write"
                ),
                "credentials": convert_and_respect_annotation_metadata(
                    object_=credentials, annotation=typing.Sequence[CreateWorkflowDtoCredentialsItem], direction="write"
                ),
                "name": name,
                "edges": convert_and_respect_annotation_metadata(
                    object_=edges, annotation=typing.Sequence[Edge], direction="write"
                ),
                "globalPrompt": global_prompt,
                "server": convert_and_respect_annotation_metadata(object_=server, annotation=Server, direction="write"),
                "compliancePlan": convert_and_respect_annotation_metadata(
                    object_=compliance_plan, annotation=CompliancePlan, direction="write"
                ),
                "analysisPlan": convert_and_respect_annotation_metadata(
                    object_=analysis_plan, annotation=AnalysisPlan, direction="write"
                ),
                "artifactPlan": convert_and_respect_annotation_metadata(
                    object_=artifact_plan, annotation=ArtifactPlan, direction="write"
                ),
                "startSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=start_speaking_plan, annotation=StartSpeakingPlan, direction="write"
                ),
                "stopSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=stop_speaking_plan, annotation=StopSpeakingPlan, direction="write"
                ),
                "monitorPlan": convert_and_respect_annotation_metadata(
                    object_=monitor_plan, annotation=MonitorPlan, direction="write"
                ),
                "backgroundSpeechDenoisingPlan": convert_and_respect_annotation_metadata(
                    object_=background_speech_denoising_plan,
                    annotation=BackgroundSpeechDenoisingPlan,
                    direction="write",
                ),
                "credentialIds": credential_ids,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def workflow_controller_find_one(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[Workflow]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def workflow_controller_delete(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[Workflow]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def workflow_controller_update(
        self,
        id: str,
        *,
        nodes: typing.Optional[typing.Sequence[UpdateWorkflowDtoNodesItem]] = OMIT,
        transcriber: typing.Optional[UpdateWorkflowDtoTranscriber] = OMIT,
        voice: typing.Optional[UpdateWorkflowDtoVoice] = OMIT,
        observability_plan: typing.Optional[LangfuseObservabilityPlan] = OMIT,
        background_sound: typing.Optional[UpdateWorkflowDtoBackgroundSound] = OMIT,
        credentials: typing.Optional[typing.Sequence[UpdateWorkflowDtoCredentialsItem]] = OMIT,
        name: typing.Optional[str] = OMIT,
        edges: typing.Optional[typing.Sequence[Edge]] = OMIT,
        global_prompt: typing.Optional[str] = OMIT,
        server: typing.Optional[Server] = OMIT,
        compliance_plan: typing.Optional[CompliancePlan] = OMIT,
        analysis_plan: typing.Optional[AnalysisPlan] = OMIT,
        artifact_plan: typing.Optional[ArtifactPlan] = OMIT,
        start_speaking_plan: typing.Optional[StartSpeakingPlan] = OMIT,
        stop_speaking_plan: typing.Optional[StopSpeakingPlan] = OMIT,
        monitor_plan: typing.Optional[MonitorPlan] = OMIT,
        background_speech_denoising_plan: typing.Optional[BackgroundSpeechDenoisingPlan] = OMIT,
        credential_ids: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[Workflow]:
        """
        Parameters
        ----------
        id : str

        nodes : typing.Optional[typing.Sequence[UpdateWorkflowDtoNodesItem]]

        transcriber : typing.Optional[UpdateWorkflowDtoTranscriber]
            This is the transcriber for the workflow.

            This can be overridden at node level using `nodes[n].transcriber`.

        voice : typing.Optional[UpdateWorkflowDtoVoice]
            This is the voice for the workflow.

            This can be overridden at node level using `nodes[n].voice`.

        observability_plan : typing.Optional[LangfuseObservabilityPlan]
            This is the plan for observability of workflow's calls.

            Currently, only Langfuse is supported.

        background_sound : typing.Optional[UpdateWorkflowDtoBackgroundSound]
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.

        credentials : typing.Optional[typing.Sequence[UpdateWorkflowDtoCredentialsItem]]
            These are dynamic credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials.

        name : typing.Optional[str]

        edges : typing.Optional[typing.Sequence[Edge]]

        global_prompt : typing.Optional[str]

        server : typing.Optional[Server]
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. tool.server
            2. workflow.server / assistant.server
            3. phoneNumber.server
            4. org.server

        compliance_plan : typing.Optional[CompliancePlan]
            This is the compliance plan for the workflow. It allows you to configure HIPAA and other compliance settings.

        analysis_plan : typing.Optional[AnalysisPlan]
            This is the plan for analysis of workflow's calls. Stored in `call.analysis`.

        artifact_plan : typing.Optional[ArtifactPlan]
            This is the plan for artifacts generated during workflow's calls. Stored in `call.artifact`.

        start_speaking_plan : typing.Optional[StartSpeakingPlan]
            This is the plan for when the workflow nodes should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.

        stop_speaking_plan : typing.Optional[StopSpeakingPlan]
            This is the plan for when workflow nodes should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.

        monitor_plan : typing.Optional[MonitorPlan]
            This is the plan for real-time monitoring of the workflow's calls.

            Usage:
            - To enable live listening of the workflow's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the workflow's calls, set `monitorPlan.controlEnabled` to `true`.

        background_speech_denoising_plan : typing.Optional[BackgroundSpeechDenoisingPlan]
            This enables filtering of noise and background speech while the user is talking.

            Features:
            - Smart denoising using Krisp
            - Fourier denoising

            Both can be used together. Order of precedence:
            - Smart denoising
            - Fourier denoising

        credential_ids : typing.Optional[typing.Sequence[str]]
            These are the credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can provide a subset using this.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[Workflow]

        """
        _response = await self._client_wrapper.httpx_client.request(
            f"workflow/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "nodes": convert_and_respect_annotation_metadata(
                    object_=nodes, annotation=typing.Sequence[UpdateWorkflowDtoNodesItem], direction="write"
                ),
                "transcriber": convert_and_respect_annotation_metadata(
                    object_=transcriber, annotation=UpdateWorkflowDtoTranscriber, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=UpdateWorkflowDtoVoice, direction="write"
                ),
                "observabilityPlan": convert_and_respect_annotation_metadata(
                    object_=observability_plan, annotation=LangfuseObservabilityPlan, direction="write"
                ),
                "backgroundSound": convert_and_respect_annotation_metadata(
                    object_=background_sound, annotation=UpdateWorkflowDtoBackgroundSound, direction="write"
                ),
                "credentials": convert_and_respect_annotation_metadata(
                    object_=credentials, annotation=typing.Sequence[UpdateWorkflowDtoCredentialsItem], direction="write"
                ),
                "name": name,
                "edges": convert_and_respect_annotation_metadata(
                    object_=edges, annotation=typing.Sequence[Edge], direction="write"
                ),
                "globalPrompt": global_prompt,
                "server": convert_and_respect_annotation_metadata(object_=server, annotation=Server, direction="write"),
                "compliancePlan": convert_and_respect_annotation_metadata(
                    object_=compliance_plan, annotation=CompliancePlan, direction="write"
                ),
                "analysisPlan": convert_and_respect_annotation_metadata(
                    object_=analysis_plan, annotation=AnalysisPlan, direction="write"
                ),
                "artifactPlan": convert_and_respect_annotation_metadata(
                    object_=artifact_plan, annotation=ArtifactPlan, direction="write"
                ),
                "startSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=start_speaking_plan, annotation=StartSpeakingPlan, direction="write"
                ),
                "stopSpeakingPlan": convert_and_respect_annotation_metadata(
                    object_=stop_speaking_plan, annotation=StopSpeakingPlan, direction="write"
                ),
                "monitorPlan": convert_and_respect_annotation_metadata(
                    object_=monitor_plan, annotation=MonitorPlan, direction="write"
                ),
                "backgroundSpeechDenoisingPlan": convert_and_respect_annotation_metadata(
                    object_=background_speech_denoising_plan,
                    annotation=BackgroundSpeechDenoisingPlan,
                    direction="write",
                ),
                "credentialIds": credential_ids,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    Workflow,
                    construct_type(
                        type_=Workflow,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
